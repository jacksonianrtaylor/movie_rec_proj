{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numba import njit\n",
    "import copy\n",
    "from skopt import Optimizer\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import Generator, PCG64\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.array as da\n",
    "\n",
    "\n",
    "# This does not change the consistency\n",
    "# cluster = LocalCluster(n_workers=8)\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "#test stock model to compare:\n",
    "from surprise import SVD,Dataset,Reader\n",
    "\n",
    "\n",
    "#LOOK: this cell has been developed to test a configuration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SEED_INT = 56\n",
    "# random.seed(56)\n",
    "# np.random.seed(56)\n",
    "# da.random.RandomState(56)\n",
    "# da.random.default_rng(56)\n",
    "# da.random.seed(56)\n",
    "\n",
    "\n",
    "def funct(block):\n",
    "\n",
    "    # SEED_INT = 56\n",
    "    # random.seed(SEED_INT)\n",
    "    # np.random.seed(SEED_INT)\n",
    "    # da.random.RandomState(SEED_INT)\n",
    "    # da.random.default_rng(SEED_INT)\n",
    "    # da.random.seed(SEED_INT)\n",
    "\n",
    "    total_sum = 0 \n",
    "\n",
    "    for row in block:\n",
    "        seed_int, user_to_data_svd_temp, user_to_data_train_temp, nof_latent_features, epochs, rt, lr = row\n",
    "\n",
    "\n",
    "        gen = Generator(PCG64(seed_int))\n",
    "\n",
    "\n",
    "        old_to_new_svd  = dict()\n",
    "        last_index_svd = 0\n",
    "        svd_cnt = 0\n",
    "\n",
    "        for user in user_to_data_svd_temp:\n",
    "            for row in user: \n",
    "                if(row[1] in old_to_new_svd.keys()):\n",
    "                    row[1] = old_to_new_svd[row[1]]\n",
    "                else:\n",
    "                    old_to_new_svd[row[1]] = last_index_svd\n",
    "                    row[1] = last_index_svd\n",
    "                    last_index_svd+=1      \n",
    "                row[0] = svd_cnt\n",
    "            svd_cnt+=1\n",
    "\n",
    "\n",
    "        old_to_new_train = copy.deepcopy(old_to_new_svd)\n",
    "        last_index_train = last_index_svd\n",
    "        train_cnt = svd_cnt\n",
    "\n",
    "        for user in user_to_data_train_temp:\n",
    "            for row in user: \n",
    "                if(row[1] in old_to_new_train.keys()):\n",
    "                    row[1] = old_to_new_train[row[1]]\n",
    "                else:\n",
    "                    old_to_new_train[row[1]] = last_index_train\n",
    "                    row[1] = last_index_train\n",
    "                    last_index_train+=1      \n",
    "                row[0] = train_cnt\n",
    "            train_cnt+=1\n",
    "\n",
    "\n",
    "        target_rating_train = []\n",
    "        train_list = []\n",
    "\n",
    "\n",
    "        movies_order_svd = set()\n",
    "        overall_average_svd = 0 \n",
    "        cnt_svd = 0\n",
    "\n",
    "\n",
    "        for user in user_to_data_svd_temp:\n",
    "            for movie in user:\n",
    "                movies_order_svd.add(movie[1])\n",
    "                train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "                overall_average_svd+=float(movie[2])\n",
    "                cnt_svd += 1\n",
    "\n",
    "\n",
    "\n",
    "        movies_order_train = copy.deepcopy(movies_order_svd)\n",
    "        overall_average_train = overall_average_svd \n",
    "        cnt_train = cnt_svd\n",
    "        train_rating_to_predict = []\n",
    "\n",
    "        for user in user_to_data_train_temp:\n",
    "            # rand_num  = random.randint(0, len(user)-1)\n",
    "            rand_num  = gen.integers(0, len(user))\n",
    "            index = 0\n",
    "            for movie in user:\n",
    "                movies_order_train.add(movie[1])\n",
    "                if(index == rand_num):\n",
    "                    train_rating_to_predict.append([int(movie[0]), int(movie[1])])\n",
    "                    target_rating_train.append(float(movie[2]))\n",
    "                else:\n",
    "                    overall_average_train+=float(movie[2])\n",
    "                    cnt_train += 1\n",
    "                    train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "                index+=1\n",
    "\n",
    "\n",
    "        overall_average_train = overall_average_train/cnt_train\n",
    "\n",
    "        # random.shuffle(train_list)\n",
    "        gen.shuffle(train_list)\n",
    "\n",
    "\n",
    "        @njit\n",
    "        def epoch(list, b1, b2, p, q, overall_average, lr, rt):\n",
    "            for row in list:\n",
    "                u = int(row[0])\n",
    "                i = int(row[1])\n",
    "                r = row[2]\n",
    "\n",
    "                pred = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "                error = r-pred\n",
    "                b1[u] += lr*(error- rt*b1[u])\n",
    "                b2[i] += lr*(error- rt*b2[i])\n",
    "                temp = lr*(error*q[i] -rt*p[u])\n",
    "                q[i] += lr*(error*p[u] -rt*q[i])\n",
    "                p[u] += temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def svd_iterative(list, n, epochs, rt, lr, overall_average, nof_users, nof_movies):\n",
    "\n",
    "            # q = np.random.normal(0, .1, (nof_movies, n))\n",
    "            # p = np.random.normal(0, .1, (nof_users, n))\n",
    "\n",
    "            q = gen.normal(0, .1, (nof_movies, n))\n",
    "            p = gen.normal(0, .1, (nof_users, n))\n",
    "\n",
    "\n",
    "            b1 = np.zeros(nof_users)\n",
    "            b2 = np.zeros(nof_movies)\n",
    "\n",
    "            np_array = np.array(list)\n",
    "\n",
    "            for _ in range(epochs):\n",
    "                epoch(np_array, b1, b2, p, q, overall_average, lr, rt)\n",
    "\n",
    "            return b1, b2, p, q\n",
    "\n",
    "\n",
    "        b1, b2, p, q = svd_iterative(train_list, nof_latent_features, epochs, rt, lr,\n",
    "                                    overall_average_train, len(user_to_data_svd_temp)+len(user_to_data_train_temp), len(movies_order_train))\n",
    "\n",
    "        feature_3_train = [overall_average_train + b1[pair[0]]+b2[pair[1]]\n",
    "                                    +np.dot(p[pair[0]],q[pair[1]]) for pair in train_rating_to_predict]\n",
    "    \n",
    "        total_sum+=mean_squared_error(target_rating_train, feature_3_train, squared = False)\n",
    "\n",
    "    return (np.array([[total_sum]], dtype=\"float32\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_sum =0 \n",
    "runs = 80\n",
    "\n",
    "\n",
    "\n",
    "nof_svd_users, nof_train_users, nof_latent_features, epochs, rt, lr = (355, 123, 196, 204, 0.03407177995884917, 0.03668743198104899)\n",
    "\n",
    "\n",
    "#LOOK: this makes this cell slightly inconsistent with the best call in the cell below\n",
    "user_to_data_svd_copy = copy.deepcopy(user_to_data_svd)\n",
    "user_to_data_train_copy = copy.deepcopy(user_to_data_train)\n",
    "\n",
    "\n",
    "# random.shuffle(user_to_data_svd_copy)\n",
    "# random.shuffle(user_to_data_train_copy)\n",
    "\n",
    "\n",
    "# user_to_data_svd_list = [user_to_data_svd_copy[i*nof_svd_users : (i+1)*nof_svd_users] for i in range(runs)]\n",
    "# user_to_data_train_list = [user_to_data_train_copy[i*nof_train_users : (i+1)*nof_train_users] for i in range(runs)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outer = Generator(PCG64(15))\n",
    "\n",
    "\n",
    "parameters_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(runs):\n",
    "    parameters_list.append([outer.integers(0,100),\n",
    "                            copy.deepcopy(outer.choice(user_to_data_svd_copy, nof_svd_users, replace = False)),\n",
    "                            copy.deepcopy(outer.choice(user_to_data_train_copy, nof_train_users, replace = False)),\n",
    "                            nof_latent_features, epochs, rt, lr])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test = np.array(parameters_list, dtype=\"object\")\n",
    "dask_array = da.from_array(test, chunks=(10,7))\n",
    "results = dask_array.map_blocks(funct, chunks = (1,1), dtype=\"float32\").compute()\n",
    "\n",
    "\n",
    "for row in results:\n",
    "    mse_sum+= row[0]\n",
    "\n",
    "\n",
    "print(\"fixed parameters rmse score:\",mse_sum/runs)\n",
    "\n",
    "\n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "\n",
    "# seed_int = 5\n",
    "# fixed parameters rmse score: 1.0399177312850951\n",
    "# seed_int = 10\n",
    "# fixed parameters rmse score: 1.0447407484054565\n",
    "# seed_int = 15\n",
    "# fixed parameters rmse score: 1.0471360564231873"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
