{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes taken: 0.6288645029067993\n",
      "        userId    id rating               title  \\\n",
      "6566765      1  1246    5.0        Rocky Balboa   \n",
      "6880303      1  2959    4.0      License to Wed   \n",
      "2083077      1  2762    4.5  Young and Innocent   \n",
      "1492304      1  1968    4.0       Fools Rush In   \n",
      "2638962      1   147    4.5       The 400 Blows   \n",
      "\n",
      "                                                                                                genres  \\\n",
      "6566765                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "6880303                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "2083077                                     [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name': 'Crime'}]   \n",
      "1492304  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "2638962                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                production_companies  \\\n",
      "6566765                                                                                                  [{'name': 'Columbia Pictures', 'id': 5}, {'name': 'Revolution Studios', 'id': 497}, {'name': 'Rogue Marble', 'id': 696}, {'name': 'Metro-Goldwyn-Mayer (MGM)', 'id': 8411}]   \n",
      "6880303  [{'name': 'Village Roadshow Pictures', 'id': 79}, {'name': 'Robert Simonds Productions', 'id': 3929}, {'name': 'Warner Bros.', 'id': 6194}, {'name': 'Phoenix Pictures', 'id': 11317}, {'name': 'Underground', 'id': 49326}, {'name': 'Proposal Productions', 'id': 49327}]   \n",
      "2083077                                                                                                                                                                                                                [{'name': 'Gaumont British Picture Corporation', 'id': 4978}]   \n",
      "1492304                                                                                                                                                                                                                                     [{'name': 'Columbia Pictures', 'id': 5}]   \n",
      "2638962                                                                                                                                 [{'name': 'Les Films du Carrosse', 'id': 53}, {'name': 'SÃ©dif Productions', 'id': 10897}, {'name': 'The Criterion Collection', 'id': 10932}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
      "6566765  [{'id': 276, 'name': 'philadelphia'}, {'id': 396, 'name': 'transporter'}, {'id': 1721, 'name': 'fight'}, {'id': 2038, 'name': \"love of one's life\"}, {'id': 2416, 'name': 'publicity'}, {'id': 2792, 'name': 'boxer'}, {'id': 2968, 'name': 'grave'}, {'id': 3393, 'name': 'tombstone'}, {'id': 3586, 'name': 'tv station'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5167, 'name': 'restaurant owner'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5380, 'name': 'virtual fight'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 10163, 'name': 'cancer'}, {'id': 155464, 'name': 'over-the-hill fighter'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                             [{'id': 1605, 'name': 'new love'}, {'id': 2856, 'name': 'ten commandments'}, {'id': 3582, 'name': 'bride'}, {'id': 3583, 'name': 'bridegroom'}, {'id': 6038, 'name': 'marriage'}, {'id': 6192, 'name': 'relation'}, {'id': 6281, 'name': 'partnership'}, {'id': 6704, 'name': 'civil registry office'}, {'id': 10093, 'name': 'priest'}, {'id': 13027, 'name': 'wedding'}, {'id': 14765, 'name': 'church'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'id': 769, 'name': 'falsely accused'}, {'id': 1655, 'name': 'country house'}, {'id': 9826, 'name': 'murder'}, {'id': 9937, 'name': 'suspense'}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'id': 828, 'name': 'waitress'}, {'id': 1463, 'name': 'culture clash'}, {'id': 9799, 'name': 'romantic comedy'}, {'id': 13149, 'name': 'pregnancy'}]   \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                      [{'id': 6930, 'name': 'fondling'}, {'id': 10183, 'name': 'independent film'}, {'id': 155518, 'name': 'nouvelle vague'}, {'id': 170268, 'name': 'skipping school'}, {'id': 170272, 'name': 'mise en scene'}, {'id': 170273, 'name': 'fingerprinting'}, {'id': 170279, 'name': '\\xa0mugshot'}, {'id': 170286, 'name': 'strict teacher'}, {'id': 170293, 'name': 'montmartre paris'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        cast  \\\n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'cast_id': 24, 'character': 'Rocky Balboa', 'credit_id': '52fe42e9c3a36847f802c61b', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 25, 'character': 'Paulie', 'credit_id': '52fe42e9c3a36847f802c61f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 1, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 26, 'character': 'Rocky Jr.', 'credit_id': '52fe42e9c3a36847f802c623', 'gender': 2, 'id': 16501, 'name': 'Milo Ventimiglia', 'order': 2, 'profile_path': '/maJeS6bA6ku21rSRceISQtwHL2h.jpg'}, {'cast_id': 27, 'character': 'Marie', 'credit_id': '52fe42e9c3a36847f802c627', 'gender': 1, 'id': 16502, 'name': 'Geraldine Hughes', 'order': 3, 'profile_path': '/bTXux3EJq25Fh2ixbet6MjdG3Fb.jpg'}, {'cast_id': 28, 'character': 'Steps', 'credit_id': '52fe42e9c3a36847f802c62b', 'gender': 2, 'id': 16503, 'name': 'James Francis Kelly III', 'order': 4, 'profile_path': '/iZyTQ2UlwNXrqLqPeNHbofFXubP.jpg'}, {'cast_id': 29, 'character': 'Duke', 'credit_id': '52fe42e9c3a36847f802c62f', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 30, 'character': 'L.C.', 'credit_id': '52fe42e9c3a36847f802c633', 'gender': 2, 'id': 16505, 'name': 'A. J. Benza', 'order': 6, 'profile_path': '/5hVinC6C1ZyD7c8EmZFTiEaF7vH.jpg'}, {'cast_id': 31, 'character': 'Adrian', 'credit_id': '52fe42e9c3a36847f802c637', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 7, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 32, 'character': 'Martin', 'credit_id': '52fe42e9c3a36847f802c63b', 'gender': 2, 'id': 16506, 'name': 'Henry G. Sanders', 'order': 8, 'profile_path': '/2SU75g2CAIzGWbgfIlNvKZQhYTZ.jpg'}, {'cast_id': 33, 'character': \"Mason 'The Line' Dixon\", 'credit_id': '52fe42e9c3a36847f802c63f', 'gender': 2, 'id': 16507, 'name': 'Antonio Tarver', 'order': 9, 'profile_path': '/kJEljjHwBvrjoxqcSVntXlejgl1.jpg'}, {'cast_id': 34, 'character': 'Spider Rico', 'credit_id': '52fe42e9c3a36847f802c643', 'gender': 2, 'id': 16508, 'name': 'Pedro Lovell', 'order': 10, 'profile_path': None}, {'cast_id': 35, 'character': 'Isabel', 'credit_id': '52fe42e9c3a36847f802c647', 'gender': 1, 'id': 16509, 'name': 'Ana Gerena', 'order': 11, 'profile_path': None}, {'cast_id': 36, 'character': 'Angie', 'credit_id': '52fe42e9c3a36847f802c64b', 'gender': 1, 'id': 16510, 'name': 'Angela Boyd', 'order': 12, 'profile_path': None}, {'cast_id': 37, 'character': 'Bar Thug', 'credit_id': '52fe42e9c3a36847f802c64f', 'gender': 0, 'id': 16511, 'name': 'Louis Giansante', 'order': 13, 'profile_path': None}, {'cast_id': 38, 'character': \"Lucky's Bartender\", 'credit_id': '52fe42e9c3a36847f802c653', 'gender': 0, 'id': 16512, 'name': 'Maureen Schilling', 'order': 14, 'profile_path': None}, {'cast_id': 40, 'character': 'X-Cell', 'credit_id': '5761db05c3a3682f20000302', 'gender': 2, 'id': 98298, 'name': 'Lahmard J. Tate', 'order': 15, 'profile_path': '/4WcFReePSxyGQJWV5wXGNfY0Y7o.jpg'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'cast_id': 18, 'character': 'Reverend Frank', 'credit_id': '52fe4376c3a36847f8056039', 'gender': 2, 'id': 2157, 'name': 'Robin Williams', 'order': 0, 'profile_path': '/sojtJyIV3lkUeThD7A2oHNm8183.jpg'}, {'cast_id': 19, 'character': 'Sadie Jones', 'credit_id': '52fe4376c3a36847f805603d', 'gender': 1, 'id': 16855, 'name': 'Mandy Moore', 'order': 1, 'profile_path': '/15sDtRpe301tZWrRYV31wjMuFpx.jpg'}, {'cast_id': 20, 'character': 'Ben Murphy', 'credit_id': '52fe4376c3a36847f8056041', 'gender': 2, 'id': 17697, 'name': 'John Krasinski', 'order': 2, 'profile_path': '/nOWwdZURikW22qo6OUSGFCTukgc.jpg'}, {'cast_id': 21, 'character': 'Carlisle', 'credit_id': '52fe4376c3a36847f8056045', 'gender': 2, 'id': 29020, 'name': 'Eric Christian Olsen', 'order': 3, 'profile_path': '/clbouet8o9IJlUd8WILD0lzHAtG.jpg'}, {'cast_id': 22, 'character': 'Lindsey Jones', 'credit_id': '52fe4376c3a36847f8056049', 'gender': 1, 'id': 15286, 'name': 'Christine Taylor', 'order': 4, 'profile_path': '/99OssnGmgGjduXFA7syxjNqt9tQ.jpg'}, {'cast_id': 23, 'character': 'Choir Boy', 'credit_id': '52fe4376c3a36847f805604d', 'gender': 2, 'id': 216, 'name': 'Josh Flitter', 'order': 5, 'profile_path': '/6RCA8tDWBxIVk9N3IqUjJEAzYGv.jpg'}, {'cast_id': 24, 'character': 'Joel', 'credit_id': '52fe4376c3a36847f8056051', 'gender': 2, 'id': 11827, 'name': 'DeRay Davis', 'order': 6, 'profile_path': '/w2JYPRLwXhNCpxpJc2v4UQYyMv8.jpg'}, {'cast_id': 25, 'character': 'Mr. Jones', 'credit_id': '52fe4376c3a36847f8056055', 'gender': 2, 'id': 21368, 'name': 'Peter Strauss', 'order': 7, 'profile_path': '/ufx1trct43k7UcT4DpoIMPZXi5A.jpg'}, {'cast_id': 26, 'character': 'Grandma Jones', 'credit_id': '52fe4376c3a36847f8056059', 'gender': 1, 'id': 6465, 'name': 'Grace Zabriskie', 'order': 8, 'profile_path': '/ibBabuSM1UyPYFFo0wBXhGbqElk.jpg'}, {'cast_id': 27, 'character': 'Mrs. Jones', 'credit_id': '52fe4376c3a36847f805605d', 'gender': 1, 'id': 29021, 'name': 'Roxanne Hart', 'order': 9, 'profile_path': '/yWGMW6HdhUGT2oIcQ4jmnkw7ZAM.jpg'}, {'cast_id': 28, 'character': 'Shelly', 'credit_id': '5586ee469251417f6f0059c8', 'gender': 1, 'id': 125167, 'name': 'Mindy Kaling', 'order': 10, 'profile_path': '/Agpd4tJyZ95hk74RifjnfnJpn9U.jpg'}, {'cast_id': 30, 'character': 'Expectant Father', 'credit_id': '56c3467cc3a36847c5001f66', 'gender': 2, 'id': 1368801, 'name': 'David Quinlan', 'order': 11, 'profile_path': '/2m75rrBhvOTtdUS9jlKW8GOHCBV.jpg'}, {'cast_id': 31, 'character': 'Judith', 'credit_id': '58e26093c3a36872f600dcf2', 'gender': 1, 'id': 113867, 'name': 'Angela Kinsey', 'order': 12, 'profile_path': '/omLdRLdwMLliVeVIualEnWVhm1a.jpg'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'cast_id': 18, 'character': 'Erica Burgoyne', 'credit_id': '52fe436bc3a36847f8052cd5', 'gender': 1, 'id': 27939, 'name': 'Nova Pilbeam', 'order': 0, 'profile_path': '/l6oHJaRYrVxsvoTSmMS5wIXaei5.jpg'}, {'cast_id': 19, 'character': 'Robert Tisdall', 'credit_id': '52fe436bc3a36847f8052cd9', 'gender': 0, 'id': 27940, 'name': 'Derrick De Marney', 'order': 1, 'profile_path': '/7VRZ7K0EZ50haOlbVr7DHZ5550O.jpg'}, {'cast_id': 20, 'character': 'Col. Burgoyne', 'credit_id': '52fe436bc3a36847f8052cdd', 'gender': 2, 'id': 27929, 'name': 'Percy Marmont', 'order': 2, 'profile_path': '/p3DIyvlxx6B0SVIxcDaPUPlEV0U.jpg'}, {'cast_id': 21, 'character': 'Old Will', 'credit_id': '52fe436bc3a36847f8052ce1', 'gender': 2, 'id': 27941, 'name': 'Edward Rigby', 'order': 3, 'profile_path': '/B7GJ0jPtODqZVgVtZHPtvZl2tO.jpg'}, {'cast_id': 22, 'character': 'Ericas Tante Margaret', 'credit_id': '52fe436bc3a36847f8052ce5', 'gender': 1, 'id': 14304, 'name': 'Mary Clare', 'order': 4, 'profile_path': '/lAdEwCGiSUj9CCMPB4L9X4oujLe.jpg'}, {'cast_id': 23, 'character': 'Det. Insp. Kent', 'credit_id': '52fe436bc3a36847f8052ce9', 'gender': 2, 'id': 7383, 'name': 'John Longden', 'order': 5, 'profile_path': '/rsCoUEx2ThNIz12fBR6vPncCICk.jpg'}, {'cast_id': 24, 'character': 'Guy', 'credit_id': '52fe436bc3a36847f8052ced', 'gender': 2, 'id': 27942, 'name': 'George Curzon', 'order': 6, 'profile_path': None}, {'cast_id': 25, 'character': 'Ericas Onkel Basil', 'credit_id': '52fe436bc3a36847f8052cf1', 'gender': 2, 'id': 14303, 'name': 'Basil Radford', 'order': 7, 'profile_path': '/9STo7Tgdutplo78ZtyeINGWkXUk.jpg'}, {'cast_id': 26, 'character': 'Christine Clay', 'credit_id': '52fe436bc3a36847f8052cf5', 'gender': 1, 'id': 27943, 'name': 'Pamela Carme', 'order': 8, 'profile_path': None}, {'cast_id': 27, 'character': 'Detective Sergeant Miller', 'credit_id': '52fe436bc3a36847f8052cf9', 'gender': 2, 'id': 27944, 'name': 'George Merritt', 'order': 9, 'profile_path': None}, {'cast_id': 28, 'character': 'Henry Briggs', 'credit_id': '52fe436bc3a36847f8052cfd', 'gender': 2, 'id': 27945, 'name': 'J.H. Roberts', 'order': 10, 'profile_path': None}, {'cast_id': 29, 'character': \"Truckfahrer bei Tom's Hat\", 'credit_id': '52fe436bc3a36847f8052d01', 'gender': 2, 'id': 27946, 'name': 'Jerry Verno', 'order': 11, 'profile_path': None}, {'cast_id': 30, 'character': 'Police Sergeant Ruddock', 'credit_id': '52fe436bc3a36847f8052d05', 'gender': 2, 'id': 27947, 'name': 'H.F. Maltby', 'order': 12, 'profile_path': None}, {'cast_id': 31, 'character': 'Police Constable', 'credit_id': '52fe436bc3a36847f8052d09', 'gender': 2, 'id': 27948, 'name': 'John Miller', 'order': 13, 'profile_path': None}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'cast_id': 2, 'character': 'Alex Whitman', 'credit_id': '52fe4327c3a36847f803e629', 'gender': 2, 'id': 14408, 'name': 'Matthew Perry', 'order': 0, 'profile_path': '/oSKEEDXDNnwWdQ68qfDVD6Q7Pxp.jpg'}, {'cast_id': 3, 'character': 'Isabel Fuentes', 'credit_id': '52fe4327c3a36847f803e62d', 'gender': 1, 'id': 3136, 'name': 'Salma Hayek', 'order': 1, 'profile_path': '/u5mg73xKVqm8oT93HoMmsgQHyoK.jpg'}, {'cast_id': 4, 'character': 'Jeff', 'credit_id': '52fe4327c3a36847f803e631', 'gender': 2, 'id': 4602, 'name': 'Jon Tenney', 'order': 2, 'profile_path': '/fiG1bW6DX1szsRDPIYjfIKPQ0kV.jpg'}, {'cast_id': 5, 'character': 'Lanie', 'credit_id': '52fe4327c3a36847f803e635', 'gender': 1, 'id': 6751, 'name': 'Siobhan Fallon', 'order': 3, 'profile_path': '/wVFa8GiY0xdOLFsvGygy9RMtcBc.jpg'}, {'cast_id': 16, 'character': 'Great Grandma', 'credit_id': '52fe4327c3a36847f803e675', 'gender': 1, 'id': 20360, 'name': 'Angelina Torres', 'order': 4, 'profile_path': None}, {'cast_id': 17, 'character': 'Richard Whitman', 'credit_id': '52fe4327c3a36847f803e679', 'gender': 2, 'id': 20361, 'name': 'John Bennett Perry', 'order': 5, 'profile_path': '/bzFhwuXsdZiOHRtBgz4XVELIFYO.jpg'}, {'cast_id': 18, 'character': 'Nan Whitman', 'credit_id': '52fe4327c3a36847f803e67d', 'gender': 1, 'id': 20362, 'name': 'Jill Clayburgh', 'order': 6, 'profile_path': '/twrfhIvbqHuJ7nXVpehvU6nyi6R.jpg'}, {'cast_id': 19, 'character': 'Cathy Stewart', 'credit_id': '52fe4327c3a36847f803e681', 'gender': 1, 'id': 20363, 'name': 'Suzanne Snyder', 'order': 7, 'profile_path': '/90FrTcjJudpeIYUjUzlO6XAmvnt.jpg'}, {'cast_id': 20, 'character': 'Amalia', 'credit_id': '52fe4327c3a36847f803e685', 'gender': 0, 'id': 13029, 'name': 'Anne Betancourt', 'order': 8, 'profile_path': '/6UU5P4DzjJTSBFztIu1nALT2tk0.jpg'}, {'cast_id': 21, 'character': 'Juan Fuentes', 'credit_id': '52fe4327c3a36847f803e689', 'gender': 2, 'id': 4511, 'name': 'Mark Adair-Rios', 'order': 9, 'profile_path': '/rX4d1e5jlF5P73qynjjUzJslB0c.jpg'}, {'cast_id': 22, 'character': 'Judd Marshall', 'credit_id': '52fe4327c3a36847f803e68d', 'gender': 2, 'id': 4171, 'name': 'Stanley DeSantis', 'order': 10, 'profile_path': '/4cHxkhTd7oklyNkdva9WJp0FLrX.jpg'}, {'cast_id': 23, 'character': 'Antonio Fuentes', 'credit_id': '52fe4327c3a36847f803e691', 'gender': 0, 'id': 4665, 'name': 'Josh Cruze', 'order': 11, 'profile_path': '/v3QrQzH0uGV9pd1dNR5Ue6a74qO.jpg'}, {'cast_id': 24, 'character': 'Petra', 'credit_id': '52fe4327c3a36847f803e695', 'gender': 0, 'id': 4666, 'name': 'Angela Lanza', 'order': 12, 'profile_path': '/zmf6TMWMVCdnuUfpgdnioaICk1L.jpg'}, {'cast_id': 25, 'character': 'Phil', 'credit_id': '52fe4327c3a36847f803e699', 'gender': 2, 'id': 4445, 'name': 'Chris Bauer', 'order': 13, 'profile_path': '/3KYVMaGkWTEDQ0T9lsu85pVbP4T.jpg'}, {'cast_id': 26, 'character': 'Chuy', 'credit_id': '577e438f925141440c000d63', 'gender': 0, 'id': 115874, 'name': 'Carlos GÃ³mez', 'order': 14, 'profile_path': '/nBxwoMv1zrhNXyEjYXbcdmAdmF0.jpg'}]   \n",
      "2638962  [{'cast_id': 6, 'character': 'Antoine Doinel', 'credit_id': '52fe421ec3a36847f8005661', 'gender': 2, 'id': 1653, 'name': 'Jean-Pierre LÃ©aud', 'order': 0, 'profile_path': '/dzkPODapVe4CSubEqI9ytTCqnZ7.jpg'}, {'cast_id': 7, 'character': 'Gilberte Doinel', 'credit_id': '52fe421ec3a36847f8005665', 'gender': 1, 'id': 1654, 'name': 'Claire Maurier', 'order': 1, 'profile_path': '/cP1n7zMsMKr77xJeR3CncomxEZ0.jpg'}, {'cast_id': 8, 'character': 'Julien Doinel', 'credit_id': '52fe421ec3a36847f8005669', 'gender': 0, 'id': 1655, 'name': 'Albert RÃ©my', 'order': 2, 'profile_path': '/6b8eyIXAV6oA5eX6ltc3hF7ZB3d.jpg'}, {'cast_id': 10, 'character': 'Mr. Bigey', 'credit_id': '52fe421ec3a36847f8005673', 'gender': 2, 'id': 1658, 'name': 'Georges Flamant', 'order': 3, 'profile_path': '/lQwmtPsFWME63x5M7IRF6g8bLrR.jpg'}, {'cast_id': 11, 'character': 'RenÃ©', 'credit_id': '52fe421ec3a36847f8005677', 'gender': 0, 'id': 1659, 'name': 'Patrick Auffay', 'order': 4, 'profile_path': None}, {'cast_id': 12, 'character': 'Director of the school', 'credit_id': '52fe421ec3a36847f800567b', 'gender': 0, 'id': 1660, 'name': 'Robert Beauvais', 'order': 5, 'profile_path': None}, {'cast_id': 13, 'character': 'Mme Bigey', 'credit_id': '52fe421ec3a36847f800567f', 'gender': 0, 'id': 1661, 'name': 'Yvonne Claudie', 'order': 6, 'profile_path': None}, {'cast_id': 14, 'character': 'English Teacher', 'credit_id': '52fe421ec3a36847f8005683', 'gender': 0, 'id': 1662, 'name': 'Pierre Repp', 'order': 7, 'profile_path': '/1AUhiNGBAR0C6AU9iK1IXBs3QTz.jpg'}, {'cast_id': 17, 'character': 'French Teacher', 'credit_id': '52fe421ec3a36847f8005693', 'gender': 0, 'id': 1656, 'name': 'Guy Decomble', 'order': 8, 'profile_path': '/34iexAuqI1asyFounbSXSCFphen.jpg'}, {'cast_id': 20, 'character': 'Betrand Mauricet', 'credit_id': '52fe421ec3a36847f8005697', 'gender': 0, 'id': 1077237, 'name': 'Daniel Couturier', 'order': 9, 'profile_path': None}, {'cast_id': 21, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569b', 'gender': 0, 'id': 1077238, 'name': 'FranÃ§ois Nocher', 'order': 10, 'profile_path': None}, {'cast_id': 22, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569f', 'gender': 2, 'id': 150939, 'name': 'Richard Kanayan', 'order': 11, 'profile_path': '/vCMDk3ifj2vJKZYCISXT3K6DYXF.jpg'}, {'cast_id': 23, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a3', 'gender': 0, 'id': 1077239, 'name': 'Renaud Fontanarosa', 'order': 12, 'profile_path': None}, {'cast_id': 24, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a7', 'gender': 0, 'id': 1077240, 'name': 'Michel Girard', 'order': 13, 'profile_path': None}, {'cast_id': 25, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056ab', 'gender': 0, 'id': 71997, 'name': 'Serge Moati', 'order': 14, 'profile_path': '/wccRQKHrX61sH4WlOtM1KBP4qaq.jpg'}, {'cast_id': 26, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056af', 'gender': 0, 'id': 1077241, 'name': 'Bernard Abbou', 'order': 15, 'profile_path': None}, {'cast_id': 27, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b3', 'gender': 0, 'id': 1077242, 'name': 'Jean-FranÃ§ois Bergouignan', 'order': 16, 'profile_path': None}, {'cast_id': 28, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b7', 'gender': 0, 'id': 1077243, 'name': 'Michel Lesignor', 'order': 17, 'profile_path': None}, {'cast_id': 31, 'character': 'Man in Street', 'credit_id': '5457f0a1c3a3683993000156', 'gender': 2, 'id': 24299, 'name': 'Jean-Claude Brialy', 'order': 18, 'profile_path': '/g3kkYcAvq90tALMErxmdAIcIXsE.jpg'}, {'cast_id': 32, 'character': 'Woman with Dog', 'credit_id': '5457f0bec3a36839a0000144', 'gender': 1, 'id': 14812, 'name': 'Jeanne Moreau', 'order': 19, 'profile_path': '/uHJnVwCzehEoz0mIlwN7xkymql8.jpg'}, {'cast_id': 33, 'character': 'Man in Funfair', 'credit_id': '5457f0d3c3a368399300015b', 'gender': 2, 'id': 34613, 'name': 'Philippe de Broca', 'order': 20, 'profile_path': '/yrvmXE2SJBX659r2Y7eWwlmwfYd.jpg'}, {'cast_id': 34, 'character': 'Man in Funfair', 'credit_id': '5457f0e5c3a368399d00014c', 'gender': 0, 'id': 1650, 'name': 'FranÃ§ois Truffaut', 'order': 21, 'profile_path': '/apCCV99N3FqB5NsEPqOzetlkprL.jpg'}]   \n",
      "\n",
      "                                                                               tagline  \\\n",
      "6566765                                                  It ain't over 'til it's over.   \n",
      "6880303                                   First came love... then came Reverend Frank.   \n",
      "2083077                                                          A Brilliant Melodrama   \n",
      "1492304  What if finding the love of your life meant changing the life that you loved?   \n",
      "2638962                                            Angel faces hell-bent for violence.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        overview  \n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When he loses a highly publicized virtual boxing match to ex-champ Rocky Balboa, reigning heavyweight titleholder, Mason Dixon retaliates by challenging Rocky to a nationally televised, 10-round exhibition bout. To the surprise of his son and friends, Rocky agrees to come out of retirement and face an opponent who's faster, stronger and thirty years his junior.  \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Newly engaged, Ben and Sadie can't wait to start their life together and live happily ever after. However Sadie's family church's Reverend Frank won't bless their union until they pass his patented, \"foolproof\" marriage prep course consisting of outrageous classes, outlandish homework assignments and some outright invasion of privacy.  \n",
      "2083077  Derrick De Marney finds himself in a 39 Steps situation when he is wrongly accused of murder. While a fugitive from the law, De Marney is helped by heroine Nova Pilbeam, who three years earlier had played the adolescent kidnap victim in Hitchcock's The Man Who Knew Too Much. The obligatory \"fish out of water\" scene, in which the principals are briefly slowed down by a banal everyday event, occurs during a child's birthday party. The actual villain, whose identity is never in doubt (Hitchcock made thrillers, not mysteries) is played by George Curzon, who suffers from a twitching eye. Curzon's revelation during an elaborate nightclub sequence is a Hitchcockian tour de force, the sort of virtuoso sequence taken for granted in these days of flexible cameras and computer enhancement, but which in 1937 took a great deal of time, patience and talent to pull off. Released in the US as The Girl Was Young, Young and Innocent was based on a novel by Josephine Tey.  \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alex Whitman (Matthew Perry) is a designer from New York City who is sent to Las Vegas to supervise the construction of a nightclub that his firm has been hired to build. Alex is a straight-laced WASP-ish type who, while enjoying a night on the town, meets Isabel Fuentes (Salma Hayek), a free-spirited Mexican-American photographer. Alex and Isabel are overtaken by lust at first sight and end up sp  \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For young Parisian boy Antoine Doinel, life is one difficult situation after another. Surrounded by inconsiderate adults, including his neglectful parents, Antoine spends his days with his best friend, Rene, trying to plan for a better life. When one of their schemes goes awry, Antoine ends up in trouble with the law, leading to even more conflicts with unsympathetic authority figures.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "movies_df = pd.read_csv('./the-movies-dataset/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={'genres':\"string\",\"id\":\"string\",\"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\",\n",
    "                                    \"production_companies\" :\"string\"})[[\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"]]\n",
    "movies_df.dropna(inplace = True)\n",
    "movies_lst = [row for row in movies_df.values.tolist() if not (row[0][len(row[0])  - 2:] == \"[]\" or row[5][len(row[5]) - 2:] == \"[]\")]\n",
    "movies_df = pd.DataFrame(movies_lst, columns = (\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"), dtype = str)\n",
    "\n",
    "\n",
    "\n",
    "ratings_df = pd.read_csv('./the-movies-dataset/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"),\n",
    "                       dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})[[\"userId\", \"movieId\", \"rating\"]]\n",
    "ratings_df.rename(columns={\"movieId\": \"id\"}, inplace = True)\n",
    "ratings_df.dropna(inplace = True)\n",
    "\n",
    "\n",
    "# Question: What if the removal of duplicate movie ids per user was processed here instead of the cell below???\n",
    "# Answer: The duplicate removal function can be ran here,...\n",
    "# but the complete_list in the cell below can also be iterated over with relative complexity in order to remove duplicates.\n",
    "# The iteration in the next cell also populates the gap list...\n",
    "# which is critical to be ran directly before the function that determines bounds for users rated movies.\n",
    "# So, omitting the no duplicate function in this cell and making it run in the next cell avoids redundant iteration.\n",
    "\n",
    "\n",
    "# Question: What if the test and train ratings bounds was enforced here instead of the cell below???\n",
    "# Answer: The merge functions below needs to be executed before determining test and train users, because merge will remove rows and ratings from users...\n",
    "# before enforcing the users to be in a certain bounds for the number of their ratings. \n",
    "# The current timing of this function will ensure that the final users are within the set train or test bounds.\n",
    "\n",
    "\n",
    "keywords_df = pd.read_csv('./the-movies-dataset/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})[[\"id\", \"keywords\"]]\n",
    "keywords_df.dropna(inplace = True)\n",
    "keywords_lst = [row for row in keywords_df.values.tolist() if not (row[1][len(row[1])  - 2:] == \"[]\")]\n",
    "keywords_df = pd.DataFrame(keywords_lst, columns = (\"id\", \"keywords\"), dtype = str)\n",
    "\n",
    "\n",
    "credits_df = pd.read_csv(\"./the-movies-dataset/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})[[\"cast\", \"id\"]]\n",
    "credits_df.dropna(inplace = True)\n",
    "credits_lst = [row for row in credits_df.values.tolist() if (not row[0][len(row[0])  - 2:] == \"[]\")]\n",
    "credits_df = pd.DataFrame(credits_lst, columns = (\"cast\", \"id\"), dtype = str)\n",
    "\n",
    "\n",
    "# Default merge is inner: This only keeps movies that have the id existing in both dataframes.\n",
    "complete_df =  pd.merge(movies_df, ratings_df, on =\"id\")\n",
    "complete_df =  pd.merge(complete_df,keywords_df, on =\"id\")\n",
    "complete_df  = pd.merge(complete_df,credits_df, on =\"id\")\n",
    "\n",
    "\n",
    "complete_df.sort_values(by = 'userId', inplace = True)\n",
    "\n",
    "\n",
    "# Master dataframe: For each (user id, movie id) row combination there is the combined movie data from movies_df, ratings_df, keywords_df, and credits_df for the movie id in question.\n",
    "# The columns are reordered.\n",
    "complete_df  = complete_df.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "# For testing:\n",
    "print(\"Minutes taken:\", (time.time()-start_time)/60)\n",
    "print(complete_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Tested on personal machine:\n",
    "# Old run with dataframe iteration (old code): 1 minute and 5.7 seconds\n",
    "# New run with list conversion before iteration (current code): 37.1 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete number of users: 260788\n",
      "met\n",
      "met\n",
      "met\n",
      "Minutes taken: 6.324570655822754\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "SEED_INT = 42\n",
    "# Seed for consistent results across runtimes:\n",
    "random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "def populate_names(item):\n",
    "    \"\"\"Extract names from the syntax of certain data entries:\"\"\"\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    index = 0\n",
    "    for item in jsons:\n",
    "        if(index == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        index += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provide_data(row):\n",
    "    \"\"\"Extract data from row of complete_list:\"\"\"\n",
    "    movie_data = []\n",
    "    movie_data.append(int(row[0]))\n",
    "    movie_data.append(int(row[1]))\n",
    "    movie_data.append(float(row[2]))\n",
    "    movie_data.append(row[3])  \n",
    "\n",
    "    movie_data.append(populate_names(row[4]))\n",
    "    movie_data.append(populate_names(row[5]))\n",
    "    movie_data.append(populate_names(row[6]))\n",
    "    movie_data.append(populate_names(row[7]))\n",
    "\n",
    "    movie_data.append(str(row[8]))\n",
    "    movie_data.append(str(row[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "\n",
    "# The list of rows with users id, the users rating for the movie, and raw data for the movie:\n",
    "# Note: It is sorted by user_id.\n",
    "complete_list = complete_df.values.tolist()\n",
    "\n",
    "print(\"Complete number of users:\", len(list(complete_df[\"userId\"].unique()))) # 260788\n",
    "\n",
    "# The complete list of user rows without ratings of the same movie more than once for a given user:\n",
    "complete_list_no_dups = []\n",
    "\n",
    "# Distinquish the user the row belongs to:\n",
    "last_id = complete_list[0][0]\n",
    "\n",
    "# The set of movies that a user has rated:\n",
    "# It is used to omit later ratings of a movie that the user has already rated.\n",
    "movie_set = set()\n",
    "\n",
    "# The number of rows of movie data a single user takes up for each user:\n",
    "gaps = []\n",
    "\n",
    "# Appended to gaps when all of a users rows of movie data have been counted:\n",
    "gap_len = 0\n",
    "\n",
    "\n",
    "# Populates gaps and complete_list_no_dups by omitting movies that already have a rating in respect to each user:\n",
    "# Note: This code is faster than using dataframe methods.\n",
    "# Example: Filter data by user and then remove duplicate movie ids for each user.\n",
    "# This avoids slow dataframe iteration, but the filter method is also slow.\n",
    "for row in complete_list:\n",
    "    if last_id != row[0]:\n",
    "        movie_set= set()\n",
    "        complete_list_no_dups.append(row)\n",
    "        movie_set.add(row[1])\n",
    "        gaps.append(gap_len)\n",
    "        gap_len = 1\n",
    "    else:\n",
    "        if row[1] not in movie_set:\n",
    "            complete_list_no_dups.append(row)\n",
    "            gap_len+=1\n",
    "            movie_set.add(row[1])\n",
    "    last_id = row[0]\n",
    "\n",
    "# Add the last gap_len:\n",
    "gaps.append(gap_len)\n",
    "\n",
    "\n",
    "\n",
    "full_index = 0 \n",
    "bounds = [] \n",
    "\n",
    "for user_index in range(len(gaps)):\n",
    "    bounds.append([full_index, full_index+gaps[user_index]])\n",
    "    full_index+=gaps[user_index]    \n",
    " \n",
    "\n",
    "\n",
    "#LOOK: rundown of process\n",
    "#LOOK: these are the types of user categories\n",
    "#users that are there only to predict the svd for train and test users\n",
    "#train users\n",
    "#test users\n",
    "\n",
    "#test and train users should have the same range of ratings\n",
    "#svd users should have a different rating range\n",
    "\n",
    "#there are 2 features to train the final model...\n",
    "#against the target ratings of the train users\n",
    "#feature 1: svd prediction from train users\n",
    "#feature 2: average rating for the train users\n",
    "\n",
    "#there are 2 features to test the final model...\n",
    "#against the target ratings of the test users\n",
    "#feature 1: svd prediction from test users\n",
    "#feature 2: average rating for the test users\n",
    "\n",
    "\n",
    "#These set the rating requirements for test and train users.\n",
    "    \n",
    "\n",
    "SVD_USER_RATING_LB = 20\n",
    "SVD_USER_RATING_UB = 30\n",
    "USER_RATING_LB = 5\n",
    "USER_RATING_UB = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(bounds)\n",
    "# no_svd_users = 1000\n",
    "# train_users = 800\n",
    "# test_users = 800\n",
    "no_svd_users = 10000\n",
    "train_users = 10000\n",
    "test_users = 10000\n",
    "\n",
    "\n",
    "last_index = -1\n",
    "bounds_svd_users = []\n",
    "bounds_train_users = []\n",
    "bounds_test_users = []\n",
    "\n",
    "\n",
    "index = 0\n",
    "for item in bounds:\n",
    "    if item[1]-item[0] >=SVD_USER_RATING_LB and item[1]-item[0] <=SVD_USER_RATING_UB:\n",
    "        bounds_svd_users.append(item)\n",
    "        if len(bounds_svd_users) == no_svd_users:\n",
    "            last_index = index\n",
    "            print(\"met\")\n",
    "            break\n",
    "    index+=1\n",
    "\n",
    "\n",
    "\n",
    "index+=1\n",
    "for item in bounds[last_index:]:\n",
    "    if item[1]-item[0] >=USER_RATING_LB and item[1]-item[0] <=USER_RATING_UB:\n",
    "        bounds_train_users.append(item)\n",
    "        if len(bounds_train_users) == train_users:\n",
    "            last_index = index\n",
    "            print(\"met\")\n",
    "            break\n",
    "    index+=1\n",
    "\n",
    "index+=1\n",
    "for item in bounds[last_index:]:\n",
    "    if item[1]-item[0] >=USER_RATING_LB and item[1]-item[0] <=USER_RATING_UB:\n",
    "        bounds_test_users.append(item)\n",
    "        if len(bounds_test_users) == test_users:\n",
    "            print(\"met\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Transformed data of the selected train users and test users (in that order):\n",
    "sampled_data = []\n",
    "\n",
    "\n",
    "for bound in bounds_svd_users:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        sampled_data.append(movie_data)\n",
    "\n",
    "\n",
    "for bound in bounds_train_users:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        sampled_data.append(movie_data)\n",
    "\n",
    "\n",
    "\n",
    "for bound in bounds_test_users:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        sampled_data.append(movie_data)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Minutes taken:\", (time.time()-start_time)/60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, 'constructed_data')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "with open(\"constructed_data/constructed_data_3.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    writer.writerows(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data_3.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nof_svd_users = 1000\n",
    "# nof_train_users = 800\n",
    "nof_svd_users = 10000\n",
    "nof_train_users = 10000\n",
    "\n",
    "user_to_data_svd = []\n",
    "user_to_data_train= []\n",
    "user_to_data_test = []\n",
    "\n",
    "user_id = data_list[0][0]\n",
    "ratings = []\n",
    "user_index = 0\n",
    "\n",
    "\n",
    "\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        if(user_index<nof_svd_users and user_index>=0):\n",
    "            user_to_data_svd.append(ratings)\n",
    "        elif(user_index<nof_svd_users+nof_train_users and user_index>=nof_svd_users):\n",
    "            user_to_data_train.append(ratings)\n",
    "        else:\n",
    "            user_to_data_test.append(ratings)         \n",
    "        user_id = row[0]\n",
    "        ratings = [row]\n",
    "        user_index+=1\n",
    "    else:\n",
    "        ratings.append(row)\n",
    "\n",
    "\n",
    "\n",
    "user_to_data_test.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 295.79 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed parameters rmse score: 1.0423293828964233\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numba import njit\n",
    "import copy\n",
    "from skopt import Optimizer\n",
    "import pandas as pd\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.array as da\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "#test stock model to compare:\n",
    "from surprise import SVD,Dataset,Reader\n",
    "\n",
    "\n",
    "#LOOK: this cell has been developed to test a configuration\n",
    "\n",
    "\n",
    "SEED_INT = 56\n",
    "random.seed(SEED_INT)\n",
    "np.random.seed(SEED_INT)\n",
    "da.random.RandomState(SEED_INT)\n",
    "da.random.default_rng(SEED_INT)\n",
    "da.random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "def funct(block):\n",
    "\n",
    "    SEED_INT = 56\n",
    "    random.seed(SEED_INT)\n",
    "    np.random.seed(SEED_INT)\n",
    "    da.random.RandomState(SEED_INT)\n",
    "    da.random.default_rng(SEED_INT)\n",
    "    da.random.seed(SEED_INT)\n",
    "\n",
    "    total_sum = 0 \n",
    "\n",
    "    for row in block:\n",
    "        user_to_data_svd_temp, user_to_data_train_temp, nof_latent_features, epochs, rt, lr = row\n",
    "\n",
    "\n",
    "        old_to_new_svd  = dict()\n",
    "        last_index_svd = 0\n",
    "        svd_cnt = 0\n",
    "\n",
    "        for user in user_to_data_svd_temp:\n",
    "            for row in user: \n",
    "                if(row[1] in old_to_new_svd.keys()):\n",
    "                    row[1] = old_to_new_svd[row[1]]\n",
    "                else:\n",
    "                    old_to_new_svd[row[1]] = last_index_svd\n",
    "                    row[1] = last_index_svd\n",
    "                    last_index_svd+=1      \n",
    "                row[0] = svd_cnt\n",
    "            svd_cnt+=1\n",
    "\n",
    "\n",
    "        old_to_new_train = copy.deepcopy(old_to_new_svd)\n",
    "        last_index_train = last_index_svd\n",
    "        train_cnt = svd_cnt\n",
    "\n",
    "        for user in user_to_data_train_temp:\n",
    "            for row in user: \n",
    "                if(row[1] in old_to_new_train.keys()):\n",
    "                    row[1] = old_to_new_train[row[1]]\n",
    "                else:\n",
    "                    old_to_new_train[row[1]] = last_index_train\n",
    "                    row[1] = last_index_train\n",
    "                    last_index_train+=1      \n",
    "                row[0] = train_cnt\n",
    "            train_cnt+=1\n",
    "\n",
    "\n",
    "        target_rating_train = []\n",
    "        train_list = []\n",
    "\n",
    "\n",
    "        movies_order_svd = set()\n",
    "        overall_average_svd = 0 \n",
    "        cnt_svd = 0\n",
    "\n",
    "\n",
    "        for user in user_to_data_svd_temp:\n",
    "            for movie in user:\n",
    "                movies_order_svd.add(movie[1])\n",
    "                train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "                overall_average_svd+=float(movie[2])\n",
    "                cnt_svd += 1\n",
    "\n",
    "\n",
    "\n",
    "        movies_order_train = copy.deepcopy(movies_order_svd)\n",
    "        overall_average_train = overall_average_svd \n",
    "        cnt_train = cnt_svd\n",
    "        train_rating_to_predict = []\n",
    "\n",
    "        for user in user_to_data_train_temp:\n",
    "            rand_num  = random.randint(0, len(user)-1)\n",
    "            index = 0\n",
    "            for movie in user:\n",
    "                movies_order_train.add(movie[1])\n",
    "                if(index == rand_num):\n",
    "                    train_rating_to_predict.append([int(movie[0]), int(movie[1])])\n",
    "                    target_rating_train.append(float(movie[2]))\n",
    "                else:\n",
    "                    overall_average_train+=float(movie[2])\n",
    "                    cnt_train += 1\n",
    "                    train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "                index+=1\n",
    "\n",
    "\n",
    "        overall_average_train = overall_average_train/cnt_train\n",
    "\n",
    "\n",
    "        random.shuffle(train_list)\n",
    "\n",
    "\n",
    "        @njit\n",
    "        def epoch(list, b1, b2, p, q, overall_average, lr, rt):\n",
    "            for row in list:\n",
    "                u = int(row[0])\n",
    "                i = int(row[1])\n",
    "                r = row[2]\n",
    "\n",
    "                pred = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "                error = r-pred\n",
    "                b1[u] += lr*(error- rt*b1[u])\n",
    "                b2[i] += lr*(error- rt*b2[i])\n",
    "                temp = lr*(error*q[i] -rt*p[u])\n",
    "                q[i] += lr*(error*p[u] -rt*q[i])\n",
    "                p[u] += temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def svd_iterative(list, n, epochs, rt, lr, overall_average, nof_users, nof_movies):\n",
    "            q = np.random.normal(0, .1, (nof_movies, n))\n",
    "            p = np.random.normal(0, .1, (nof_users, n))\n",
    "\n",
    "            b1 = np.zeros(nof_users)\n",
    "            b2 = np.zeros(nof_movies)\n",
    "\n",
    "            np_array = np.array(list)\n",
    "\n",
    "            for _ in range(epochs):\n",
    "                epoch(np_array, b1, b2, p, q, overall_average, lr, rt)\n",
    "\n",
    "            return b1, b2, p, q\n",
    "\n",
    "\n",
    "        b1, b2, p, q = svd_iterative(train_list, nof_latent_features, epochs, rt, lr,\n",
    "                                    overall_average_train, len(user_to_data_svd_temp)+len(user_to_data_train_temp), len(movies_order_train))\n",
    "\n",
    "        feature_3_train = [overall_average_train + b1[pair[0]]+b2[pair[1]]\n",
    "                                    +np.dot(p[pair[0]],q[pair[1]]) for pair in train_rating_to_predict]\n",
    "    \n",
    "        total_sum+=mean_squared_error(target_rating_train, feature_3_train, squared = False)\n",
    "\n",
    "    return (np.array([[total_sum]], dtype=\"float32\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_sum =0 \n",
    "runs = 80\n",
    "\n",
    "\n",
    "\n",
    "nof_svd_users, nof_train_users, nof_latent_features, epochs, rt, lr = (355, 123, 196, 204, 0.03407177995884917, 0.03668743198104899)\n",
    "\n",
    "\n",
    "#LOOK: this makes this cell slightly inconsistent with the best call in the cell below\n",
    "user_to_data_svd_copy = copy.deepcopy(user_to_data_svd)\n",
    "user_to_data_train_copy = copy.deepcopy(user_to_data_train)\n",
    "\n",
    "\n",
    "# random.shuffle(user_to_data_svd_copy)\n",
    "# random.shuffle(user_to_data_train_copy)\n",
    "\n",
    "\n",
    "# user_to_data_svd_list = [user_to_data_svd_copy[i*nof_svd_users : (i+1)*nof_svd_users] for i in range(runs)]\n",
    "# user_to_data_train_list = [user_to_data_train_copy[i*nof_train_users : (i+1)*nof_train_users] for i in range(runs)]\n",
    "\n",
    "\n",
    "\n",
    "parameters_list = []\n",
    "\n",
    "for _ in range(runs):\n",
    "    parameters_list.append([copy.deepcopy(random.sample(user_to_data_svd_copy, nof_svd_users)),\n",
    "                            copy.deepcopy(random.sample(user_to_data_train_copy, nof_train_users)),\n",
    "                            nof_latent_features, epochs, rt, lr])\n",
    "\n",
    "\n",
    "\n",
    "test = np.array(parameters_list, dtype=\"object\")\n",
    "dask_array = da.from_array(test, chunks=(10,6))\n",
    "results = dask_array.map_blocks(funct, chunks = (1,1), dtype=\"float32\").compute()\n",
    "\n",
    "\n",
    "for row in results:\n",
    "    mse_sum+= row[0]\n",
    "\n",
    "\n",
    "print(\"fixed parameters rmse score:\",mse_sum/runs)\n",
    "\n",
    "\n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "\n",
    "#LOOK: it is possible that random number generation is not needed\n",
    "#After all, the true goal is to make results consistent no matter the seed used\n",
    "\n",
    "\n",
    "# fixed parameters rmse score: 1.053252637386322\n",
    "# fixed parameters rmse score: 1.0423293828964233\n",
    "# inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 279.58 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 283.98 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 286.06 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 286.56 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 267.79 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 270.75 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 278.46 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 278.60 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 273.38 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\distributed\\client.py:3162: UserWarning: Sending large graph of size 262.88 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: x [323, 136, 265, 178, 0.015681081867037996, 0.0481870063690547]\n",
      "Result: y 1.0419336438179017\n",
      "time taken: 16.073787983258566\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numba import njit\n",
    "import copy\n",
    "from skopt import Optimizer\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Dask for parralel computing\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.array as da\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "SEED_INT = 15\n",
    "random.seed(SEED_INT)\n",
    "np.random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "\n",
    "def funct(block):\n",
    "\n",
    "    #LOOK: need to perform operations on the block size which is ten (need a loop)\n",
    "    #user_to_data_svd_temp, user_to_data_train_temp become lists\n",
    "    total_sum = 0 \n",
    "\n",
    "    for row in block:\n",
    "        user_to_data_svd_temp, user_to_data_train_temp, nof_latent_features, epochs, rt, lr = row\n",
    "\n",
    "\n",
    "        old_to_new_svd  = dict()\n",
    "        last_index_svd = 0\n",
    "        svd_cnt = 0\n",
    "\n",
    "        for user in user_to_data_svd_temp:\n",
    "            for row in user: \n",
    "                if(row[1] in old_to_new_svd.keys()):\n",
    "                    row[1] = old_to_new_svd[row[1]]\n",
    "                else:\n",
    "                    old_to_new_svd[row[1]] = last_index_svd\n",
    "                    row[1] = last_index_svd\n",
    "                    last_index_svd+=1      \n",
    "                row[0] = svd_cnt\n",
    "            svd_cnt+=1\n",
    "\n",
    "\n",
    "        old_to_new_train = copy.deepcopy(old_to_new_svd)\n",
    "        last_index_train = last_index_svd\n",
    "        train_cnt = svd_cnt\n",
    "\n",
    "        for user in user_to_data_train_temp:\n",
    "            for row in user: \n",
    "                if(row[1] in old_to_new_train.keys()):\n",
    "                    row[1] = old_to_new_train[row[1]]\n",
    "                else:\n",
    "                    old_to_new_train[row[1]] = last_index_train\n",
    "                    row[1] = last_index_train\n",
    "                    last_index_train+=1      \n",
    "                row[0] = train_cnt\n",
    "            train_cnt+=1\n",
    "\n",
    "        # for ___ in range(5):    \n",
    "        #     print(user_to_data_svd_temp[0][___])\n",
    "        # for ___ in range(5):  \n",
    "        #     print(user_to_data_train_temp[0][___])\n",
    "\n",
    "\n",
    "        target_rating_train = []\n",
    "        train_list = []\n",
    "\n",
    "\n",
    "        movies_order_svd = set()\n",
    "        overall_average_svd = 0 \n",
    "        cnt_svd = 0\n",
    "\n",
    "\n",
    "        for user in user_to_data_svd_temp:\n",
    "            for movie in user:\n",
    "                movies_order_svd.add(movie[1])\n",
    "                train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "                overall_average_svd+=float(movie[2])\n",
    "                cnt_svd += 1\n",
    "\n",
    "\n",
    "\n",
    "        movies_order_train = copy.deepcopy(movies_order_svd)\n",
    "        overall_average_train = overall_average_svd \n",
    "        cnt_train = cnt_svd\n",
    "        train_rating_to_predict = []\n",
    "\n",
    "        for user in user_to_data_train_temp:\n",
    "            #passed\n",
    "            rand_num  = random.randint(0, len(user)-1)\n",
    "            index = 0\n",
    "            for movie in user:\n",
    "                movies_order_train.add(movie[1])\n",
    "                if(index == rand_num):\n",
    "                    train_rating_to_predict.append([int(movie[0]), int(movie[1])])\n",
    "                    target_rating_train.append(float(movie[2]))\n",
    "                else:\n",
    "                    overall_average_train+=float(movie[2])\n",
    "                    cnt_train += 1\n",
    "                    train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "                index+=1\n",
    "\n",
    "\n",
    "        #failed\n",
    "        #note: the user is consistent but the movie isn't\n",
    "                \n",
    "        # for ___ in range(5):  \n",
    "        #     print(train_rating_to_predict[___])\n",
    "\n",
    "        # for ___ in range(5):\n",
    "        #     print(train_list[___])\n",
    "\n",
    "\n",
    "        overall_average_train = overall_average_train/cnt_train\n",
    "\n",
    "\n",
    "        #passed\n",
    "        random.shuffle(train_list)\n",
    "\n",
    "\n",
    "\n",
    "        @njit\n",
    "        def epoch(list, b1, b2, p, q, overall_average, lr, rt):\n",
    "            for row in list:\n",
    "                #conversions needed because numpy array converts to decimal\n",
    "                u = int(row[0])\n",
    "                i = int(row[1])\n",
    "                r = row[2]\n",
    "\n",
    "                pred = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "                error = r-pred\n",
    "                b1[u] += lr*(error- rt*b1[u])\n",
    "                b2[i] += lr*(error- rt*b2[i])\n",
    "                temp = lr*(error*q[i] -rt*p[u])\n",
    "                q[i] += lr*(error*p[u] -rt*q[i])\n",
    "                p[u] += temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def svd_iterative(list, n, epochs, rt, lr, overall_average, nof_users, nof_movies):\n",
    "            #passed\n",
    "            q = np.random.normal(0, .1, (nof_movies, n))\n",
    "            p = np.random.normal(0, .1, (nof_users, n))\n",
    "\n",
    "            b1 = np.zeros(nof_users)\n",
    "            b2 = np.zeros(nof_movies)\n",
    "\n",
    "            np_array = np.array(list)\n",
    "\n",
    "            for _ in range(epochs):\n",
    "                epoch(np_array, b1, b2, p, q, overall_average, lr, rt)\n",
    "\n",
    "            return b1, b2, p, q\n",
    "\n",
    "\n",
    "        #LOOK: potential problem: is len(user_to_data_svd_temp)+len(user_to_data_train_temp) the right legnht of all users\n",
    "        #Answer: yes becasue there no users with only test rating (they at least have 5 ratings total).\n",
    "\n",
    "        b1, b2, p, q = svd_iterative(train_list, nof_latent_features, epochs, rt, lr,\n",
    "                                    overall_average_train, len(user_to_data_svd_temp)+len(user_to_data_train_temp), len(movies_order_train))\n",
    "\n",
    "        #failed:\n",
    "        # print(b1[0:5])\n",
    "        # print(b2[0:5])\n",
    "        # print(q[0][0:5])\n",
    "        # print(p[0][0:5])\n",
    "        # print(train_rating_to_predict[0:5])\n",
    "\n",
    "        #passed: \n",
    "        # print(target_rating_train[0:5])\n",
    "\n",
    "        feature_3_train = [overall_average_train + b1[pair[0]]+b2[pair[1]]\n",
    "                                    +np.dot(p[pair[0]],q[pair[1]]) for pair in train_rating_to_predict]\n",
    "        \n",
    "        #failed:\n",
    "        # print(feature_3_train[0:5])\n",
    "\n",
    "        total_sum+=mean_squared_error(target_rating_train, feature_3_train, squared = False)\n",
    "\n",
    "    return (np.array([[total_sum]], dtype=\"float32\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#external parameters that are not part of the optimization process:\n",
    "#user_to_data_svd\n",
    "#user_to_data_train\n",
    "\n",
    "\n",
    "#very large objective function:\n",
    "def objective_function(vars):\n",
    "    \n",
    "    nof_svd_users, nof_train_users,nof_latent_features, epochs, rt, lr = vars\n",
    "\n",
    "    # rounding here is a mistake:\n",
    "    # nof_svd_users = round(nof_svd_users)\n",
    "    # nof_train_users = round(nof_train_users)\n",
    "    # nof_latent_features = round(nof_latent_features)\n",
    "    # epochs = round(epochs)\n",
    "\n",
    "\n",
    "\n",
    "    #LOOK: How does this integrate into the final model combining multiple features???\n",
    "    # If I were to include the other features this function would take much longer\n",
    "    # current plan: onyl use this fucntion to find teh right parameters \n",
    "    # then test with these parameter for all the features again using....\n",
    "    # random selected users from the overall pool\n",
    "\n",
    "\n",
    "    average_score = 0\n",
    "    runs = 80\n",
    "\n",
    "    #LOOK: At this level parallelzation can be applied since each\n",
    "    #set of variables is temporary besides user_to_data_svd and user_to_data_train\n",
    "\n",
    "    #LOOK: instead of random sampling\n",
    "    #the 10000 train and svd users can be seperated into 20 parts\n",
    "    #so no user gets selected twice\n",
    "    #20 runs should be enough\n",
    "    #may need to shuffle user_to_data_svd and user_to_data_train....\n",
    "    #probably not since the bounds are shuffled in cell 2\n",
    "\n",
    "\n",
    "    user_to_data_svd_copy = copy.deepcopy(user_to_data_svd)\n",
    "    user_to_data_train_copy = copy.deepcopy(user_to_data_train)\n",
    "\n",
    "\n",
    "    # random.shuffle(user_to_data_svd_copy)\n",
    "    # random.shuffle(user_to_data_train_copy)\n",
    "\n",
    "    # user_to_data_svd_list = [user_to_data_svd_copy[i*nof_svd_users : (i+1)*nof_svd_users]for i in range(runs)]\n",
    "    # user_to_data_train_list = [user_to_data_train_copy[i*nof_train_users : (i+1)*nof_train_users] for i in range(runs)]\n",
    "\n",
    "\n",
    "    #LOOK: problem: if the runs is more than 20 then it is possible for some sub ararys in user_to_data_svd_list to not have enough users\n",
    "    #Instead need to try randomly sampling from user_to_data_svd_copy as there will always be enough \n",
    "\n",
    "\n",
    "    #With dask: After using deepcopy, sample from the copies 80 times\n",
    "    #build a dask array with length of 80 (for each sample) (not sure what to do with chunks)\n",
    "    #chunks is used to parallelize the task\n",
    "    #call map_blocks off the array and compute\n",
    "    #extract the results and average them\n",
    "    #need to convert the iteration step into a function\n",
    "\n",
    "\n",
    "    #parameters needed for the fucntion:\n",
    "    #(svd sample, train sample), nof_latent_features, epochs, rt, lr\n",
    "\n",
    "\n",
    "    parameters_list = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        parameters_list.append([random.sample(user_to_data_svd_copy, nof_svd_users),\n",
    "                                random.sample(user_to_data_train_copy, nof_train_users),\n",
    "                                nof_latent_features, epochs, rt, lr])\n",
    "\n",
    "\n",
    "\n",
    "    test = np.array(parameters_list, dtype=\"object\")\n",
    "    dask_array = da.from_array(test, chunks=(10,6))\n",
    "    results = dask_array.map_blocks(funct, chunks = (1,1), dtype=\"float32\").compute()\n",
    "\n",
    "\n",
    "    sum = 0 \n",
    "    for item in results:\n",
    "        sum += item[0]\n",
    "\n",
    "    return sum/runs\n",
    "\n",
    "\n",
    "\n",
    "    # for __ in range(runs):\n",
    "\n",
    "\n",
    "    #     # user_to_data_svd_temp = user_to_data_svd_list[__]\n",
    "    #     # user_to_data_train_temp = user_to_data_train_list[__]\n",
    "\n",
    "\n",
    "    #     user_to_data_svd_temp  = random.sample(user_to_data_svd_copy, nof_svd_users)\n",
    "    #     user_to_data_train_temp  = random.sample(user_to_data_train_copy, nof_train_users)    \n",
    "\n",
    "\n",
    "    #     old_to_new_svd  = dict()\n",
    "    #     last_index_svd = 0\n",
    "    #     svd_cnt = 0\n",
    "\n",
    "    #     for user in user_to_data_svd_temp:\n",
    "    #         for row in user: \n",
    "    #             if(row[1] in old_to_new_svd.keys()):\n",
    "    #                 row[1] = old_to_new_svd[row[1]]\n",
    "    #             else:\n",
    "    #                 old_to_new_svd[row[1]] = last_index_svd\n",
    "    #                 row[1] = last_index_svd\n",
    "    #                 last_index_svd+=1      \n",
    "    #             row[0] = svd_cnt\n",
    "    #         svd_cnt+=1\n",
    "\n",
    "\n",
    "    #     old_to_new_train = copy.deepcopy(old_to_new_svd)\n",
    "    #     last_index_train = last_index_svd\n",
    "    #     train_cnt = svd_cnt\n",
    "\n",
    "    #     for user in user_to_data_train_temp:\n",
    "    #         for row in user: \n",
    "    #             if(row[1] in old_to_new_train.keys()):\n",
    "    #                 row[1] = old_to_new_train[row[1]]\n",
    "    #             else:\n",
    "    #                 old_to_new_train[row[1]] = last_index_train\n",
    "    #                 row[1] = last_index_train\n",
    "    #                 last_index_train+=1      \n",
    "    #             row[0] = train_cnt\n",
    "    #         train_cnt+=1\n",
    "\n",
    "    #     # for ___ in range(5):    \n",
    "    #     #     print(user_to_data_svd_temp[0][___])\n",
    "    #     # for ___ in range(5):  \n",
    "    #     #     print(user_to_data_train_temp[0][___])\n",
    "\n",
    "\n",
    "    #     target_rating_train = []\n",
    "    #     train_list = []\n",
    "\n",
    "\n",
    "    #     movies_order_svd = set()\n",
    "    #     overall_average_svd = 0 \n",
    "    #     cnt_svd = 0\n",
    "\n",
    "\n",
    "    #     for user in user_to_data_svd_temp:\n",
    "    #         for movie in user:\n",
    "    #             movies_order_svd.add(movie[1])\n",
    "    #             train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "    #             overall_average_svd+=float(movie[2])\n",
    "    #             cnt_svd += 1\n",
    "\n",
    "\n",
    "\n",
    "    #     movies_order_train = copy.deepcopy(movies_order_svd)\n",
    "    #     overall_average_train = overall_average_svd \n",
    "    #     cnt_train = cnt_svd\n",
    "    #     train_rating_to_predict = []\n",
    "\n",
    "    #     for user in user_to_data_train_temp:\n",
    "    #         #passed\n",
    "    #         rand_num  = random.randint(0, len(user)-1)\n",
    "    #         index = 0\n",
    "    #         for movie in user:\n",
    "    #             movies_order_train.add(movie[1])\n",
    "    #             if(index == rand_num):\n",
    "    #                 train_rating_to_predict.append([int(movie[0]), int(movie[1])])\n",
    "    #                 target_rating_train.append(float(movie[2]))\n",
    "    #             else:\n",
    "    #                 overall_average_train+=float(movie[2])\n",
    "    #                 cnt_train += 1\n",
    "    #                 train_list.append([int(movie[0]), int(movie[1]), float(movie[2])])\n",
    "    #             index+=1\n",
    "\n",
    "\n",
    "    #     #failed\n",
    "    #     #note: the user is consistent but the movie isn't\n",
    "                \n",
    "    #     # for ___ in range(5):  \n",
    "    #     #     print(train_rating_to_predict[___])\n",
    "\n",
    "    #     # for ___ in range(5):\n",
    "    #     #     print(train_list[___])\n",
    "\n",
    "\n",
    "    #     overall_average_train = overall_average_train/cnt_train\n",
    "\n",
    "\n",
    "    #     #passed\n",
    "    #     random.shuffle(train_list)\n",
    "\n",
    "\n",
    "\n",
    "    #     @njit\n",
    "    #     def epoch(list, b1, b2, p, q, overall_average, lr, rt):\n",
    "    #         for row in list:\n",
    "    #             #conversions needed because numpy array converts to decimal\n",
    "    #             u = int(row[0])\n",
    "    #             i = int(row[1])\n",
    "    #             r = row[2]\n",
    "\n",
    "    #             pred = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "    #             error = r-pred\n",
    "    #             b1[u] += lr*(error- rt*b1[u])\n",
    "    #             b2[i] += lr*(error- rt*b2[i])\n",
    "    #             temp = lr*(error*q[i] -rt*p[u])\n",
    "    #             q[i] += lr*(error*p[u] -rt*q[i])\n",
    "    #             p[u] += temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #     def svd_iterative(list, n, epochs, rt, lr, overall_average, nof_users, nof_movies):\n",
    "    #         #passed\n",
    "    #         q = np.random.normal(0, .1, (nof_movies, n))\n",
    "    #         p = np.random.normal(0, .1, (nof_users, n))\n",
    "\n",
    "    #         b1 = np.zeros(nof_users)\n",
    "    #         b2 = np.zeros(nof_movies)\n",
    "\n",
    "    #         np_array = np.array(list)\n",
    "\n",
    "    #         for _ in range(epochs):\n",
    "    #             epoch(np_array, b1, b2, p, q, overall_average, lr, rt)\n",
    "\n",
    "    #         return b1, b2, p, q\n",
    "\n",
    "\n",
    "    #     #LOOK: potential problem: is len(user_to_data_svd_temp)+len(user_to_data_train_temp) the right legnht of all users\n",
    "    #     #Answer: yes becasue there no users with only test rating (they at least have 5 ratings total).\n",
    "\n",
    "    #     b1, b2, p, q = svd_iterative(train_list, nof_latent_features, epochs, rt, lr,\n",
    "    #                                 overall_average_train, len(user_to_data_svd_temp)+len(user_to_data_train_temp), len(movies_order_train))\n",
    "\n",
    "    #     #failed:\n",
    "    #     # print(b1[0:5])\n",
    "    #     # print(b2[0:5])\n",
    "    #     # print(q[0][0:5])\n",
    "    #     # print(p[0][0:5])\n",
    "    #     # print(train_rating_to_predict[0:5])\n",
    "\n",
    "    #     #passed: \n",
    "    #     # print(target_rating_train[0:5])\n",
    "\n",
    "    #     feature_3_train = [overall_average_train + b1[pair[0]]+b2[pair[1]]\n",
    "    #                                 +np.dot(p[pair[0]],q[pair[1]]) for pair in train_rating_to_predict]\n",
    "        \n",
    "    #     #failed:\n",
    "    #     # print(feature_3_train[0:5])\n",
    "\n",
    "    #     average_score += mean_squared_error(target_rating_train, feature_3_train, squared = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bayesian_optimization(bounds, iterations):\n",
    "\n",
    "    #presets\n",
    "    #LOOK: what is the number of jobs???\n",
    "    #try modifying n_initial_points and n_jobs....\n",
    "    #LOOK closely at the optimize function\n",
    "\n",
    "    optimizer = Optimizer(\n",
    "        dimensions=bounds,\n",
    "        base_estimator=\"gp\",\n",
    "        # try setting higher values here...\n",
    "        # 10 already tested\n",
    "        n_initial_points = 10,\n",
    "        acq_func=\"EI\",\n",
    "        acq_optimizer=\"sampling\",\n",
    "        random_state=SEED_INT\n",
    "    )\n",
    "\n",
    "\n",
    "    #reproducable: \n",
    "    # X_init =[np.random.uniform(item[0], item[1]) for item in bounds]\n",
    "    X_init = [(item[0] + item[1])/2.0 for item in bounds]\n",
    "\n",
    "\n",
    "    for i in range(4):\n",
    "        X_init[i] = round(X_init[i])\n",
    "\n",
    "    #Not reproducable:\n",
    "    Y_init = objective_function(X_init)\n",
    "\n",
    "\n",
    "    optimizer.tell(X_init, Y_init)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x_next = optimizer.ask()\n",
    "        for i in range(4):\n",
    "            x_next[i] = round(x_next[i])\n",
    "        y_next = objective_function(x_next)\n",
    "        optimizer.tell(x_next, y_next)\n",
    "\n",
    "    #LOOK: does the optimizer shoot for the min or the max?\n",
    "    #gpt: the goal is to minimize the obejective function...\n",
    "\n",
    "    sorted_pairs = sorted(zip(optimizer.Xi, optimizer.yi), key = lambda pair : pair[1], reverse=False)\n",
    "\n",
    "\n",
    "    X = sorted_pairs[0][0]\n",
    "    y = sorted_pairs[0][1]\n",
    "\n",
    " \n",
    "    for i in range(5):\n",
    "        print(sorted_pairs[i][0])\n",
    "        print(sorted_pairs[i][1])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "#of_svd_users, nof_train_users,\n",
    "# nof_latent_features, epochs, rt, lr\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.space import Integer\n",
    "\n",
    "# bounds = [(200.0, 700.0),(100.0, 600.0),(10.0,200.0),(10.0,300.0),(.01, .05),(.001, .05)]\n",
    "# nof_svd_users, nof_train_users,nof_latent_features, epochs, rt, lr\n",
    "\n",
    "mid_points = [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "\n",
    "mid_points = [(lambda pair : int((pair[0]+pair[1])/2) if((pair[0]+pair[1])/2==int((pair[0]+pair[1])/2)) else (pair[0]+pair[1])/2)(item) for item in mid_points]\n",
    "\n",
    "\n",
    "bounds = [Integer(300, 500, name = 'nof_svd_users'),Integer(100, 200, name = 'nof_train_users'),\n",
    "          Integer(100,300, name = 'nof_latent_features'),Integer(100,400, name = 'epochs'),\n",
    "          Real(.01, .075, name = 'rt'),Real(.001, .05, name = 'lr')]\n",
    "\n",
    "\n",
    "# LOOK: This is the custom made baysian opt\n",
    "# X, y = bayesian_optimization(bounds, 5)\n",
    "\n",
    "\n",
    "#LOOK: is ther another way???\n",
    "#LOOK: numpy version downgraded to verison 1.23.5 to support usage of np.int in built in functions...\n",
    "# https://github.com/WongKinYiu/yolov7/issues/1280\n",
    "#avoids having ot use (np.int = int)\n",
    "\n",
    "\n",
    "# https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html\n",
    "# https://scikit-optimize.github.io/stable/modules/generated/skopt.gp_minimize.html#skopt.gp_minimize\n",
    "\n",
    "# This is currently not typical baysian optimization:\n",
    "# LOOK: try to use baysian optmization as applied in the above link\n",
    "\n",
    "#LOOK: Why does n_calls need to be equal to or larger than n_initial points\n",
    "res = gp_minimize(objective_function,                 \n",
    "                  bounds,      \n",
    "                  n_calls=10, \n",
    "                  n_initial_points = 9,    \n",
    "                  # n_initial_points = 10, \n",
    "                  x0 = mid_points,    \n",
    "                  random_state= SEED_INT,\n",
    "                  n_points = 10000,\n",
    "                  )\n",
    "\n",
    "\n",
    "print(\"Solution: x\", res.x)\n",
    "print(\"Result: y\", res.fun)\n",
    "print(\"time taken:\", (time.time()-start)/60)\n",
    "\n",
    "\n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: need to try starting at the midpoint value for bounds instead of randomly selecting the starting point\n",
    "\n",
    "#LOOK: need to compare to stock svd suprise algorithm\n",
    "\n",
    "#LOOK: what is the number of jobs???\n",
    "#try modifying n_initial_points and n_jobs....\n",
    "\n",
    "\n",
    "#LOOK: Question: What is the issue with keeping the seeds that perfrom the best to use with the actual model\n",
    "#just because they perform well with a certain seed doesn mean it will perfrom well with completely new random data\n",
    "#the point of the model is to generalize to new data, not learn the data it has access to.\n",
    "#LOOK: Potential solution: Need to test the trained model on more chunks of data before evaluation\n",
    "#LOOK: In training, the initial model params partly determine by random chance (the seed)\n",
    "#need to test multple initial conditions with the same hyperparamters that need to be tuned \n",
    "\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 5\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# no shuffle\n",
    "# random init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [490, 114, 265, 100, 0.075, 0.003306356733754837]\n",
    "# Result: y 1.008934000606866\n",
    "# time taken: 14.760872900485992\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 5\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# shuffle\n",
    "# random init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [359, 105, 159, 322, 0.019187838615362548, 0.02148636162678124]\n",
    "# Result: y 1.0268730779416964\n",
    "# time taken: 15.03641388018926\n",
    "\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 5\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [491, 107, 100, 398, 0.06854948616872057, 0.02732078900650637]\n",
    "# Result: y 1.0097142989582657\n",
    "# time taken: 22.572298232714335\n",
    "\n",
    "#****\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 5\n",
    "# calls = 20\n",
    "# runs = 40\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 10\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# no shuffle\n",
    "# random init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [408, 113, 183, 334, 0.047953588767488946, 0.009948940378798735]\n",
    "# Result: y 0.998127063254195\n",
    "# time taken: 15.871690555413563\n",
    "\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 10\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# shuffle\n",
    "# random init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [419, 144, 171, 276, 0.019715636904085565, 0.009390691312187987]\n",
    "# Result: y 1.0273296521578534\n",
    "# time taken: 16.87793436050415\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 10\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [442, 127, 153, 145, 0.05444819790848023, 0.04101348992581268]\n",
    "# Result: y 1.0108166741898796\n",
    "# time taken: 18.037524509429932\n",
    "\n",
    "#****\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 10\n",
    "# calls = 20\n",
    "# runs = 40\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# no shuffle\n",
    "# random init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [463, 159, 122, 346, 0.07023178357221199, 0.0022226985841246414]\n",
    "# Result: y 1.013064110433222\n",
    "# time taken: 17.710401757558188\n",
    "\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# shuffle\n",
    "# random init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [410, 198, 184, 350, 0.05588458182689485, 0.03895764265158545]\n",
    "# Result: y 1.0295537903652323\n",
    "# time taken: 21.355472441514333\n",
    "\n",
    "\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 20\n",
    "# runs = 20\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [387, 183, 259, 380, 0.05996516467807905, 0.013017812396446948]\n",
    "# Result: y 1.0126191620694736\n",
    "# time taken: 27.12620999018351\n",
    "\n",
    "#****\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 20\n",
    "# runs = 40\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [437, 100, 169, 189, 0.016322398571097588, 0.024221960056937827]\n",
    "# Result: y 1.0389433334175275\n",
    "# time taken: 37.2435434738795\n",
    "\n",
    "\n",
    "#********\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 10\n",
    "# runs = 80\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [355, 123, 196, 204, 0.03407177995884917, 0.03668743198104899]\n",
    "# Result: y 1.084261420345655\n",
    "# time taken: 37.630781781673434\n",
    "\n",
    "#(2 blocks)\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 10\n",
    "# runs = 80\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [355, 123, 196, 204, 0.03407177995884917, 0.03668743198104899]\n",
    "# Result: y 1.0563209533691407\n",
    "# time taken: 23.191765848795573\n",
    "\n",
    "#(8 blocks) (inconsistent)\n",
    "# upperseed = 42\n",
    "# svd bounds: 20-30\n",
    "# trainbounds: 5-10\n",
    "# 10000 svd pool, 10000 train pool\n",
    "# seed = 15\n",
    "# calls = 10\n",
    "# runs = 80\n",
    "# shuffle\n",
    "# middle init\n",
    "# [(300, 500),(100, 200),(100,300),(100,400),(.01, .075),(.001, .05)]\n",
    "# Solution: x [323, 136, 265, 178, 0.015681081867037996, 0.0481870063690547]\n",
    "# Result: y 1.0332631111145019\n",
    "# time taken: 15.885440341631572\n",
    "\n",
    "# Solution: x [323, 136, 265, 178, 0.015681081867037996, 0.0481870063690547]\n",
    "# Result: y 1.0419336438179017\n",
    "# time taken: 16.073787983258566\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
