{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data source\n",
    "\n",
    "* Download the data needed for this jupyter notebook from kaggle and store it in a new folder (the-movies-dataset) in the current directory.\n",
    "\n",
    "\n",
    "* Upon running this cell, the user will be asked for their username and key which can be found in a fresh api token from kaggle.\n",
    "\n",
    "* Instructions to get api token to authenticate the data request (Note: kaggle account required):\n",
    "    1. Sign into kaggle.\n",
    "    2. Go to the 'Account' tab of your user profile and select 'Create New Token'. \n",
    "    3. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
    "\n",
    "* If the folder has been created and the files are already in that folder, than this cell does nothing and requires no credentials.\n",
    "\n",
    "* Data Source Information: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?select=movies_metadata.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:Downloading the-movies-dataset.zip to ./the-movies-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228M/228M [00:23<00:00, 10.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Raw Data\n",
    "\n",
    "Combining certain data from the necessary csv files into a single dataframe (complete_df).\n",
    "\n",
    "* Rows are removed from each dataframe when they do not have sufficent data for a column or the data from a column does not exist.\n",
    "* This kind of row removal is done before multiple copies of the same movie data becomes present in multple rows, to save time and space.\n",
    "* Iteration through rows of a dataframe at this level is inefficient compared to list iteration.\n",
    "* This is why the dataframes are converted into lists before iteration and then back again to dataframes, so the merge function can be applied to combine the data into a single dataframe (complete_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes taken: 0.6275500257809957\n",
      "        userId    id rating               title  \\\n",
      "6566765      1  1246    5.0        Rocky Balboa   \n",
      "6880303      1  2959    4.0      License to Wed   \n",
      "2083077      1  2762    4.5  Young and Innocent   \n",
      "1492304      1  1968    4.0       Fools Rush In   \n",
      "2638962      1   147    4.5       The 400 Blows   \n",
      "\n",
      "                                                                                                genres  \\\n",
      "6566765                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "6880303                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "2083077                                     [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name': 'Crime'}]   \n",
      "1492304  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "2638962                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                production_companies  \\\n",
      "6566765                                                                                                  [{'name': 'Columbia Pictures', 'id': 5}, {'name': 'Revolution Studios', 'id': 497}, {'name': 'Rogue Marble', 'id': 696}, {'name': 'Metro-Goldwyn-Mayer (MGM)', 'id': 8411}]   \n",
      "6880303  [{'name': 'Village Roadshow Pictures', 'id': 79}, {'name': 'Robert Simonds Productions', 'id': 3929}, {'name': 'Warner Bros.', 'id': 6194}, {'name': 'Phoenix Pictures', 'id': 11317}, {'name': 'Underground', 'id': 49326}, {'name': 'Proposal Productions', 'id': 49327}]   \n",
      "2083077                                                                                                                                                                                                                [{'name': 'Gaumont British Picture Corporation', 'id': 4978}]   \n",
      "1492304                                                                                                                                                                                                                                     [{'name': 'Columbia Pictures', 'id': 5}]   \n",
      "2638962                                                                                                                                 [{'name': 'Les Films du Carrosse', 'id': 53}, {'name': 'Sédif Productions', 'id': 10897}, {'name': 'The Criterion Collection', 'id': 10932}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
      "6566765  [{'id': 276, 'name': 'philadelphia'}, {'id': 396, 'name': 'transporter'}, {'id': 1721, 'name': 'fight'}, {'id': 2038, 'name': \"love of one's life\"}, {'id': 2416, 'name': 'publicity'}, {'id': 2792, 'name': 'boxer'}, {'id': 2968, 'name': 'grave'}, {'id': 3393, 'name': 'tombstone'}, {'id': 3586, 'name': 'tv station'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5167, 'name': 'restaurant owner'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5380, 'name': 'virtual fight'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 10163, 'name': 'cancer'}, {'id': 155464, 'name': 'over-the-hill fighter'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                             [{'id': 1605, 'name': 'new love'}, {'id': 2856, 'name': 'ten commandments'}, {'id': 3582, 'name': 'bride'}, {'id': 3583, 'name': 'bridegroom'}, {'id': 6038, 'name': 'marriage'}, {'id': 6192, 'name': 'relation'}, {'id': 6281, 'name': 'partnership'}, {'id': 6704, 'name': 'civil registry office'}, {'id': 10093, 'name': 'priest'}, {'id': 13027, 'name': 'wedding'}, {'id': 14765, 'name': 'church'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'id': 769, 'name': 'falsely accused'}, {'id': 1655, 'name': 'country house'}, {'id': 9826, 'name': 'murder'}, {'id': 9937, 'name': 'suspense'}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'id': 828, 'name': 'waitress'}, {'id': 1463, 'name': 'culture clash'}, {'id': 9799, 'name': 'romantic comedy'}, {'id': 13149, 'name': 'pregnancy'}]   \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                      [{'id': 6930, 'name': 'fondling'}, {'id': 10183, 'name': 'independent film'}, {'id': 155518, 'name': 'nouvelle vague'}, {'id': 170268, 'name': 'skipping school'}, {'id': 170272, 'name': 'mise en scene'}, {'id': 170273, 'name': 'fingerprinting'}, {'id': 170279, 'name': '\\xa0mugshot'}, {'id': 170286, 'name': 'strict teacher'}, {'id': 170293, 'name': 'montmartre paris'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        cast  \\\n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'cast_id': 24, 'character': 'Rocky Balboa', 'credit_id': '52fe42e9c3a36847f802c61b', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 25, 'character': 'Paulie', 'credit_id': '52fe42e9c3a36847f802c61f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 1, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 26, 'character': 'Rocky Jr.', 'credit_id': '52fe42e9c3a36847f802c623', 'gender': 2, 'id': 16501, 'name': 'Milo Ventimiglia', 'order': 2, 'profile_path': '/maJeS6bA6ku21rSRceISQtwHL2h.jpg'}, {'cast_id': 27, 'character': 'Marie', 'credit_id': '52fe42e9c3a36847f802c627', 'gender': 1, 'id': 16502, 'name': 'Geraldine Hughes', 'order': 3, 'profile_path': '/bTXux3EJq25Fh2ixbet6MjdG3Fb.jpg'}, {'cast_id': 28, 'character': 'Steps', 'credit_id': '52fe42e9c3a36847f802c62b', 'gender': 2, 'id': 16503, 'name': 'James Francis Kelly III', 'order': 4, 'profile_path': '/iZyTQ2UlwNXrqLqPeNHbofFXubP.jpg'}, {'cast_id': 29, 'character': 'Duke', 'credit_id': '52fe42e9c3a36847f802c62f', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 30, 'character': 'L.C.', 'credit_id': '52fe42e9c3a36847f802c633', 'gender': 2, 'id': 16505, 'name': 'A. J. Benza', 'order': 6, 'profile_path': '/5hVinC6C1ZyD7c8EmZFTiEaF7vH.jpg'}, {'cast_id': 31, 'character': 'Adrian', 'credit_id': '52fe42e9c3a36847f802c637', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 7, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 32, 'character': 'Martin', 'credit_id': '52fe42e9c3a36847f802c63b', 'gender': 2, 'id': 16506, 'name': 'Henry G. Sanders', 'order': 8, 'profile_path': '/2SU75g2CAIzGWbgfIlNvKZQhYTZ.jpg'}, {'cast_id': 33, 'character': \"Mason 'The Line' Dixon\", 'credit_id': '52fe42e9c3a36847f802c63f', 'gender': 2, 'id': 16507, 'name': 'Antonio Tarver', 'order': 9, 'profile_path': '/kJEljjHwBvrjoxqcSVntXlejgl1.jpg'}, {'cast_id': 34, 'character': 'Spider Rico', 'credit_id': '52fe42e9c3a36847f802c643', 'gender': 2, 'id': 16508, 'name': 'Pedro Lovell', 'order': 10, 'profile_path': None}, {'cast_id': 35, 'character': 'Isabel', 'credit_id': '52fe42e9c3a36847f802c647', 'gender': 1, 'id': 16509, 'name': 'Ana Gerena', 'order': 11, 'profile_path': None}, {'cast_id': 36, 'character': 'Angie', 'credit_id': '52fe42e9c3a36847f802c64b', 'gender': 1, 'id': 16510, 'name': 'Angela Boyd', 'order': 12, 'profile_path': None}, {'cast_id': 37, 'character': 'Bar Thug', 'credit_id': '52fe42e9c3a36847f802c64f', 'gender': 0, 'id': 16511, 'name': 'Louis Giansante', 'order': 13, 'profile_path': None}, {'cast_id': 38, 'character': \"Lucky's Bartender\", 'credit_id': '52fe42e9c3a36847f802c653', 'gender': 0, 'id': 16512, 'name': 'Maureen Schilling', 'order': 14, 'profile_path': None}, {'cast_id': 40, 'character': 'X-Cell', 'credit_id': '5761db05c3a3682f20000302', 'gender': 2, 'id': 98298, 'name': 'Lahmard J. Tate', 'order': 15, 'profile_path': '/4WcFReePSxyGQJWV5wXGNfY0Y7o.jpg'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'cast_id': 18, 'character': 'Reverend Frank', 'credit_id': '52fe4376c3a36847f8056039', 'gender': 2, 'id': 2157, 'name': 'Robin Williams', 'order': 0, 'profile_path': '/sojtJyIV3lkUeThD7A2oHNm8183.jpg'}, {'cast_id': 19, 'character': 'Sadie Jones', 'credit_id': '52fe4376c3a36847f805603d', 'gender': 1, 'id': 16855, 'name': 'Mandy Moore', 'order': 1, 'profile_path': '/15sDtRpe301tZWrRYV31wjMuFpx.jpg'}, {'cast_id': 20, 'character': 'Ben Murphy', 'credit_id': '52fe4376c3a36847f8056041', 'gender': 2, 'id': 17697, 'name': 'John Krasinski', 'order': 2, 'profile_path': '/nOWwdZURikW22qo6OUSGFCTukgc.jpg'}, {'cast_id': 21, 'character': 'Carlisle', 'credit_id': '52fe4376c3a36847f8056045', 'gender': 2, 'id': 29020, 'name': 'Eric Christian Olsen', 'order': 3, 'profile_path': '/clbouet8o9IJlUd8WILD0lzHAtG.jpg'}, {'cast_id': 22, 'character': 'Lindsey Jones', 'credit_id': '52fe4376c3a36847f8056049', 'gender': 1, 'id': 15286, 'name': 'Christine Taylor', 'order': 4, 'profile_path': '/99OssnGmgGjduXFA7syxjNqt9tQ.jpg'}, {'cast_id': 23, 'character': 'Choir Boy', 'credit_id': '52fe4376c3a36847f805604d', 'gender': 2, 'id': 216, 'name': 'Josh Flitter', 'order': 5, 'profile_path': '/6RCA8tDWBxIVk9N3IqUjJEAzYGv.jpg'}, {'cast_id': 24, 'character': 'Joel', 'credit_id': '52fe4376c3a36847f8056051', 'gender': 2, 'id': 11827, 'name': 'DeRay Davis', 'order': 6, 'profile_path': '/w2JYPRLwXhNCpxpJc2v4UQYyMv8.jpg'}, {'cast_id': 25, 'character': 'Mr. Jones', 'credit_id': '52fe4376c3a36847f8056055', 'gender': 2, 'id': 21368, 'name': 'Peter Strauss', 'order': 7, 'profile_path': '/ufx1trct43k7UcT4DpoIMPZXi5A.jpg'}, {'cast_id': 26, 'character': 'Grandma Jones', 'credit_id': '52fe4376c3a36847f8056059', 'gender': 1, 'id': 6465, 'name': 'Grace Zabriskie', 'order': 8, 'profile_path': '/ibBabuSM1UyPYFFo0wBXhGbqElk.jpg'}, {'cast_id': 27, 'character': 'Mrs. Jones', 'credit_id': '52fe4376c3a36847f805605d', 'gender': 1, 'id': 29021, 'name': 'Roxanne Hart', 'order': 9, 'profile_path': '/yWGMW6HdhUGT2oIcQ4jmnkw7ZAM.jpg'}, {'cast_id': 28, 'character': 'Shelly', 'credit_id': '5586ee469251417f6f0059c8', 'gender': 1, 'id': 125167, 'name': 'Mindy Kaling', 'order': 10, 'profile_path': '/Agpd4tJyZ95hk74RifjnfnJpn9U.jpg'}, {'cast_id': 30, 'character': 'Expectant Father', 'credit_id': '56c3467cc3a36847c5001f66', 'gender': 2, 'id': 1368801, 'name': 'David Quinlan', 'order': 11, 'profile_path': '/2m75rrBhvOTtdUS9jlKW8GOHCBV.jpg'}, {'cast_id': 31, 'character': 'Judith', 'credit_id': '58e26093c3a36872f600dcf2', 'gender': 1, 'id': 113867, 'name': 'Angela Kinsey', 'order': 12, 'profile_path': '/omLdRLdwMLliVeVIualEnWVhm1a.jpg'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'cast_id': 18, 'character': 'Erica Burgoyne', 'credit_id': '52fe436bc3a36847f8052cd5', 'gender': 1, 'id': 27939, 'name': 'Nova Pilbeam', 'order': 0, 'profile_path': '/l6oHJaRYrVxsvoTSmMS5wIXaei5.jpg'}, {'cast_id': 19, 'character': 'Robert Tisdall', 'credit_id': '52fe436bc3a36847f8052cd9', 'gender': 0, 'id': 27940, 'name': 'Derrick De Marney', 'order': 1, 'profile_path': '/7VRZ7K0EZ50haOlbVr7DHZ5550O.jpg'}, {'cast_id': 20, 'character': 'Col. Burgoyne', 'credit_id': '52fe436bc3a36847f8052cdd', 'gender': 2, 'id': 27929, 'name': 'Percy Marmont', 'order': 2, 'profile_path': '/p3DIyvlxx6B0SVIxcDaPUPlEV0U.jpg'}, {'cast_id': 21, 'character': 'Old Will', 'credit_id': '52fe436bc3a36847f8052ce1', 'gender': 2, 'id': 27941, 'name': 'Edward Rigby', 'order': 3, 'profile_path': '/B7GJ0jPtODqZVgVtZHPtvZl2tO.jpg'}, {'cast_id': 22, 'character': 'Ericas Tante Margaret', 'credit_id': '52fe436bc3a36847f8052ce5', 'gender': 1, 'id': 14304, 'name': 'Mary Clare', 'order': 4, 'profile_path': '/lAdEwCGiSUj9CCMPB4L9X4oujLe.jpg'}, {'cast_id': 23, 'character': 'Det. Insp. Kent', 'credit_id': '52fe436bc3a36847f8052ce9', 'gender': 2, 'id': 7383, 'name': 'John Longden', 'order': 5, 'profile_path': '/rsCoUEx2ThNIz12fBR6vPncCICk.jpg'}, {'cast_id': 24, 'character': 'Guy', 'credit_id': '52fe436bc3a36847f8052ced', 'gender': 2, 'id': 27942, 'name': 'George Curzon', 'order': 6, 'profile_path': None}, {'cast_id': 25, 'character': 'Ericas Onkel Basil', 'credit_id': '52fe436bc3a36847f8052cf1', 'gender': 2, 'id': 14303, 'name': 'Basil Radford', 'order': 7, 'profile_path': '/9STo7Tgdutplo78ZtyeINGWkXUk.jpg'}, {'cast_id': 26, 'character': 'Christine Clay', 'credit_id': '52fe436bc3a36847f8052cf5', 'gender': 1, 'id': 27943, 'name': 'Pamela Carme', 'order': 8, 'profile_path': None}, {'cast_id': 27, 'character': 'Detective Sergeant Miller', 'credit_id': '52fe436bc3a36847f8052cf9', 'gender': 2, 'id': 27944, 'name': 'George Merritt', 'order': 9, 'profile_path': None}, {'cast_id': 28, 'character': 'Henry Briggs', 'credit_id': '52fe436bc3a36847f8052cfd', 'gender': 2, 'id': 27945, 'name': 'J.H. Roberts', 'order': 10, 'profile_path': None}, {'cast_id': 29, 'character': \"Truckfahrer bei Tom's Hat\", 'credit_id': '52fe436bc3a36847f8052d01', 'gender': 2, 'id': 27946, 'name': 'Jerry Verno', 'order': 11, 'profile_path': None}, {'cast_id': 30, 'character': 'Police Sergeant Ruddock', 'credit_id': '52fe436bc3a36847f8052d05', 'gender': 2, 'id': 27947, 'name': 'H.F. Maltby', 'order': 12, 'profile_path': None}, {'cast_id': 31, 'character': 'Police Constable', 'credit_id': '52fe436bc3a36847f8052d09', 'gender': 2, 'id': 27948, 'name': 'John Miller', 'order': 13, 'profile_path': None}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'cast_id': 2, 'character': 'Alex Whitman', 'credit_id': '52fe4327c3a36847f803e629', 'gender': 2, 'id': 14408, 'name': 'Matthew Perry', 'order': 0, 'profile_path': '/oSKEEDXDNnwWdQ68qfDVD6Q7Pxp.jpg'}, {'cast_id': 3, 'character': 'Isabel Fuentes', 'credit_id': '52fe4327c3a36847f803e62d', 'gender': 1, 'id': 3136, 'name': 'Salma Hayek', 'order': 1, 'profile_path': '/u5mg73xKVqm8oT93HoMmsgQHyoK.jpg'}, {'cast_id': 4, 'character': 'Jeff', 'credit_id': '52fe4327c3a36847f803e631', 'gender': 2, 'id': 4602, 'name': 'Jon Tenney', 'order': 2, 'profile_path': '/fiG1bW6DX1szsRDPIYjfIKPQ0kV.jpg'}, {'cast_id': 5, 'character': 'Lanie', 'credit_id': '52fe4327c3a36847f803e635', 'gender': 1, 'id': 6751, 'name': 'Siobhan Fallon', 'order': 3, 'profile_path': '/wVFa8GiY0xdOLFsvGygy9RMtcBc.jpg'}, {'cast_id': 16, 'character': 'Great Grandma', 'credit_id': '52fe4327c3a36847f803e675', 'gender': 1, 'id': 20360, 'name': 'Angelina Torres', 'order': 4, 'profile_path': None}, {'cast_id': 17, 'character': 'Richard Whitman', 'credit_id': '52fe4327c3a36847f803e679', 'gender': 2, 'id': 20361, 'name': 'John Bennett Perry', 'order': 5, 'profile_path': '/bzFhwuXsdZiOHRtBgz4XVELIFYO.jpg'}, {'cast_id': 18, 'character': 'Nan Whitman', 'credit_id': '52fe4327c3a36847f803e67d', 'gender': 1, 'id': 20362, 'name': 'Jill Clayburgh', 'order': 6, 'profile_path': '/twrfhIvbqHuJ7nXVpehvU6nyi6R.jpg'}, {'cast_id': 19, 'character': 'Cathy Stewart', 'credit_id': '52fe4327c3a36847f803e681', 'gender': 1, 'id': 20363, 'name': 'Suzanne Snyder', 'order': 7, 'profile_path': '/90FrTcjJudpeIYUjUzlO6XAmvnt.jpg'}, {'cast_id': 20, 'character': 'Amalia', 'credit_id': '52fe4327c3a36847f803e685', 'gender': 0, 'id': 13029, 'name': 'Anne Betancourt', 'order': 8, 'profile_path': '/6UU5P4DzjJTSBFztIu1nALT2tk0.jpg'}, {'cast_id': 21, 'character': 'Juan Fuentes', 'credit_id': '52fe4327c3a36847f803e689', 'gender': 2, 'id': 4511, 'name': 'Mark Adair-Rios', 'order': 9, 'profile_path': '/rX4d1e5jlF5P73qynjjUzJslB0c.jpg'}, {'cast_id': 22, 'character': 'Judd Marshall', 'credit_id': '52fe4327c3a36847f803e68d', 'gender': 2, 'id': 4171, 'name': 'Stanley DeSantis', 'order': 10, 'profile_path': '/4cHxkhTd7oklyNkdva9WJp0FLrX.jpg'}, {'cast_id': 23, 'character': 'Antonio Fuentes', 'credit_id': '52fe4327c3a36847f803e691', 'gender': 0, 'id': 4665, 'name': 'Josh Cruze', 'order': 11, 'profile_path': '/v3QrQzH0uGV9pd1dNR5Ue6a74qO.jpg'}, {'cast_id': 24, 'character': 'Petra', 'credit_id': '52fe4327c3a36847f803e695', 'gender': 0, 'id': 4666, 'name': 'Angela Lanza', 'order': 12, 'profile_path': '/zmf6TMWMVCdnuUfpgdnioaICk1L.jpg'}, {'cast_id': 25, 'character': 'Phil', 'credit_id': '52fe4327c3a36847f803e699', 'gender': 2, 'id': 4445, 'name': 'Chris Bauer', 'order': 13, 'profile_path': '/3KYVMaGkWTEDQ0T9lsu85pVbP4T.jpg'}, {'cast_id': 26, 'character': 'Chuy', 'credit_id': '577e438f925141440c000d63', 'gender': 0, 'id': 115874, 'name': 'Carlos Gómez', 'order': 14, 'profile_path': '/nBxwoMv1zrhNXyEjYXbcdmAdmF0.jpg'}]   \n",
      "2638962  [{'cast_id': 6, 'character': 'Antoine Doinel', 'credit_id': '52fe421ec3a36847f8005661', 'gender': 2, 'id': 1653, 'name': 'Jean-Pierre Léaud', 'order': 0, 'profile_path': '/dzkPODapVe4CSubEqI9ytTCqnZ7.jpg'}, {'cast_id': 7, 'character': 'Gilberte Doinel', 'credit_id': '52fe421ec3a36847f8005665', 'gender': 1, 'id': 1654, 'name': 'Claire Maurier', 'order': 1, 'profile_path': '/cP1n7zMsMKr77xJeR3CncomxEZ0.jpg'}, {'cast_id': 8, 'character': 'Julien Doinel', 'credit_id': '52fe421ec3a36847f8005669', 'gender': 0, 'id': 1655, 'name': 'Albert Rémy', 'order': 2, 'profile_path': '/6b8eyIXAV6oA5eX6ltc3hF7ZB3d.jpg'}, {'cast_id': 10, 'character': 'Mr. Bigey', 'credit_id': '52fe421ec3a36847f8005673', 'gender': 2, 'id': 1658, 'name': 'Georges Flamant', 'order': 3, 'profile_path': '/lQwmtPsFWME63x5M7IRF6g8bLrR.jpg'}, {'cast_id': 11, 'character': 'René', 'credit_id': '52fe421ec3a36847f8005677', 'gender': 0, 'id': 1659, 'name': 'Patrick Auffay', 'order': 4, 'profile_path': None}, {'cast_id': 12, 'character': 'Director of the school', 'credit_id': '52fe421ec3a36847f800567b', 'gender': 0, 'id': 1660, 'name': 'Robert Beauvais', 'order': 5, 'profile_path': None}, {'cast_id': 13, 'character': 'Mme Bigey', 'credit_id': '52fe421ec3a36847f800567f', 'gender': 0, 'id': 1661, 'name': 'Yvonne Claudie', 'order': 6, 'profile_path': None}, {'cast_id': 14, 'character': 'English Teacher', 'credit_id': '52fe421ec3a36847f8005683', 'gender': 0, 'id': 1662, 'name': 'Pierre Repp', 'order': 7, 'profile_path': '/1AUhiNGBAR0C6AU9iK1IXBs3QTz.jpg'}, {'cast_id': 17, 'character': 'French Teacher', 'credit_id': '52fe421ec3a36847f8005693', 'gender': 0, 'id': 1656, 'name': 'Guy Decomble', 'order': 8, 'profile_path': '/34iexAuqI1asyFounbSXSCFphen.jpg'}, {'cast_id': 20, 'character': 'Betrand Mauricet', 'credit_id': '52fe421ec3a36847f8005697', 'gender': 0, 'id': 1077237, 'name': 'Daniel Couturier', 'order': 9, 'profile_path': None}, {'cast_id': 21, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569b', 'gender': 0, 'id': 1077238, 'name': 'François Nocher', 'order': 10, 'profile_path': None}, {'cast_id': 22, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569f', 'gender': 2, 'id': 150939, 'name': 'Richard Kanayan', 'order': 11, 'profile_path': '/vCMDk3ifj2vJKZYCISXT3K6DYXF.jpg'}, {'cast_id': 23, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a3', 'gender': 0, 'id': 1077239, 'name': 'Renaud Fontanarosa', 'order': 12, 'profile_path': None}, {'cast_id': 24, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a7', 'gender': 0, 'id': 1077240, 'name': 'Michel Girard', 'order': 13, 'profile_path': None}, {'cast_id': 25, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056ab', 'gender': 0, 'id': 71997, 'name': 'Serge Moati', 'order': 14, 'profile_path': '/wccRQKHrX61sH4WlOtM1KBP4qaq.jpg'}, {'cast_id': 26, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056af', 'gender': 0, 'id': 1077241, 'name': 'Bernard Abbou', 'order': 15, 'profile_path': None}, {'cast_id': 27, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b3', 'gender': 0, 'id': 1077242, 'name': 'Jean-François Bergouignan', 'order': 16, 'profile_path': None}, {'cast_id': 28, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b7', 'gender': 0, 'id': 1077243, 'name': 'Michel Lesignor', 'order': 17, 'profile_path': None}, {'cast_id': 31, 'character': 'Man in Street', 'credit_id': '5457f0a1c3a3683993000156', 'gender': 2, 'id': 24299, 'name': 'Jean-Claude Brialy', 'order': 18, 'profile_path': '/g3kkYcAvq90tALMErxmdAIcIXsE.jpg'}, {'cast_id': 32, 'character': 'Woman with Dog', 'credit_id': '5457f0bec3a36839a0000144', 'gender': 1, 'id': 14812, 'name': 'Jeanne Moreau', 'order': 19, 'profile_path': '/uHJnVwCzehEoz0mIlwN7xkymql8.jpg'}, {'cast_id': 33, 'character': 'Man in Funfair', 'credit_id': '5457f0d3c3a368399300015b', 'gender': 2, 'id': 34613, 'name': 'Philippe de Broca', 'order': 20, 'profile_path': '/yrvmXE2SJBX659r2Y7eWwlmwfYd.jpg'}, {'cast_id': 34, 'character': 'Man in Funfair', 'credit_id': '5457f0e5c3a368399d00014c', 'gender': 0, 'id': 1650, 'name': 'François Truffaut', 'order': 21, 'profile_path': '/apCCV99N3FqB5NsEPqOzetlkprL.jpg'}]   \n",
      "\n",
      "                                                                               tagline  \\\n",
      "6566765                                                  It ain't over 'til it's over.   \n",
      "6880303                                   First came love... then came Reverend Frank.   \n",
      "2083077                                                          A Brilliant Melodrama   \n",
      "1492304  What if finding the love of your life meant changing the life that you loved?   \n",
      "2638962                                            Angel faces hell-bent for violence.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        overview  \n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When he loses a highly publicized virtual boxing match to ex-champ Rocky Balboa, reigning heavyweight titleholder, Mason Dixon retaliates by challenging Rocky to a nationally televised, 10-round exhibition bout. To the surprise of his son and friends, Rocky agrees to come out of retirement and face an opponent who's faster, stronger and thirty years his junior.  \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Newly engaged, Ben and Sadie can't wait to start their life together and live happily ever after. However Sadie's family church's Reverend Frank won't bless their union until they pass his patented, \"foolproof\" marriage prep course consisting of outrageous classes, outlandish homework assignments and some outright invasion of privacy.  \n",
      "2083077  Derrick De Marney finds himself in a 39 Steps situation when he is wrongly accused of murder. While a fugitive from the law, De Marney is helped by heroine Nova Pilbeam, who three years earlier had played the adolescent kidnap victim in Hitchcock's The Man Who Knew Too Much. The obligatory \"fish out of water\" scene, in which the principals are briefly slowed down by a banal everyday event, occurs during a child's birthday party. The actual villain, whose identity is never in doubt (Hitchcock made thrillers, not mysteries) is played by George Curzon, who suffers from a twitching eye. Curzon's revelation during an elaborate nightclub sequence is a Hitchcockian tour de force, the sort of virtuoso sequence taken for granted in these days of flexible cameras and computer enhancement, but which in 1937 took a great deal of time, patience and talent to pull off. Released in the US as The Girl Was Young, Young and Innocent was based on a novel by Josephine Tey.  \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alex Whitman (Matthew Perry) is a designer from New York City who is sent to Las Vegas to supervise the construction of a nightclub that his firm has been hired to build. Alex is a straight-laced WASP-ish type who, while enjoying a night on the town, meets Isabel Fuentes (Salma Hayek), a free-spirited Mexican-American photographer. Alex and Isabel are overtaken by lust at first sight and end up sp  \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For young Parisian boy Antoine Doinel, life is one difficult situation after another. Surrounded by inconsiderate adults, including his neglectful parents, Antoine spends his days with his best friend, Rene, trying to plan for a better life. When one of their schemes goes awry, Antoine ends up in trouble with the law, leading to even more conflicts with unsympathetic authority figures.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "movies_df = pd.read_csv('./the-movies-dataset/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={'genres':\"string\",\"id\":\"string\",\"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\",\n",
    "                                    \"production_companies\" :\"string\"})[[\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"]]\n",
    "movies_df.dropna(inplace = True)\n",
    "movies_lst = [row for row in movies_df.values.tolist() if not (row[0][len(row[0])  - 2:] == \"[]\" or row[5][len(row[5]) - 2:] == \"[]\")]\n",
    "movies_df = pd.DataFrame(movies_lst, columns = (\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"), dtype = str)\n",
    "\n",
    "\n",
    "\n",
    "ratings_df = pd.read_csv('./the-movies-dataset/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"),\n",
    "                       dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})[[\"userId\", \"movieId\", \"rating\"]]\n",
    "ratings_df.rename(columns={\"movieId\": \"id\"}, inplace = True)\n",
    "ratings_df.dropna(inplace = True)\n",
    "\n",
    "\n",
    "# Question: What if the removal of duplicate movie ids per user was processed here instead of the cell below???\n",
    "# Answer: The duplicate removal function can be ran here,...\n",
    "# but the complete_list in the cell below can also be iterated over with relative complexity in order to remove duplicates.\n",
    "# The iteration in the next cell also populates the gap list...\n",
    "# which is critical to be ran directly before the function that determines bounds for users rated movies.\n",
    "# So, omitting the no duplicate function in this cell and making it run in the next cell avoids redundant iteration.\n",
    "\n",
    "\n",
    "# Question: What if the test and train ratings bounds was enforced here instead of the cell below???\n",
    "# Answer: The merge functions below needs to be executed before determining test and train users, because merge will remove rows and ratings from users...\n",
    "# before enforcing the users to be in a certain bounds for the number of their ratings. \n",
    "# The current timing of this function will ensure that the final users are within the set train or test bounds.\n",
    "\n",
    "\n",
    "keywords_df = pd.read_csv('./the-movies-dataset/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})[[\"id\", \"keywords\"]]\n",
    "keywords_df.dropna(inplace = True)\n",
    "keywords_lst = [row for row in keywords_df.values.tolist() if not (row[1][len(row[1])  - 2:] == \"[]\")]\n",
    "keywords_df = pd.DataFrame(keywords_lst, columns = (\"id\", \"keywords\"), dtype = str)\n",
    "\n",
    "\n",
    "credits_df = pd.read_csv(\"./the-movies-dataset/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})[[\"cast\", \"id\"]]\n",
    "credits_df.dropna(inplace = True)\n",
    "credits_lst = [row for row in credits_df.values.tolist() if (not row[0][len(row[0])  - 2:] == \"[]\")]\n",
    "credits_df = pd.DataFrame(credits_lst, columns = (\"cast\", \"id\"), dtype = str)\n",
    "\n",
    "\n",
    "# Default merge is inner: This only keeps movies that have the id existing in both dataframes.\n",
    "complete_df =  pd.merge(movies_df, ratings_df, on =\"id\")\n",
    "complete_df =  pd.merge(complete_df,keywords_df, on =\"id\")\n",
    "complete_df  = pd.merge(complete_df,credits_df, on =\"id\")\n",
    "\n",
    "\n",
    "complete_df.sort_values(by = 'userId', inplace = True)\n",
    "\n",
    "\n",
    "# Master dataframe: For each (user id, movie id) row combination there is the combined movie data from movies_df, ratings_df, keywords_df, and credits_df for the movie id in question.\n",
    "# The columns are reordered.\n",
    "complete_df  = complete_df.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "# For testing:\n",
    "print(\"Minutes taken:\", (time.time()-start_time)/60)\n",
    "print(complete_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Tested on personal machine:\n",
    "# Old run with dataframe iteration (old code): 1 minute and 5.7 seconds\n",
    "# New run with list conversion before iteration (current code): 37.1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Selection\n",
    "1. Select data from users that have a number of ratings within a certain bounds.\n",
    "2. Select a random subset of this data and simplify it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete number of users: 260788\n",
      "Minutes taken: 0.6642666419347127\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import hist\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "SEED_INT = 5\n",
    "# Seed for consistent results across runtimes:\n",
    "random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "def populate_names(item):\n",
    "    \"\"\"Extract names from the syntax of certain data entries:\"\"\"\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    index = 0\n",
    "    for item in jsons:\n",
    "        if(index == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        index += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provide_data(row):\n",
    "    \"\"\"Extract data from row of complete_list:\"\"\"\n",
    "    movie_data = []\n",
    "    movie_data.append(int(row[0]))\n",
    "    movie_data.append(int(row[1]))\n",
    "    movie_data.append(float(row[2]))\n",
    "    movie_data.append(row[3])  \n",
    "\n",
    "    movie_data.append(populate_names(row[4]))\n",
    "    movie_data.append(populate_names(row[5]))\n",
    "    movie_data.append(populate_names(row[6]))\n",
    "    movie_data.append(populate_names(row[7]))\n",
    "\n",
    "    movie_data.append(str(row[8]))\n",
    "    movie_data.append(str(row[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "\n",
    "# The list of rows with users id, the users rating for the movie, and raw data for the movie:\n",
    "# Note: It is sorted by user_id.\n",
    "complete_list = complete_df.values.tolist()\n",
    "\n",
    "print(\"Complete number of users:\", len(list(complete_df[\"userId\"].unique()))) # 260788\n",
    "\n",
    "# The complete list of user rows without ratings of the same movie more than once for a given user:\n",
    "complete_list_no_dups = []\n",
    "\n",
    "# Distinquish the user the row belongs to:\n",
    "last_id = complete_list[0][0]\n",
    "\n",
    "# The set of movies that a user has rated:\n",
    "# It is used to omit later ratings of a movie that the user has already rated.\n",
    "movie_set = set()\n",
    "\n",
    "# The number of rows of movie data a single user takes up for each user:\n",
    "gaps = []\n",
    "\n",
    "# Appended to gaps when all of a users rows of movie data have been counted:\n",
    "gap_len = 0\n",
    "\n",
    "\n",
    "# Populates gaps and complete_list_no_dups by omitting movies that already have a rating in respect to each user:\n",
    "# Note: This code is faster than using dataframe methods.\n",
    "# Example: Filter data by user and then remove duplicate movie ids for each user.\n",
    "# This avoids slow dataframe iteration, but the filter method is also slow.\n",
    "for row in complete_list:\n",
    "    if last_id != row[0]:\n",
    "        movie_set= set()\n",
    "        complete_list_no_dups.append(row)\n",
    "        movie_set.add(row[1])\n",
    "        gaps.append(gap_len)\n",
    "        gap_len = 1\n",
    "    else:\n",
    "        if row[1] not in movie_set:\n",
    "            complete_list_no_dups.append(row)\n",
    "            gap_len+=1\n",
    "            movie_set.add(row[1])\n",
    "    last_id = row[0]\n",
    "\n",
    "# Add the last gap_len:\n",
    "gaps.append(gap_len)\n",
    "\n",
    "\n",
    "\n",
    "full_index = 0 \n",
    "bounds = [] \n",
    "\n",
    "for user_index in range(len(gaps)):\n",
    "    bounds.append([full_index, full_index+gaps[user_index]])\n",
    "    full_index+=gaps[user_index]    \n",
    " \n",
    "\n",
    "\n",
    "#LOOK: rundown of process\n",
    "#LOOK: these are the types of user categories\n",
    "#users that are there only to predict the svd for train and test users\n",
    "#train users\n",
    "#test users\n",
    "\n",
    "#test and train users should have the same range of ratings\n",
    "#svd users should have a different rating range\n",
    "\n",
    "#there are 2 features to train the final model...\n",
    "#against the target ratings of the train users\n",
    "#feature 1: svd prediction from train users\n",
    "#feature 2: average rating for the train users\n",
    "\n",
    "#there are 2 features to test the final model...\n",
    "#against the target ratings of the test users\n",
    "#feature 1: svd prediction from test users\n",
    "#feature 2: average rating for the test users\n",
    "\n",
    "\n",
    "#These set the rating requirements for test and train users.\n",
    "    \n",
    "\n",
    "SVD_USER_RATING_LB = 20\n",
    "SVD_USER_RATING_UB = 30\n",
    "USER_RATING_LB = 5\n",
    "USER_RATING_UB = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(bounds)\n",
    "no_svd_users = 1000\n",
    "train_users = 800\n",
    "test_users = 800\n",
    "last_index = -1\n",
    "bounds_svd_users = []\n",
    "bounds_train_users = []\n",
    "bounds_test_users = []\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: the problem seems to occur only when user groups share simlair ratings bounds\n",
    "#why???\n",
    "\n",
    "index = 0\n",
    "for item in bounds:\n",
    "    if item[1]-item[0] >=SVD_USER_RATING_LB and item[1]-item[0] <=SVD_USER_RATING_UB:\n",
    "        bounds_svd_users.append(item)\n",
    "        if len(bounds_svd_users) == no_svd_users:\n",
    "            last_index = index\n",
    "            break\n",
    "    index+=1\n",
    "\n",
    "\n",
    "\n",
    "index+=1\n",
    "for item in bounds[last_index:]:\n",
    "    if item[1]-item[0] >=USER_RATING_LB and item[1]-item[0] <=USER_RATING_UB:\n",
    "        bounds_train_users.append(item)\n",
    "        if len(bounds_train_users) == train_users:\n",
    "            last_index = index\n",
    "            break\n",
    "    index+=1\n",
    "\n",
    "index+=1\n",
    "for item in bounds[last_index:]:\n",
    "    if item[1]-item[0] >=USER_RATING_LB and item[1]-item[0] <=USER_RATING_UB:\n",
    "        bounds_test_users.append(item)\n",
    "        if len(bounds_test_users) == test_users:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Transformed data of the selected train users and test users (in that order):\n",
    "sampled_data = []\n",
    "\n",
    "\n",
    "for bound in bounds_svd_users:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        sampled_data.append(movie_data)\n",
    "\n",
    "\n",
    "for bound in bounds_train_users:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        sampled_data.append(movie_data)\n",
    "\n",
    "\n",
    "\n",
    "for bound in bounds_test_users:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        sampled_data.append(movie_data)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Minutes taken:\", (time.time()-start_time)/60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data\n",
    "\n",
    "Save selected data in constructed_data.csv file so that cells below it can run without running this cell and above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, 'constructed_data')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "with open(\"constructed_data/constructed_data_3.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    writer.writerows(sampled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "This is the starting cell to run if the data is already saved to the constructed_data.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data_3.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and re-sample Data:\n",
    "\n",
    "Format the data into a list of movie data rows for each movie rated for the user for each user. Then, select a subset of that data for each user type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "#LOOK: change back to zero...\n",
    "SEED_INT = 5\n",
    "\n",
    "random.seed(SEED_INT)\n",
    "\n",
    "user_to_data_svd = []\n",
    "user_to_data_train= []\n",
    "user_to_data_test = []\n",
    "\n",
    "user_id = data_list[0][0]\n",
    "ratings = []\n",
    "user_index = 0\n",
    "\n",
    "\n",
    "#LOOK: What if two diiferen user have the same id???\n",
    "\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        if(user_index<1000 and user_index>=0):\n",
    "            user_to_data_svd.append(ratings)\n",
    "        elif(user_index<1800 and user_index>=1000):\n",
    "            user_to_data_train.append(ratings)\n",
    "        else:\n",
    "            user_to_data_test.append(ratings)         \n",
    "        user_id = row[0]\n",
    "        ratings = [row]\n",
    "        user_index+=1\n",
    "    else:\n",
    "        ratings.append(row)\n",
    "\n",
    "\n",
    "\n",
    "user_to_data_test.append(ratings)\n",
    "\n",
    "\n",
    "#sample and relabel user and movie indices\n",
    "user_to_data_svd = random.sample(user_to_data_svd, 1000)\n",
    "user_to_data_train = random.sample(user_to_data_train, 800)\n",
    "user_to_data_test = random.sample(user_to_data_test, 800)\n",
    "\n",
    "\n",
    "old_to_new_svd  = dict()\n",
    "last_index_svd = 0\n",
    "svd_cnt = 0\n",
    "\n",
    "for user in user_to_data_svd:\n",
    "    for row in user: \n",
    "        if(row[1] in old_to_new_svd.keys()):\n",
    "            row[1] = old_to_new_svd[row[1]]\n",
    "        else:\n",
    "            old_to_new_svd[row[1]] = last_index_svd\n",
    "            row[1] = last_index_svd\n",
    "            last_index_svd+=1      \n",
    "        row[0] = svd_cnt\n",
    "    svd_cnt+=1\n",
    "\n",
    "\n",
    "old_to_new_train = copy.deepcopy(old_to_new_svd)\n",
    "last_index_train = last_index_svd\n",
    "train_cnt = svd_cnt\n",
    "\n",
    "for user in user_to_data_train:\n",
    "    for row in user: \n",
    "        if(row[1] in old_to_new_train.keys()):\n",
    "            row[1] = old_to_new_train[row[1]]\n",
    "        else:\n",
    "            old_to_new_train[row[1]] = last_index_train\n",
    "            row[1] = last_index_train\n",
    "            last_index_train+=1      \n",
    "        row[0] = train_cnt\n",
    "    train_cnt+=1\n",
    "\n",
    "old_to_new_test = copy.deepcopy(old_to_new_svd)\n",
    "last_index_test = last_index_svd\n",
    "test_cnt = svd_cnt\n",
    "\n",
    "for user in user_to_data_test:\n",
    "    for row in user: \n",
    "        if(row[1] in old_to_new_test.keys()):\n",
    "            row[1] = old_to_new_test[row[1]]\n",
    "        else:\n",
    "            old_to_new_test[row[1]] = last_index_test\n",
    "            row[1] = last_index_test\n",
    "            last_index_test+=1      \n",
    "        row[0] = test_cnt\n",
    "    test_cnt+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0125046273267093\n",
      "0.26576702553132336\n",
      "1.0563343901436708\n",
      "0.24348389376077495\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "from ordered_set import OrderedSet\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from surprise import SVD,Dataset,Reader\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import copy\n",
    "\n",
    "SEED_INT = 5\n",
    "# Seed for consistent results across runtimes:\n",
    "random.seed(SEED_INT)\n",
    "np.random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "#LOOK: The nof test users actually matters alot in the svd_focus notebook!\n",
    "#this mean more testing shuld be done\n",
    "\n",
    "\n",
    "# methods of getting svd predictions for train and test users:\n",
    "# should give all of these a try!!!\n",
    "\n",
    "\n",
    "# 1: \n",
    "# make an svd model for every test or train user combined with all the svd users\n",
    "# then make predictions for the single attatched test or train user\n",
    "# problem: too slow!!!\n",
    "\n",
    "# 2:\n",
    "# another method is batch processing:\n",
    "# use all of the train user with the svd users to build a model then make predcitions with the train users\n",
    "# use all the test users with the svd users to build a model then make prediction with the test users\n",
    "\n",
    "# problem: does not answer a users rating request imediately without a pool of users with the same range \n",
    "# for nof ratings...\n",
    "# However, to solve this problem, this pool of users alike can still be acessed randomly from a database\n",
    "# problem: train and test users are less helpful for bulding the svd since they have less ratings\n",
    "# requirements: same number of train and test users because otherwise the svd works differently...\n",
    "# and the final model (combination of two features) will be lead astray.\n",
    "# problem: the train and test users only aproximate the client user that enters a number of ratings.\n",
    "# just because the user enters a certain amount of ratings doesnt mean we known how...\n",
    "# it corresponds to the number of movies they rated in the database. answering this is a whole other question.\n",
    "# helpful idea: force the user to enter an exact number of (movie, rating) pairs...\n",
    "# because we don't know how the distribution of nof train/test user ratings for a certain bounds of ratings\n",
    "# correlates to the number of movie, rating pairs entered on the client.\n",
    "# helpful idea: this method can be slightly optimized for individual prediction by replacing the users that are\n",
    "# alike the user that requests a rating with a number of svd users with a higher rating range.\n",
    "# This is idea 1 but cannot be used in bulk with the sheer amount of data and is only good for individual\n",
    "# client requests. Idea 2 at best produces similair scores to idea 1, but is infeasble in testing\n",
    "# this should be noted in the readme!!!\n",
    "\n",
    "\n",
    "# 3: \n",
    "# train the svd model with the svd users\n",
    "# then train a little bit more with a single train or test user\n",
    "# then make a prediction for a single train or test user\n",
    "# problem: hard to determine the right amount of training\n",
    "# problem: the traning order is off\n",
    "\n",
    "\n",
    "#LOOK: will be trying to make #2 work first\n",
    "\n",
    "\n",
    "#these 6 are the variables for the final model:\n",
    "feature_1_train = [] #user average predictions (if not exist set to train or tes oevrall average)\n",
    "feature_1_test = [] \n",
    "feature_2_train = [] #svd predictions\n",
    "feature_2_test = [] \n",
    "target_rating_train = []\n",
    "target_rating_test = []\n",
    "\n",
    "\n",
    "#used later\n",
    "movie_ratings_avg_list_train = []\n",
    "movie_ratings_avg_list_test = []\n",
    "\n",
    "\n",
    "\n",
    "#temporary variables:\n",
    "movies_order_svd = OrderedSet()\n",
    "movie_ratings_sum_dict_svd = dict()\n",
    "movie_ratings_count_dict_svd = dict()\n",
    "svd_user_to_movie_to_rating = []\n",
    "overall_average_svd = 0 \n",
    "cnt_svd = 0\n",
    "\n",
    "\n",
    "for user in user_to_data_svd:\n",
    "    movie_to_rating  = dict()\n",
    "    for movie in user:\n",
    "        movies_order_svd.add(movie[1])\n",
    "        movie_to_rating[movie[1]] = float(movie[2])\n",
    "        if(movie[1] in movie_ratings_sum_dict_svd.keys()):\n",
    "            movie_ratings_sum_dict_svd[movie[1]] += float(movie[2])\n",
    "            movie_ratings_count_dict_svd[movie[1]] += 1\n",
    "        else:\n",
    "            movie_ratings_sum_dict_svd[movie[1]] = float(movie[2])\n",
    "            movie_ratings_count_dict_svd[movie[1]] = 1\n",
    "        overall_average_svd+=float(movie[2])\n",
    "        cnt_svd += 1\n",
    "    svd_user_to_movie_to_rating.append(movie_to_rating)\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: Problem: there are users that are in svd set and the train set....hmm\n",
    "\n",
    "movies_order_train = copy.deepcopy(movies_order_svd)\n",
    "movie_ratings_sum_dict_train = copy.deepcopy(movie_ratings_sum_dict_svd)\n",
    "movie_ratings_count_dict_train = copy.deepcopy(movie_ratings_count_dict_svd)\n",
    "train_user_to_movie_to_rating = copy.deepcopy(svd_user_to_movie_to_rating)\n",
    "overall_average_train = overall_average_svd \n",
    "cnt_train = cnt_svd\n",
    "target_movie_train = []\n",
    "\n",
    "for user in user_to_data_train:\n",
    "    rand_num  = random.randint(0, len(user)-1)\n",
    "    index = 0\n",
    "    movie_to_rating  = dict()\n",
    "    #these two varaibles are used for the user average ratings\n",
    "    user_rating_sum = 0\n",
    "    usr_rating_count = 0\n",
    "    for movie in user:\n",
    "        movies_order_train.add(movie[1])\n",
    "        if(index == rand_num):\n",
    "            target_movie_train.append(movie[1])\n",
    "            target_rating_train.append(float(movie[2]))\n",
    "        else:\n",
    "            if(movie[1] in movie_ratings_sum_dict_train.keys()):\n",
    "                movie_ratings_sum_dict_train[movie[1]] += float(movie[2])\n",
    "                movie_ratings_count_dict_train[movie[1]] += 1\n",
    "            else:\n",
    "                movie_ratings_sum_dict_train[movie[1]] = float(movie[2])\n",
    "                movie_ratings_count_dict_train[movie[1]] = 1\n",
    "            movie_to_rating[movie[1]] = float(movie[2])\n",
    "            overall_average_train+=float(movie[2])\n",
    "            cnt_train += 1\n",
    "            user_rating_sum+=float(movie[2])\n",
    "            usr_rating_count +=1\n",
    "        index+=1\n",
    "    if(user_rating_sum==0):\n",
    "        feature_1_train.append(-1)\n",
    "    else: \n",
    "        feature_1_train.append(user_rating_sum/usr_rating_count)\n",
    "    train_user_to_movie_to_rating.append(movie_to_rating)\n",
    "\n",
    "\n",
    "overall_average_train = overall_average_train/cnt_train\n",
    "\n",
    "for i in range(len(feature_1_train)):\n",
    "    if feature_1_train[i] ==-1:\n",
    "        feature_1_train[i] = overall_average_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "movies_order_test = copy.deepcopy(movies_order_svd)\n",
    "movie_ratings_sum_dict_test = copy.deepcopy(movie_ratings_sum_dict_svd)\n",
    "movie_ratings_count_dict_test = copy.deepcopy(movie_ratings_count_dict_svd)\n",
    "test_user_to_movie_to_rating = copy.deepcopy(svd_user_to_movie_to_rating)\n",
    "overall_average_test = overall_average_svd \n",
    "cnt_test = cnt_svd\n",
    "target_movie_test = []\n",
    "\n",
    "\n",
    "#left off here\n",
    "for user in user_to_data_test:\n",
    "    rand_num  = random.randint(0, len(user)-1)\n",
    "    index = 0\n",
    "    movie_to_rating  = dict()\n",
    "    user_rating_sum = 0\n",
    "    usr_rating_count = 0\n",
    "    for movie in user:\n",
    "        movies_order_test.add(movie[1])\n",
    "        if(index == rand_num):\n",
    "            target_movie_test.append(movie[1])\n",
    "            target_rating_test.append(float(movie[2]))\n",
    "        else:\n",
    "            if(movie[1] in movie_ratings_sum_dict_test.keys()):\n",
    "                movie_ratings_sum_dict_test[movie[1]] += float(movie[2])\n",
    "                movie_ratings_count_dict_test[movie[1]] += 1\n",
    "            else:\n",
    "                movie_ratings_sum_dict_test[movie[1]] = float(movie[2])\n",
    "                movie_ratings_count_dict_test[movie[1]] = 1\n",
    "            movie_to_rating[movie[1]] = float(movie[2])\n",
    "            overall_average_test+=float(movie[2])\n",
    "            cnt_test += 1\n",
    "            user_rating_sum+=float(movie[2])\n",
    "            usr_rating_count +=1\n",
    "        index+=1\n",
    "    if(user_rating_sum==0):\n",
    "        feature_1_test.append(-1)\n",
    "    else: \n",
    "        feature_1_test.append(user_rating_sum/usr_rating_count)\n",
    "    test_user_to_movie_to_rating.append(movie_to_rating)\n",
    "\n",
    "overall_average_test  = overall_average_test/cnt_test\n",
    "\n",
    "for i in range(len(feature_1_test)):\n",
    "    if feature_1_test[i] ==-1:\n",
    "        feature_1_test[i] = overall_average_test\n",
    "\n",
    "\n",
    "#checkpoint1...\n",
    "\n",
    "\n",
    "#need to find movie_wise averages for...\n",
    "#the svd+train set and the svd+test set\n",
    "#train:\n",
    "movie_ratings_avg_list_train = []\n",
    "for movie in movies_order_train:\n",
    "    if movie in movie_ratings_sum_dict_train.keys():\n",
    "        movie_ratings_avg_list_train.append(movie_ratings_sum_dict_train[movie]/movie_ratings_count_dict_train[movie])\n",
    "    else:\n",
    "        movie_ratings_avg_list_train.append(overall_average_train)\n",
    "\n",
    "#test:\n",
    "movie_ratings_avg_list_test = []\n",
    "for movie in movies_order_test:\n",
    "    if movie in movie_ratings_sum_dict_test.keys():\n",
    "        movie_ratings_avg_list_test.append(movie_ratings_sum_dict_test[movie]/movie_ratings_count_dict_test[movie])\n",
    "    else:\n",
    "        movie_ratings_avg_list_test.append(overall_average_test) \n",
    "\n",
    "\n",
    "train_users_to_movie_ratings = []\n",
    "test_users_to_movie_ratings = []\n",
    "\n",
    "for i in range(len(user_to_data_svd)):\n",
    "    j = 0\n",
    "    lst = []\n",
    "    for movie in movies_order_train: \n",
    "        if movie in train_user_to_movie_to_rating[i].keys():\n",
    "            lst.append(train_user_to_movie_to_rating[i][movie])\n",
    "        else:\n",
    "            lst.append(movie_ratings_avg_list_train[j])\n",
    "        j += 1\n",
    "    train_users_to_movie_ratings.append(lst)\n",
    "    j = 0\n",
    "    lst1 = []\n",
    "    for movie in movies_order_test: \n",
    "        if movie in test_user_to_movie_to_rating[i].keys():\n",
    "            lst1.append(test_user_to_movie_to_rating[i][movie])\n",
    "        else:\n",
    "            lst1.append(movie_ratings_avg_list_test[j])\n",
    "        j += 1\n",
    "    test_users_to_movie_ratings.append(lst1)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(user_to_data_train)):\n",
    "    j = 0\n",
    "    lst = []\n",
    "    for movie in movies_order_train: \n",
    "        if(target_movie_train[i] == movie):\n",
    "            lst.append(movie_ratings_avg_list_train[j])\n",
    "        elif movie in train_user_to_movie_to_rating[i].keys():\n",
    "            lst.append(train_user_to_movie_to_rating[i][movie])\n",
    "        else:\n",
    "            lst.append(movie_ratings_avg_list_train[j])\n",
    "        j += 1\n",
    "    train_users_to_movie_ratings.append(lst)\n",
    "\n",
    "for i in range(len(user_to_data_test)):\n",
    "    j = 0\n",
    "    lst = []\n",
    "    for movie in movies_order_test: \n",
    "        if(target_movie_test[i] == movie):\n",
    "            lst.append(movie_ratings_avg_list_test[j])\n",
    "        elif movie in test_user_to_movie_to_rating[i].keys():\n",
    "            lst.append(test_user_to_movie_to_rating[i][movie])\n",
    "        else:\n",
    "            lst.append(movie_ratings_avg_list_test[j])\n",
    "        j += 1\n",
    "    test_users_to_movie_ratings.append(lst)\n",
    "\n",
    "\n",
    "\n",
    "#SVD methods....\n",
    "@njit\n",
    "def epoch(list, b1, b2, p, q, overall_average, lr, rt):\n",
    "    for row in list:\n",
    "        #conversions needed because numpy array converts to decimal\n",
    "        u = int(row[0])\n",
    "        i = int(row[1])\n",
    "        r = row[2]\n",
    "\n",
    "        pred = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "        error = r-pred\n",
    "        b1[u] += lr*(error- rt*b1[u])\n",
    "        b2[i] += lr*(error- rt*b2[i])\n",
    "        temp = lr*(error*q[i] -rt*p[u])\n",
    "        q[i] += lr*(error*p[u] -rt*q[i])\n",
    "        p[u] += temp\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: some row in list is requesting an item that is out of bounds\n",
    "#in this case it is the features that is out of bounds\n",
    "        \n",
    "def svd_iterative(list, n, epochs, rt, lr, overall_average, nof_users, nof_movies):\n",
    "    \n",
    "    q = np.random.normal(0, .1, (nof_movies, n))\n",
    "    p = np.random.normal(0, .1, (nof_users, n))\n",
    "\n",
    "    b1 = np.zeros(nof_users)\n",
    "    b2 = np.zeros(nof_movies)\n",
    "\n",
    "    np_array = np.array(list)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        epoch(np_array, b1, b2, p, q, overall_average, lr, rt)\n",
    "\n",
    "    return b1, b2, p, q\n",
    "\n",
    "\n",
    "# train_list = []\n",
    "# train_index = 0\n",
    "# train_movies_to_predict = []\n",
    "# for user_ratings, user_dict in zip(train_users_to_movie_ratings, train_user_to_movie_to_rating):\n",
    "#     for rating, movie_id in zip(user_ratings, list(movies_order_train)):\n",
    "#         if movie_id in user_dict.keys():\n",
    "#             train_list.append((train_index, int(movie_id), rating))\n",
    "#         elif(train_index >= len(user_to_data_svd)):\n",
    "#             if(movie_id == target_movie_train[train_index-len(user_to_data_svd)]):\n",
    "#                 train_movies_to_predict.append((train_index, int(movie_id)))\n",
    "#     train_index+=1\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: why is this different than above???\n",
    "train_list = []\n",
    "train_index = 0\n",
    "train_movies_to_predict = []\n",
    "for user_dict in train_user_to_movie_to_rating:\n",
    "    for movie_id in list(movies_order_train):\n",
    "        if movie_id in user_dict.keys():\n",
    "            train_list.append((train_index, int(movie_id), user_dict[movie_id]))\n",
    "        elif(train_index >= len(user_to_data_svd)):\n",
    "            if(movie_id == target_movie_train[train_index-len(user_to_data_svd)]):\n",
    "                train_movies_to_predict.append((train_index, int(movie_id)))\n",
    "    train_index+=1\n",
    "\n",
    "random.shuffle(train_list)\n",
    "\n",
    "#train_list and train_movies to predict ready for usage...\n",
    "\n",
    "\n",
    "#LOOK: problem is that the indices are in the order svd, train, test\n",
    "#when really there should be two orders:\n",
    "#svd train and then svd test\n",
    "\n",
    "# test_list = []\n",
    "# test_index = 0\n",
    "# test_movies_to_predict = []\n",
    "# for user_ratings, user_dict in zip(test_users_to_movie_ratings, test_user_to_movie_to_rating):\n",
    "#     for rating, movie_id in zip(user_ratings, list(movies_order_test)):\n",
    "#         if movie_id in user_dict.keys():\n",
    "#             test_list.append((test_index, int(movie_id), rating))\n",
    "#         elif(test_index >= len(user_to_data_svd)):     \n",
    "#             if(movie_id == target_movie_test[test_index-len(user_to_data_svd)]):\n",
    "#                 test_movies_to_predict.append((test_index, int(movie_id)))\n",
    "#     test_index+=1\n",
    "\n",
    "test_list = []\n",
    "test_index = 0\n",
    "test_movies_to_predict = []\n",
    "for user_dict in test_user_to_movie_to_rating:\n",
    "    for movie_id in list(movies_order_test):\n",
    "        if movie_id in user_dict.keys():\n",
    "            test_list.append((test_index, int(movie_id), user_dict[movie_id]))\n",
    "        elif(test_index >= len(user_to_data_svd)):     \n",
    "            if(movie_id == target_movie_test[test_index-len(user_to_data_svd)]):\n",
    "                test_movies_to_predict.append((test_index, int(movie_id)))\n",
    "    test_index+=1\n",
    "\n",
    "random.shuffle(test_list)\n",
    "\n",
    "\n",
    "#test_list and test_movies to predict ready for usage\n",
    "\n",
    "\n",
    "#now need to invoke svd for train and test sets:\n",
    "\n",
    "#svd_iterative(train_list, n, epochs, rt, lr, overall_average, nof_users, nof_movies):\n",
    "\n",
    "b1, b2, p, q = svd_iterative(train_list, 50,30,.03,.0075,\n",
    "                            overall_average_train, len(train_users_to_movie_ratings), len(list(movies_order_train)))\n",
    "\n",
    "feature_2_train = [overall_average_train + b1[pair[0]]+b2[pair[1]]\n",
    "                            +np.dot(p[pair[0]],q[pair[1]]) for pair in train_movies_to_predict]\n",
    "\n",
    "b1, b2, p, q = svd_iterative(test_list, 50,30,.03,.0075,\n",
    "                            overall_average_test, len(test_users_to_movie_ratings), len(list(movies_order_test)))\n",
    "\n",
    "feature_2_test = [overall_average_test + b1[pair[0]]+b2[pair[1]]\n",
    "                            +np.dot(p[pair[0]],q[pair[1]]) for pair in test_movies_to_predict]\n",
    "                     \n",
    "print(mean_squared_error(target_rating_train, feature_2_train, squared = False))\n",
    "print(r2_score(target_rating_train, feature_2_train))\n",
    "print(mean_squared_error(target_rating_test, feature_2_test, squared = False))\n",
    "print(r2_score(target_rating_test, feature_2_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
