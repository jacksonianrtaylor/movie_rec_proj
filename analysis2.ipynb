{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 847)\t1\n",
      "  (0, 1208)\t1\n",
      "  (0, 1456)\t1\n",
      "  (0, 349)\t2\n",
      "  (0, 942)\t1\n",
      "  (0, 1395)\t1\n",
      "  (0, 105)\t1\n",
      "  (0, 567)\t1\n",
      "  (0, 222)\t1\n",
      "  (0, 277)\t1\n",
      "  (0, 1099)\t1\n",
      "  (0, 805)\t1\n",
      "  (0, 1157)\t1\n",
      "  (0, 1129)\t1\n",
      "  (0, 1163)\t1\n",
      "  (0, 437)\t1\n",
      "  (0, 347)\t1\n",
      "  (0, 1464)\t1\n",
      "  (0, 207)\t1\n",
      "  (0, 1348)\t1\n",
      "  (1, 347)\t1\n",
      "  (1, 1464)\t1\n",
      "  (1, 371)\t1\n",
      "  (1, 201)\t2\n",
      "  (1, 1207)\t1\n",
      "  :\t:\n",
      "  (3, 56)\t1\n",
      "  (3, 903)\t1\n",
      "  (3, 675)\t1\n",
      "  (3, 1552)\t1\n",
      "  (4, 1469)\t1\n",
      "  (4, 767)\t1\n",
      "  (4, 1301)\t1\n",
      "  (4, 150)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 271)\t1\n",
      "  (4, 671)\t1\n",
      "  (4, 1538)\t1\n",
      "  (4, 919)\t1\n",
      "  (4, 865)\t1\n",
      "  (4, 1037)\t1\n",
      "  (4, 755)\t1\n",
      "  (4, 838)\t1\n",
      "  (4, 704)\t1\n",
      "  (4, 1258)\t1\n",
      "  (4, 485)\t1\n",
      "  (4, 1401)\t1\n",
      "  (4, 15)\t1\n",
      "  (4, 980)\t1\n",
      "  (4, 263)\t1\n",
      "  (4, 772)\t1\n",
      "[<1x1616 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, <1x1616 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, <1x1616 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, <1x1616 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, <1x1616 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'csr_matrix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mprint\u001b[39m(count_matrix[\u001b[39m1\u001b[39m:count_matrix\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]][\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m])\n\u001b[0;32m    118\u001b[0m \u001b[39mprint\u001b[39m(lst[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m])\n\u001b[1;32m--> 120\u001b[0m cosine_sim \u001b[39m=\u001b[39m cosine_similarity(count_matrix[\u001b[39m1\u001b[39;49m:count_matrix\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]]\n\u001b[0;32m    121\u001b[0m ,lst)\n\u001b[0;32m    123\u001b[0m \u001b[39m#print(cosine_sim)\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[39m# index =0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m#cutome?\u001b[39;00m\n",
      "File \u001b[1;32md:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1393\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \n\u001b[0;32m   1360\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[39m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1393\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1395\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[1;32md:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:163\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[1;32m--> 163\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    164\u001b[0m         Y,\n\u001b[0;32m    165\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    166\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    167\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    168\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    169\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n\u001b[0;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32md:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import var\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#load data\n",
    "ratings = pd.read_csv('dataset/ratings.csv')\n",
    "moviesPartial = pd.read_csv('dataset/movies.csv')\n",
    "moviesFull = pd.read_csv('dataset/movie_dataset.csv')\n",
    "\n",
    "#drop duplicates\n",
    "moviesFull.drop_duplicates(subset = 'title', inplace=True)\n",
    "\n",
    "#drop columns that do nothing\n",
    "ratings = ratings.drop(['timestamp'], axis = 1)\n",
    "moviesPartial = moviesPartial.drop(['genres'],axis=1)\n",
    "\n",
    "#all the users are to be tested\n",
    "userRatings = []\n",
    "for i in range(1,611):\n",
    "    userRatings.append(ratings[ratings['userId'] ==i])\n",
    "\n",
    "#remove the year and keep the name\n",
    "moviesPartial['title'] = moviesPartial['title'].map(lambda string: string[:-7])\n",
    "\n",
    "#drop duplicates\n",
    "moviesPartial.drop_duplicates(subset = 'title', inplace=True)\n",
    "\n",
    "#helper functions:\n",
    "def get_title_from_movieId(tmp):\n",
    "    return moviesPartial[moviesPartial[\"movieId\"]== tmp][\"title\"].to_string(index=False)\n",
    "\n",
    "def checkTitle(tmp):\n",
    "    if(tmp not in list(moviesFull[\"title\"])):\n",
    "        #The word \"the\" is being apended to the ends of titles\n",
    "        tmp = tmp[-3:] +\" \"+ tmp[:-5]\n",
    "        return moviesFull[moviesFull[\"title\"] == tmp][\"title\"].to_string(index=False)\n",
    "    else:\n",
    "        return moviesFull[moviesFull[\"title\"] == tmp][\"title\"].to_string(index=False)\n",
    "\n",
    "\n",
    "\n",
    "#used to filter out movies that are not in both data sets\n",
    "newUserTitles = []\n",
    "newUserRatings = []\n",
    "for userRating in userRatings:\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    for rating, id in zip(list(userRating[\"rating\"]), list(userRating[\"movieId\"])):\n",
    "        title = get_title_from_movieId(id)\n",
    "        checked = checkTitle(title)\n",
    "        if(checked != 'Series([], )'):\n",
    "            temp1.append(checked)\n",
    "            temp2.append(rating)\n",
    "    newUserTitles.append(temp1)\n",
    "    newUserRatings.append(temp2)\n",
    "    \n",
    "\n",
    "\n",
    "#this might lead to a referencce error\n",
    "#populate infos; a list of data frames\n",
    "infos = []\n",
    "for user in newUserTitles:\n",
    "    i = 0\n",
    "    tempInfo = pd.DataFrame(columns = list(moviesFull.columns))\n",
    "    for name in user:\n",
    "        if(len(moviesFull[moviesFull[\"title\"] == name]) !=0):\n",
    "            tempInfo.loc[i] = moviesFull[moviesFull[\"title\"] == name].iloc[0]\n",
    "        i+=1\n",
    "    infos.append(tempInfo)\n",
    "    \n",
    "\n",
    "features = ['keywords','cast','genres','director']\n",
    "\n",
    "\n",
    "for info in infos:\n",
    "    for feature in features:\n",
    "        info[feature] = info[feature].fillna('')\n",
    "\n",
    "colNumbers = []\n",
    "for feature in features:   \n",
    "    colNumbers.append(infos[0].columns.get_loc(feature))\n",
    "\n",
    "fullDataList =[]\n",
    "\n",
    "\n",
    "for frame in infos:\n",
    "    fullDataList.append(frame.values.tolist())\n",
    "\n",
    "combinedFeatures = []\n",
    "\n",
    "for item in fullDataList:\n",
    "    tmp = []\n",
    "    for row in item:\n",
    "        tmp.append(row[colNumbers[0]]+\" \"+row[colNumbers[1]]+\" \"+row[colNumbers[2]]+\" \"+row[colNumbers[3]])\n",
    "    combinedFeatures.append(tmp)\n",
    "\n",
    "\n",
    "cv = CountVectorizer() \n",
    "count_matrix = cv.fit_transform(combinedFeatures[0])\n",
    "\n",
    "\n",
    "lst = [count_matrix[0]]*(count_matrix.shape[1]-1)\n",
    "\n",
    "\n",
    "print(count_matrix[1:count_matrix.shape[1]][0:5])\n",
    "print(lst[0:5])\n",
    "\n",
    "cosine_sim = cosine_similarity(X = count_matrix[1:count_matrix.shape[1]]\n",
    ",Y = lst)\n",
    "\n",
    "#print(cosine_sim)\n",
    "\n",
    "# index =0\n",
    "# for item in combinedFeatures:\n",
    "#     if(index == 4):\n",
    "#         break\n",
    "#     cv = CountVectorizer() \n",
    "#     count_matrix = cv.fit_transform(item)\n",
    "#     testData = count_matrix[0]\n",
    "#     cosine_sim = cosine_similarity(count_matrix[1:len(testData)],count_matrix[0])\n",
    "#     index+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cosine_similarity sim function computes more then is needed at the moment\n",
    "\n",
    "#cutome?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
