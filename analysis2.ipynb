{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.04016097]\n",
      " [0.        ]\n",
      " [0.09759001]\n",
      " [0.        ]\n",
      " [0.05      ]\n",
      " [0.09325048]\n",
      " [0.05      ]\n",
      " [0.        ]\n",
      " [0.13693064]\n",
      " [0.04662524]\n",
      " [0.14301939]\n",
      " [0.09128709]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.09325048]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.03952847]\n",
      " [0.04472136]\n",
      " [0.        ]\n",
      " [0.15389675]\n",
      " [0.04767313]\n",
      " [0.1204829 ]\n",
      " [0.04662524]\n",
      " [0.        ]\n",
      " [0.08032193]\n",
      " [0.04662524]\n",
      " [0.05129892]\n",
      " [0.04767313]\n",
      " [0.08451543]\n",
      " [0.23354968]\n",
      " [0.09759001]\n",
      " [0.04767313]\n",
      " [0.04564355]\n",
      " [0.05129892]\n",
      " [0.09128709]\n",
      " [0.09325048]\n",
      " [0.        ]\n",
      " [0.08164966]\n",
      " [0.07784989]\n",
      " [0.        ]\n",
      " [0.0860663 ]\n",
      " [0.05      ]\n",
      " [0.1315587 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.0438529 ]\n",
      " [0.09128709]\n",
      " [0.        ]\n",
      " [0.05      ]\n",
      " [0.1       ]\n",
      " [0.04662524]\n",
      " [0.04564355]\n",
      " [0.        ]\n",
      " [0.08451543]\n",
      " [0.04767313]\n",
      " [0.09325048]\n",
      " [0.12456822]\n",
      " [0.04564355]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.04564355]\n",
      " [0.        ]\n",
      " [0.09534626]\n",
      " [0.        ]\n",
      " [0.04767313]\n",
      " [0.12677314]\n",
      " [0.05129892]\n",
      " [0.08944272]\n",
      " [0.0860663 ]\n",
      " [0.09682458]\n",
      " [0.04767313]\n",
      " [0.05270463]\n",
      " [0.        ]\n",
      " [0.14638501]\n",
      " [0.048795  ]\n",
      " [0.04564355]\n",
      " [0.1       ]\n",
      " [0.04472136]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.03952847]\n",
      " [0.05      ]\n",
      " [0.04082483]\n",
      " [0.04303315]\n",
      " [0.04303315]\n",
      " [0.09325048]\n",
      " [0.048795  ]\n",
      " [0.04564355]\n",
      " [0.048795  ]\n",
      " [0.        ]\n",
      " [0.08164966]\n",
      " [0.        ]\n",
      " [0.0877058 ]\n",
      " [0.03952847]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.12247449]\n",
      " [0.26832816]\n",
      " [0.048795  ]\n",
      " [0.        ]\n",
      " [0.05      ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.13416408]\n",
      " [0.08944272]\n",
      " [0.        ]\n",
      " [0.04662524]\n",
      " [0.04767313]\n",
      " [0.        ]\n",
      " [0.0877058 ]\n",
      " [0.        ]\n",
      " [0.04662524]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.09325048]\n",
      " [0.048795  ]\n",
      " [0.04303315]\n",
      " [0.048795  ]\n",
      " [0.09128709]\n",
      " [0.04472136]\n",
      " [0.        ]\n",
      " [0.04767313]\n",
      " [0.        ]\n",
      " [0.09534626]\n",
      " [0.04564355]\n",
      " [0.0438529 ]\n",
      " [0.09759001]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import var\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#load data\n",
    "ratings = pd.read_csv('dataset/ratings.csv')\n",
    "moviesPartial = pd.read_csv('dataset/movies.csv')\n",
    "moviesFull = pd.read_csv('dataset/movie_dataset.csv')\n",
    "\n",
    "#drop duplicates\n",
    "moviesFull.drop_duplicates(subset = 'title', inplace=True)\n",
    "\n",
    "#drop columns that do nothing\n",
    "ratings = ratings.drop(['timestamp'], axis = 1)\n",
    "moviesPartial = moviesPartial.drop(['genres'],axis=1)\n",
    "\n",
    "#all the users are to be tested\n",
    "userRatings = []\n",
    "for i in range(1,611):\n",
    "    userRatings.append(ratings[ratings['userId'] ==i])\n",
    "\n",
    "#remove the year and keep the name\n",
    "moviesPartial['title'] = moviesPartial['title'].map(lambda string: string[:-7])\n",
    "\n",
    "#drop duplicates\n",
    "moviesPartial.drop_duplicates(subset = 'title', inplace=True)\n",
    "\n",
    "#helper functions:\n",
    "def get_title_from_movieId(tmp):\n",
    "    return moviesPartial[moviesPartial[\"movieId\"]== tmp][\"title\"].to_string(index=False)\n",
    "\n",
    "def checkTitle(tmp):\n",
    "    if(tmp not in list(moviesFull[\"title\"])):\n",
    "        #The word \"the\" is being apended to the ends of titles\n",
    "        tmp = tmp[-3:] +\" \"+ tmp[:-5]\n",
    "        return moviesFull[moviesFull[\"title\"] == tmp][\"title\"].to_string(index=False)\n",
    "    else:\n",
    "        return moviesFull[moviesFull[\"title\"] == tmp][\"title\"].to_string(index=False)\n",
    "\n",
    "\n",
    "\n",
    "#used to filter out movies that are not in both data sets\n",
    "newUserTitles = []\n",
    "newUserRatings = []\n",
    "for userRating in userRatings:\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    for rating, id in zip(list(userRating[\"rating\"]), list(userRating[\"movieId\"])):\n",
    "        title = get_title_from_movieId(id)\n",
    "        checked = checkTitle(title)\n",
    "        if(checked != 'Series([], )'):\n",
    "            temp1.append(checked)\n",
    "            temp2.append(rating)\n",
    "    newUserTitles.append(temp1)\n",
    "    newUserRatings.append(temp2)\n",
    "    \n",
    "\n",
    "\n",
    "#this might lead to a referencce error\n",
    "#populate infos; a list of data frames\n",
    "infos = []\n",
    "for user in newUserTitles:\n",
    "    i = 0\n",
    "    tempInfo = pd.DataFrame(columns = list(moviesFull.columns))\n",
    "    for name in user:\n",
    "        if(len(moviesFull[moviesFull[\"title\"] == name]) !=0):\n",
    "            tempInfo.loc[i] = moviesFull[moviesFull[\"title\"] == name].iloc[0]\n",
    "        i+=1\n",
    "    infos.append(tempInfo)\n",
    "    \n",
    "\n",
    "features = ['keywords','cast','genres','director']\n",
    "\n",
    "\n",
    "for info in infos:\n",
    "    for feature in features:\n",
    "        info[feature] = info[feature].fillna('')\n",
    "\n",
    "colNumbers = []\n",
    "for feature in features:   \n",
    "    colNumbers.append(infos[0].columns.get_loc(feature))\n",
    "\n",
    "fullDataList =[]\n",
    "\n",
    "\n",
    "for frame in infos:\n",
    "    fullDataList.append(frame.values.tolist())\n",
    "\n",
    "combinedFeatures = []\n",
    "\n",
    "for item in fullDataList:\n",
    "    tmp = []\n",
    "    for row in item:\n",
    "        tmp.append(row[colNumbers[0]]+\" \"+row[colNumbers[1]]+\" \"+row[colNumbers[2]]+\" \"+row[colNumbers[3]])\n",
    "    combinedFeatures.append(tmp)\n",
    "\n",
    "\n",
    "def transform1(arr):\n",
    "    ret = []\n",
    "    for item in arr:\n",
    "        if(item<=.5):\n",
    "            ret.append(1/item)\n",
    "        if(item>.5):\n",
    "            ret.append(-1*(1/(1-item)))\n",
    "    return ret\n",
    "\n",
    "def transform2(arr):\n",
    "    ret = []\n",
    "    for item in arr:\n",
    "        ret.append(1/item)\n",
    "    return ret\n",
    "\n",
    "\n",
    "cv = CountVectorizer() \n",
    "count_matrix = cv.fit_transform(combinedFeatures[0]).toarray()\n",
    "cosine_sim = cosine_similarity(X = count_matrix[1:count_matrix.shape[1]]\n",
    ",Y = [count_matrix[0]])\n",
    "\n",
    "average = sum(newUserRatings[0][1:])/(len(newUserRatings[0])-1)\n",
    "ratings = newUserRatings[0][1:]\n",
    "similairities = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "\n",
    "scores = stats.zscore(ratings)\n",
    "p_values = norm.sf(scores)\n",
    "vals1 = transform1(p_values)\n",
    "scores = stats.zscore(similairities)\n",
    "p_values = norm.sf(scores)\n",
    "vals2 = transform2(p_values)\n",
    "\n",
    "totalRating = 0\n",
    "\n",
    "s1 = abs(sum(vals1))\n",
    "s2 = abs(sum(vals2))\n",
    "\n",
    "for val1, val2,sim, rating in zip(vals1, vals2, similairities, ratings):\n",
    "    totalRating += (val1/s1)*(val2/s2)*40\n",
    "    \n",
    "\n",
    "print(\"calulated rating:\", average+totalRating)\n",
    "print(\"actual rating:\", newUserRatings[0][0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
