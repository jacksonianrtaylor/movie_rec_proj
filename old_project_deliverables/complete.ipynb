{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "moviesFull = pd.read_csv('large_source_data/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={\"tagline\": \"string\", \"id\":\"string\", 'genres':\"string\", \"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\", \"production_companies\" :\"string\"})\n",
    "ratings = pd.read_csv('large_source_data/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"), dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})\n",
    "ratings = ratings.rename(columns={\"movieId\": \"id\"})\n",
    "\n",
    "keywords = pd.read_csv('large_source_data/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})\n",
    "credits = pd.read_csv(\"large_source_data/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})\n",
    "\n",
    "complete =  pd.merge(moviesFull, ratings, on =\"id\")\n",
    "complete =  pd.merge(complete,keywords, on =\"id\")\n",
    "complete  = pd.merge(complete,credits, on =\"id\")\n",
    "\n",
    "\n",
    "complete = complete.sort_values(by = 'userId')\n",
    "\n",
    "complete  = complete.dropna()\n",
    "\n",
    "complete  = complete.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "#used to filter the rows of a data\n",
    "def condition(array):\n",
    "    length = len(array[4])\n",
    "    if(array[4][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[5])\n",
    "    if(array[5][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[6])\n",
    "    if(array[6][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[7])\n",
    "    if(array[7][length-2:] == \"[]\"):\n",
    "        return False   \n",
    "    length = len(array[8])\n",
    "    if(array[8][length-4:]==\"<NA>\"):\n",
    "        return False\n",
    "    length = len(array[9])\n",
    "    if(array[9][length-4:]==\"<NA>\"):\n",
    "        return False \n",
    "    return True\n",
    "\n",
    "\n",
    "#used to extract names from string of list of json formats\n",
    "def populateNames(item):\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    cnt = 0\n",
    "    for item in jsons:\n",
    "        if(cnt == len(jsons)-1):\n",
    "            tempDict = ast.literal_eval(item)\n",
    "            names+=str(tempDict[\"name\"])\n",
    "        else:\n",
    "            tempDict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(tempDict[\"name\"])+\" \")\n",
    "        cnt += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provideData(array):\n",
    "    movieData = []\n",
    "    movieData.append(int(array[0]))\n",
    "    movieData.append(int(array[1]))\n",
    "    movieData.append(float(array[2]))\n",
    "    movieData.append(array[3])  \n",
    "\n",
    "    movieData.append(populateNames(array[4]))\n",
    "    movieData.append(populateNames(array[5]))\n",
    "    movieData.append(populateNames(array[6]))\n",
    "    movieData.append(populateNames(array[7]))\n",
    "\n",
    "    movieData.append(str(array[8]))\n",
    "    movieData.append(str(array[9]))\n",
    "    return movieData\n",
    "    \n",
    "\n",
    "\n",
    "#convert the dataframe into an array\n",
    "#and then build a dictionary\n",
    "completeDict = dict()\n",
    "completeArray = complete.to_numpy()\n",
    "arrayOfUserIds = []\n",
    "\n",
    "\n",
    "#get all unique user ids\n",
    "lastId  = -1\n",
    "for item in completeArray:\n",
    "    if(item[0]!= lastId):\n",
    "        arrayOfUserIds.append(item[0])\n",
    "        lastId = item[0]\n",
    "\n",
    "\n",
    "index  = 0\n",
    "nofUsers = 5000\n",
    "#5000 users are tested and potentially added to the dict\n",
    "for i in range(0, nofUsers):\n",
    "    completeDict[arrayOfUserIds[i]] = []\n",
    "    for j in range(index, len(completeArray)):\n",
    "        if completeArray[j][0] == arrayOfUserIds[i]:\n",
    "            #this is where conditions are checked in completeArray[j]\n",
    "            if(condition(completeArray[j])):\n",
    "                #this is where data is tranformed\n",
    "                transformed = provideData(completeArray[j])\n",
    "                completeDict[arrayOfUserIds[i]].append(transformed)         \n",
    "        else:\n",
    "            #ignore if the number o ratings is too small\n",
    "            if (len(completeDict[arrayOfUserIds[i]])<10):\n",
    "                del completeDict[arrayOfUserIds[i]]\n",
    "            index = j+1\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in a file so that cells below can run without running the above\n",
    "import csv\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    for item in completeDict.keys():\n",
    "        writer.writerows(completeDict[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a starting point if the data is already saved to the csv file\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "dataList =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", 'r', encoding=\"utf-8\") as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    dataList = list(csv_reader)\n",
    "\n",
    "dataList = dataList[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie id to list of ratings\n",
    "movieDict = dict()\n",
    "\n",
    "#user id to the rated movies by that user\n",
    "userDict = dict()\n",
    "\n",
    "userId = -1\n",
    "for row in dataList:\n",
    "    if (row[0]!=userId):\n",
    "        userId = row[0]\n",
    "        userDict[row[0]] = [row]\n",
    "    else:\n",
    "        userDict[row[0]].append(row)\n",
    "\n",
    "    if(row[1] in movieDict.keys()):\n",
    "        movieDict[row[1]].append(row[2])\n",
    "    else:\n",
    "        movieDict[row[1]] = [row[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "#dictionary of user id to a list of string of combined textual features for each movie \n",
    "#does not include ratings or movie id\n",
    "\n",
    "combinedCorpus = dict()\n",
    "\n",
    "i = 0\n",
    "for key in userDict.keys():\n",
    "    movieStrings = []\n",
    "    for movieData in userDict[key]:\n",
    "        movieString = \"\"\n",
    "        #avoid the first three data points (user id, movieid, and rating)\n",
    "        for index in range (3,len(movieData)):\n",
    "            if(index!= len(movieData)-1):\n",
    "                movieString+= movieData[index]+\" \"\n",
    "            else:\n",
    "                movieString+= movieData[index]\n",
    "        cleaned = remove_stopwords(movieString)\n",
    "        movieStrings.append(cleaned)\n",
    "    combinedCorpus[key] = movieStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackson\\AppData\\Local\\Temp\\ipykernel_15228\\597354738.py:63: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skew1= skew(ratings)\n",
      "C:\\Users\\jackson\\AppData\\Local\\Temp\\ipykernel_15228\\597354738.py:65: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  kurt1 = kurtosis(ratings)\n",
      "C:\\Users\\jackson\\AppData\\Local\\Temp\\ipykernel_15228\\597354738.py:63: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skew1= skew(ratings)\n",
      "C:\\Users\\jackson\\AppData\\Local\\Temp\\ipykernel_15228\\597354738.py:65: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  kurt1 = kurtosis(ratings)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import statistics\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import numpy as np\n",
    "\n",
    "#analysis \n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "def getAverageMovieRatings(movieId):\n",
    "    ret =0 \n",
    "    cnt = 0\n",
    "    for item in movieDict[movieId]:\n",
    "        ret+= float(item)\n",
    "        cnt+=1\n",
    "    return (ret/cnt)\n",
    "\n",
    "\n",
    "def getUserRatings(userId):\n",
    "    ret = []\n",
    "    for item in userDict[userId]:\n",
    "        ret.append(float(item[2]))\n",
    "    return ret\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for key in combinedCorpus.keys():\n",
    "\n",
    "    count_matrix = CountVectorizer().fit_transform(combinedCorpus[key]).toarray().tolist()\n",
    "    randIndex = random.randint(0, len(count_matrix)-1)\n",
    "    randTestItem = count_matrix[randIndex]\n",
    "    del count_matrix[randIndex]\n",
    "\n",
    "    #find similarity with the count of each word between the random movie and the other movies\n",
    "    cosine_sim = cosine_similarity(X = count_matrix ,Y = [randTestItem])\n",
    "\n",
    "    ratings = copy.deepcopy(getUserRatings(key))\n",
    "    randomRating = ratings[randIndex]\n",
    "    del ratings[randIndex]\n",
    "\n",
    "\n",
    "    similairities = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "    averageRating =  sum(ratings)/(len(ratings))\n",
    "\n",
    "    #populate features (more detail in paper)\n",
    "    features = []\n",
    "\n",
    "    features.append(getAverageMovieRatings(userDict[key][randIndex][1]))\n",
    "    features.append(averageRating)\n",
    "    features.append(sum(similairities)/(len(similairities)))\n",
    "    features.append(statistics.variance(ratings))\n",
    "    features.append(statistics.variance(similairities))\n",
    "\n",
    "    skew1= skew(ratings)\n",
    "    skew2 = skew(similairities)\n",
    "    kurt1 = kurtosis(ratings)\n",
    "    kurt2 = kurtosis(similairities)\n",
    "\n",
    "\n",
    "    lst = []\n",
    "    for item in [skew1,skew2, kurt1, kurt2]:\n",
    "        if(math.isnan(item)):\n",
    "            lst.append(0)\n",
    "        else:   \n",
    "            lst.append(item)\n",
    "\n",
    "    features.append(lst[0])\n",
    "    features.append(lst[1])\n",
    "    features.append(lst[2])\n",
    "    features.append(lst[3])\n",
    "\n",
    "    totalRating = 0\n",
    "\n",
    "    for sim, rating in zip(similairities, ratings):\n",
    "        totalRating += sim*(rating-averageRating)\n",
    "    \n",
    "\n",
    "    features.append(totalRating)\n",
    "    X.append(features)\n",
    "    y.append(randomRating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores:\n",
      "[0.23190825 0.23378539 0.2654336  0.13857587 0.19720419]\n",
      "mean score:\n",
      "0.21338145819859541\n",
      "layers:\n",
      "(50, 50, 50)\n",
      "activation function:\n",
      "tanh\n",
      "solver:\n",
      "adam\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "layers = (50, 50, 50)\n",
    "act = \"tanh\"\n",
    "solve = \"adam\"\n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes=layers,activation =act, solver =solve,  max_iter=1000, random_state =1)\n",
    "\n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "scores = cross_val_score(regr, X, y, cv = k_folds)\n",
    "\n",
    "print(\"cross validation scores:\")\n",
    "print(scores)\n",
    "print(\"mean score:\")\n",
    "print(scores.mean())\n",
    "print(\"layers:\")\n",
    "print(layers)\n",
    "print(\"activation function:\")\n",
    "print(act)\n",
    "print(\"solver:\")\n",
    "print(solve)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
