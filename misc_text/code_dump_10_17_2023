#this operation is too much at once....
# complete_array = np.array(complete_list_no_dups)

#another idea...
# complete_list = []
# gaps = []

# list_of_user_ids = list(complete["userId"].unique())

# for user_id in list_of_user_ids:
#     rows = complete.loc[complete['userId'] == user_id].drop_duplicates(subset = "id").values.tolist()
#     complete_list.extend(rows)
#     gaps.append(len(rows))

# #can there be multiple data type per line???
# complete_array = np.asarray(complete_list)

#another idea...
# for user_id in list_of_user_ids:
#     #is this faster than iteration when the users are already sorted???
#     #should test this!!!
#     user_list = list(complete.loc[complete['column_name'] == user_id])
#     movie_set = set()
#     number_of_movies_for_user = 0
#     for item in user_list:
#         if(item not in movie_set):
#             movie_set.add(item)
#             number_of_movies_for_user+=1
#         else:
#             #record index of the movie so it can be removed
#             #ideally all at once
#             #this canbe done right after complete_array is created
#             filler =0           
#     if number_of_movies_for_user == 0:
#         #record index of the list_of_user_ids so it can be removes
#         #ideally all at once
#         #this condition can replace what is below!!!
#         #also need to remove all the rows from complete array that have this user id!!!
#         filler =0



#original idea that does not work to remove duplicates:

#transform dataframe data frame into numpy array
# complete_array = complete.to_numpy()
#a list of the unique user ids
# list_of_user_ids = list(complete["userId"].unique())
#a dictionary of user ids to the number of ratings with that id
# counts = complete['userId'].value_counts()
#gaps is a list of the number of movies each user rated where a user corresponds with the index
# gaps = [counts[id] for id in list_of_user_ids]



#this is the minimum number of ratings a user must have to be tested
#this can be altered to fully test more realistic senarios
#for instance: what if test users dont have close to 100 ratings???
#test items: 2, 100

#orginal idea:

# min_number_of_users = 2
# complete_arr_index = 0
# index = 0
# items_to_remove = []

# # this enforces min number of ratings:
# for _ in range(len(gaps)):
#     if gaps[index] < min_number_of_users:
#         items_to_remove.extend(list(range(complete_arr_index,complete_arr_index + gaps[index])))
#         complete_arr_index+=gaps[index]
#         del gaps[index]
#         del list_of_user_ids[index]
#     else:
#         complete_arr_index+=gaps[index]
#         index+=1
    
# complete_array = np.delete(complete_array, items_to_remove, axis=0)



#this is for testing whether a movie is rated twice for any single user:
# for item in user_to_data:
#     movie_ids_set = set()
#     movie_ids_list = []
#     for movie_row in item:
#         movie_ids_set.add(movie_row[1])
#         movie_ids_list.append(movie_row[1])  
#     if(len(movie_ids_list)>len(movie_ids_set)):
#         print("error")



        # #these are the scaled versions of variables directly above
        # #these are only relevant with user averages scalings opposed to movie average scaling...
        # #note currently being used
        # word_counts_transformed = []
        # target_word_counts_transformed = []

#word count sums for each word in users_words_in_order for each user
        # sums = dict()

        # #for each movie the user watched record the wordcount for each word in users_words_in_order
        # for movie_id in movie_id_to_words.keys():
        #     if movie_id != user_to_target_movie_id[-1]:
        #         temp_dict = Counter(movie_id_to_words[movie_id])
        #         temp_list = []
        #         # sum = 0
        #         for word in users_words_in_order:
        #             if word in temp_dict.keys():
        #                 temp_list.append(temp_dict[word])
        #                 # sum+=temp_dict[word]
        #                 if word in sums.keys():
        #                     sums[word] += temp_dict[word] 
        #                 else:
        #                     sums[word] = temp_dict[word] 
        #             else:
        #                 temp_list.append(0) 
        #                 if word not in sums.keys():
        #                     sums[word] = 0  

        #         word_counts.append(temp_list)  

        #         # append to word_counts_transformed:
        #         # avg = float(sum/len(users_words_in_order))
        #         # word_counts_transformed.append([x - avg for x in temp_list])
        #     else:

        #         temp_dict = Counter(movie_id_to_words[movie_id])
        #         temp_list = []
        #         # sum = 0
        #         for word in users_words_in_order:
        #             if word in temp_dict.keys():
        #                 temp_list.append(temp_dict[word])
        #                 # sum+=temp_dict[word]
        #                 if word in sums.keys():
        #                     sums[word] += temp_dict[word] 
        #                 else:
        #                     sums[word] = temp_dict[word]             
        #             else:
        #                 temp_list.append(0) 
        #                 if word not in sums.keys():
        #                     sums[word] = 0 

        #         target_word_counts = temp_list

        #         # set target_word_counts_transformed:
        #         # avg = float(sum/len(users_words_in_order))
        #         # target_word_counts_transformed = [x - avg for x in temp_list]


#LOOK:
#what if there is no movie_id == user_to_target_movie_id[i]
#this can happen when a test users target movie is not in the train_users.movies_in_order...


#solution:

#this could be run once with only train_movies
#and then used to populate the train svd
#and then extract the prediction to train the model


#then again with all movies train_movies + test_movies
#then used to populate the full svd
#and then extract the prediction to test model


#note: movie_id_to_average_rating_train should only be used for the train run of this function
#for the test version of the this movie_id_to_average_rating_full should be used