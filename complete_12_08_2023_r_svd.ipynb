{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data source\n",
    "\n",
    "* Download the data needed for this jupyter notebook from kaggle and store it in a new folder (the-movies-dataset) in the current directory.\n",
    "\n",
    "\n",
    "* Upon running this cell, the user will be asked for their username and key which can be found in a fresh api token from kaggle.\n",
    "\n",
    "* Instructions to get api token to authenticate the data request (Note: kaggle account required):\n",
    "    1. Sign into kaggle.\n",
    "    2. Go to the 'Account' tab of your user profile and select 'Create New Token'. \n",
    "    3. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
    "\n",
    "* If the folder has been created and the files are already in that folder, than this cell does nothing and requires no credentials.\n",
    "\n",
    "* Data Source Information: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?select=movies_metadata.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:Downloading the-movies-dataset.zip to ./the-movies-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228M/228M [00:23<00:00, 10.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Raw Data\n",
    "\n",
    "Combining certain data from the necessary csv files into a single dataframe (complete_df).\n",
    "\n",
    "* Rows are removed from each dataframe when they do not have sufficent data for a column or the data from a column does not exist.\n",
    "* This kind of row removal is done before multiple copies of the same movie data becomes present in multple rows, to save time and space.\n",
    "* Iteration through rows of a dataframe at this level is inefficient compared to list iteration.\n",
    "* This is why the dataframes are converted into lists before iteration and then back again to dataframes, so the merge function can be applied to combine the data into a single dataframe (complete_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes taken: 0.04170004924138387\n",
      "      userId    id rating                           title  \\\n",
      "10151      1  2105    4.0                    American Pie   \n",
      "9353       1  1371    2.5                       Rocky III   \n",
      "12209      1  2193    2.0                        My Tutor   \n",
      "15297      1  2294    2.0  Jay and Silent Bob Strike Back   \n",
      "24848     10  1690    3.0                          Hostel   \n",
      "\n",
      "                                                                                              genres  \\\n",
      "10151                               [{'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "9353                                                                   [{'id': 18, 'name': 'Drama'}]   \n",
      "12209  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "15297                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "24848                                                                 [{'id': 27, 'name': 'Horror'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                         production_companies  \\\n",
      "10151                                                                 [{'name': 'Universal Pictures', 'id': 33}, {'name': 'Summit Entertainment', 'id': 491}, {'name': 'Newmarket Capital Group', 'id': 506}, {'name': 'Zide-Perry Productions', 'id': 3169}]   \n",
      "9353                                                                                                                                                                                                                   [{'name': 'United Artists', 'id': 60}]   \n",
      "12209                                                                                                                                                    [{'name': 'Crown International Pictures', 'id': 1009}, {'name': 'Marimark Productions', 'id': 1010}]   \n",
      "15297                                                                                                                            [{'name': 'Dimension Films', 'id': 7405}, {'name': 'View Askew Productions', 'id': 16934}, {'name': 'Miramax', 'id': 53009}]   \n",
      "24848  [{'name': 'International Production Company', 'id': 1507}, {'name': 'Raw Nerve', 'id': 1631}, {'name': 'Lionsgate', 'id': 1632}, {'name': 'Next Entertainment', 'id': 1633}, {'name': 'Screen Gems', 'id': 3287}, {'name': 'Hostel LLC', 'id': 17793}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 keywords  \\\n",
      "10151                                   [{'id': 3687, 'name': 'graduation'}, {'id': 6139, 'name': 'innocence'}, {'id': 10683, 'name': 'coming of age'}, {'id': 13130, 'name': 'teenager'}, {'id': 33910, 'name': 'high school student'}, {'id': 44447, 'name': 'pie'}, {'id': 155722, 'name': 'teen comedy'}, {'id': 156777, 'name': 'teenage sexuality'}, {'id': 160140, 'name': 'exchange student'}, {'id': 167310, 'name': 'sitting on a toilet'}, {'id': 178649, 'name': 'voyeurism'}, {'id': 208445, 'name': 'virginity'}, {'id': 215404, 'name': 'laxative'}, {'id': 226226, 'name': 'prom night'}]   \n",
      "9353                                [{'id': 396, 'name': 'transporter'}, {'id': 1482, 'name': 'trainer'}, {'id': 2792, 'name': 'boxer'}, {'id': 3737, 'name': 'dying and death'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5394, 'name': 'rematch'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 6075, 'name': 'sport'}, {'id': 9748, 'name': 'revenge'}, {'id': 10232, 'name': 'fame'}, {'id': 10329, 'name': 'wealth'}]   \n",
      "12209                                                                                                                                                                                                                                                                                                                                                                                                                                                     [{'id': 6274, 'name': 'learning and teaching'}, {'id': 18015, 'name': 'tutor'}, {'id': 157799, 'name': 'older woman younger man relationship'}]   \n",
      "15297                                                                                                                            [{'id': 886, 'name': 'film making'}, {'id': 168033, 'name': 'jay and silent bob'}, {'id': 168039, 'name': 'self mocking'}, {'id': 168040, 'name': 'character is subject of comic'}, {'id': 168042, 'name': 'reference to prince valiant'}, {'id': 168049, 'name': 'indiana jones spoof scene'}, {'id': 168051, 'name': 'monkey actor'}, {'id': 168054, 'name': 'view askew'}, {'id': 168063, 'name': 'gigantic hand'}, {'id': 168069, 'name': 'animal experimentation'}]   \n",
      "24848  [{'id': 472, 'name': 'bathroom'}, {'id': 572, 'name': 'sex'}, {'id': 587, 'name': 'amsterdam'}, {'id': 1295, 'name': 'europe'}, {'id': 1411, 'name': 'brothel'}, {'id': 5689, 'name': 'slovakia'}, {'id': 5891, 'name': 'backpacker'}, {'id': 8087, 'name': 'horror'}, {'id': 10292, 'name': 'gore'}, {'id': 11221, 'name': 'blood'}, {'id': 13006, 'name': 'torture'}, {'id': 155955, 'name': 'business card'}, {'id': 156149, 'name': 'doberman'}, {'id': 157958, 'name': 'hostel'}, {'id': 157959, 'name': 'surgery'}, {'id': 198438, 'name': 'elite club'}, {'id': 198441, 'name': 'fingers'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          cast  \\\n",
      "10151  [{'cast_id': 16, 'character': 'Jim Levenstein', 'credit_id': '52fe4336c3a36847f8042cb7', 'gender': 2, 'id': 21593, 'name': 'Jason Biggs', 'order': 0, 'profile_path': '/7CcISIHMvpzcUVo4NmxgA6f71RQ.jpg'}, {'cast_id': 17, 'character': \"Chris 'Oz' Ostreicher\", 'credit_id': '52fe4336c3a36847f8042cbb', 'gender': 2, 'id': 21594, 'name': 'Chris Klein', 'order': 1, 'profile_path': '/foKh17RAUIhmfNgZ3TIvHJrNkDR.jpg'}, {'cast_id': 18, 'character': 'Kevin Meyers', 'credit_id': '52fe4336c3a36847f8042cbf', 'gender': 2, 'id': 21403, 'name': 'Thomas Ian Nicholas', 'order': 2, 'profile_path': '/tYiQ6Ift5S8ZVeWQ8f7CJnQLkT.jpg'}, {'cast_id': 19, 'character': 'Michelle Flaherty', 'credit_id': '52fe4336c3a36847f8042cc3', 'gender': 1, 'id': 21595, 'name': 'Alyson Hannigan', 'order': 3, 'profile_path': '/vZw7AEUOs9lbkS0lYzDyaFp9Tjv.jpg'}, {'cast_id': 20, 'character': 'Nadia', 'credit_id': '52fe4336c3a36847f8042cc7', 'gender': 1, 'id': 21596, 'name': 'Shannon Elizabeth', 'order': 4, 'profile_path': '/c7l0KsU2PAXXseofmSvsmIMQH1N.jpg'}, {'cast_id': 21, 'character': \"Victoria 'Vicky' Lathum\", 'credit_id': '52fe4336c3a36847f8042ccb', 'gender': 1, 'id': 1234, 'name': 'Tara Reid', 'order': 5, 'profile_path': '/9nI9GsV1HZS3YKvMqrGuuEYWr8v.jpg'}, {'cast_id': 27, 'character': 'Paul Finch', 'credit_id': '52fe4336c3a36847f8042cdf', 'gender': 2, 'id': 52480, 'name': 'Eddie Kaye Thomas', 'order': 6, 'profile_path': '/6XCAQSm73OyMK7zh6LJ6XUdfYZV.jpg'}, {'cast_id': 23, 'character': 'Steve Stifler', 'credit_id': '52fe4336c3a36847f8042ccf', 'gender': 2, 'id': 57599, 'name': 'Seann William Scott', 'order': 7, 'profile_path': '/c7iqFLkgNiTMAS9xGw0GlfJcm4H.jpg'}, {'cast_id': 25, 'character': \"Jim's Father\", 'credit_id': '52fe4336c3a36847f8042cd7', 'gender': 2, 'id': 26510, 'name': 'Eugene Levy', 'order': 8, 'profile_path': '/69IBiDjU1gSqtrcGOA7PA7aEYsc.jpg'}, {'cast_id': 28, 'character': 'Jessica', 'credit_id': '52fe4336c3a36847f8042ce3', 'gender': 1, 'id': 10871, 'name': 'Natasha Lyonne', 'order': 9, 'profile_path': '/8rhl25eCPQQFhv1Mvqe9eMP3MpS.jpg'}, {'cast_id': 26, 'character': 'Heather', 'credit_id': '52fe4336c3a36847f8042cdb', 'gender': 1, 'id': 8211, 'name': 'Mena Suvari', 'order': 10, 'profile_path': '/xnc7WgBvfefwu3nJ5IkCjQrhPz0.jpg'}, {'cast_id': 24, 'character': \"Stifler's Mom\", 'credit_id': '52fe4336c3a36847f8042cd3', 'gender': 1, 'id': 38334, 'name': 'Jennifer Coolidge', 'order': 11, 'profile_path': '/jOVVWdfxLQ9MOumqM3VxiwAlT9a.jpg'}, {'cast_id': 29, 'character': 'Chuck Sherman', 'credit_id': '52fe4336c3a36847f8042ce7', 'gender': 2, 'id': 26999, 'name': 'Chris Owen', 'order': 12, 'profile_path': '/1E23sADcIzpaRhsUHiAWMfvOPFm.jpg'}, {'cast_id': 31, 'character': 'Albert', 'credit_id': '53bc249a0e0a26196b003158', 'gender': 2, 'id': 53116, 'name': 'Eric Lively', 'order': 13, 'profile_path': '/wEl6qozyL6UrjsNcMmAG2T2r9n0.jpg'}, {'cast_id': 32, 'character': \"Jim's Mother\", 'credit_id': '53bc24bb0e0a26196e003189', 'gender': 1, 'id': 54586, 'name': 'Molly Cheek', 'order': 14, 'profile_path': '/47iPOiKc0otACk0vIDm6VnlQBO6.jpg'}, {'cast_id': 33, 'character': 'John', 'credit_id': '53bc2b30c3a368661e00268c', 'gender': 2, 'id': 68842, 'name': 'John Cho', 'order': 15, 'profile_path': '/wlA5pkKGun8BS7GjCqXrzthTOk4.jpg'}, {'cast_id': 34, 'character': 'Justin', 'credit_id': '53bc2b48c3a36866280025ce', 'gender': 2, 'id': 88507, 'name': 'Justin Isfeld', 'order': 16, 'profile_path': '/4N5wxIkEzBEHbh1mNu9wyfgmGHO.jpg'}, {'cast_id': 35, 'character': 'Matt Stifler', 'credit_id': '53bc2b6ec3a368661e002691', 'gender': 2, 'id': 116027, 'name': 'Eli Marienthal', 'order': 17, 'profile_path': '/eK4kfRpE12lCoCamBJWyHfWDDbq.jpg'}, {'cast_id': 41, 'character': 'College Girl', 'credit_id': '5634071bc3a3681b5e0154c0', 'gender': 1, 'id': 61111, 'name': 'Tara Subkoff', 'order': 18, 'profile_path': '/qBbSymmytAOqgAGlll3sN5LXih3.jpg'}, {'cast_id': 42, 'character': 'Coach Marshall', 'credit_id': '56ac7f94c3a3681c4700596c', 'gender': 2, 'id': 6564, 'name': 'Lawrence Pressman', 'order': 19, 'profile_path': '/mot6LcTgUnZKd1U60iZNxytNpdQ.jpg'}, {'cast_id': 43, 'character': 'English Teacher', 'credit_id': '56ac7fb99251417c980017a7', 'gender': 2, 'id': 2249, 'name': 'Clyde Kusatsu', 'order': 20, 'profile_path': '/gM5vHl3hl0CgKJxeqwjyeOdhzjP.jpg'}, {'cast_id': 44, 'character': 'Band Member', 'credit_id': '56ac7fd2c3a3681c3f005f58', 'gender': 1, 'id': 37936, 'name': 'Christina Milian', 'order': 21, 'profile_path': '/8qWk7ZELhhHKG8HD0yse0QomzkA.jpg'}, {'cast_id': 45, 'character': 'Party Guy', 'credit_id': '56ac7fea9251410e8f00519d', 'gender': 0, 'id': 42288, 'name': 'Woody Schultz', 'order': 22, 'profile_path': '/AjzkMGiWGnG27W1JTDWDGYn8TP.jpg'}, {'cast_id': 46, 'character': 'Sarah, the Sophomore Chick', 'credit_id': '56ac801ac3a3681c310055f0', 'gender': 1, 'id': 217524, 'name': 'Eden Riegel', 'order': 23, 'profile_path': '/wMcRg3Y0x70U1vFoK0hBY7zS20E.jpg'}, {'cast_id': 53, 'character': 'Vocal Jazz Teacher', 'credit_id': '575f89329251415e27001230', 'gender': 1, 'id': 184340, 'name': 'Akuyoe Graham', 'order': 24, 'profile_path': '/jLp7Va2a7QrqUoxZ8jhNO6Y67zc.jpg'}, {'cast_id': 47, 'character': 'Vocal Jazz Girl', 'credit_id': '56ac806c9251417e11005950', 'gender': 1, 'id': 76031, 'name': 'Veronica Lauren', 'order': 25, 'profile_path': '/cS8gnKZaY2vZrCje8U5OnNjwuLo.jpg'}, {'cast_id': 48, 'character': 'Vocal Jazz Girl', 'credit_id': '56ac81009251417e140058d0', 'gender': 1, 'id': 1225809, 'name': 'Monica McSwain', 'order': 26, 'profile_path': '/yDwvXIF6pv4gt6D5SLz0O865qsa.jpg'}, {'cast_id': 55, 'character': 'Vocal Jazz Group', 'credit_id': '5796b171c3a3680d18002bc1', 'gender': 2, 'id': 1656606, 'name': 'Fletcher Sheridan', 'order': 27, 'profile_path': '/1XV5vdVSFTvePXxQQg8ev3lspl6.jpg'}, {'cast_id': 56, 'character': 'Vocal Jazz Group', 'credit_id': '5796b203c3a368019e00080c', 'gender': 1, 'id': 1656607, 'name': 'Robyn Roth', 'order': 28, 'profile_path': '/bnDpJaw77N4RKLDkN58PB0rQUgA.jpg'}, {'cast_id': 57, 'character': 'Vocal Jazz Group', 'credit_id': '5796b2e2c3a3680a3c002844', 'gender': 2, 'id': 1656608, 'name': 'Jamar Cargo', 'order': 29, 'profile_path': '/i0HmerjCn2JlRIF79KdXWRBK5sW.jpg'}, {'cast_id': 49, 'character': 'Courtney, the Random Cute Girl', 'credit_id': '56ac8171c3a3681c54005766', 'gender': 1, 'id': 83585, 'name': 'Sasha Barrese', 'order': 30, 'profile_path': '/4SGcSiC46h86mdChDj0taF5eHSl.jpg'}, {'cast_id': 50, 'character': \"Vicky's Mom\", 'credit_id': '56ac81909251417e1100597e', 'gender': 1, 'id': 1394788, 'name': 'Linda Gehringer', 'order': 31, 'profile_path': '/hWRDJvcBLHu2iRCXSIBpmgvmPbG.jpg'}, {'cast_id': 51, 'character': 'Bathroom Girl', 'credit_id': '56ac81bf9251410e8f0051de', 'gender': 1, 'id': 61219, 'name': 'Jillian Bach', 'order': 32, 'profile_path': '/8P4y1ndyTCVltT20zB5kFkPO9OC.jpg'}, {'cast_id': 52, 'character': 'Enthralled Girl', 'credit_id': '56ac846f9251410e8f005257', 'gender': 0, 'id': 1570015, 'name': 'Katie Lansdale', 'order': 33, 'profile_path': '/qT0Z1rzSpcA2zM2c7G5XddFnR7W.jpg'}, {'cast_id': 54, 'character': 'Enthusiastic Guy', 'credit_id': '575f89a09251415e250011d6', 'gender': 2, 'id': 35768, 'name': 'James DeBello', 'order': 34, 'profile_path': '/xhDScFpgfM9gfIyNQm8KOr0qEU5.jpg'}, {'cast_id': 58, 'character': 'Computer Nerd', 'credit_id': '5796b384c3a3680c9e00289e', 'gender': 2, 'id': 1656609, 'name': 'Travis Cody Aimer', 'order': 35, 'profile_path': '/nNVutDnAOHVCow5Y9BVFejQg5XZ.jpg'}, {'cast_id': 59, 'character': 'Garage Band Member', 'credit_id': '5796b459c3a3680a3c00292f', 'gender': 2, 'id': 234801, 'name': 'Mark Hoppus', 'order': 36, 'profile_path': '/lZjOBtpfBP6hB2olYcdDFAEmnKD.jpg'}, {'cast_id': 60, 'character': 'Garage Band Member', 'credit_id': '5796b4aec3a3680c9e00294c', 'gender': 2, 'id': 84546, 'name': 'Tom DeLonge', 'order': 37, 'profile_path': '/2hQjktJFvDvcERPE7adlWgA4EMS.jpg'}, {'cast_id': 61, 'character': 'Guy with Monkey', 'credit_id': '5796b6009251417e31002a29', 'gender': 2, 'id': 1517843, 'name': 'Daniel Spink', 'order': 38, 'profile_path': '/gTKbwBbN9Ipo3Bo9zhfL5rE97nb.jpg'}, {'cast_id': 62, 'character': 'Computer Girl', 'credit_id': '5796b8ebc3a368019e000c41', 'gender': 1, 'id': 1223965, 'name': 'Clementine Ford', 'order': 39, 'profile_path': '/mtyqtAjmSMs5kARn4nUV19aQZ83.jpg'}, {'cast_id': 65, 'character': 'Drinking Buddy', 'credit_id': '579e61a9c3a3683d66002ec3', 'gender': 2, 'id': 1659340, 'name': 'Casey Erklin', 'order': 41, 'profile_path': '/uOJFGrNeC4Cod2qczr4gAwGdhDq.jpg'}, {'cast_id': 64, 'character': 'Tom Myers (uncredited)', 'credit_id': '5796bc969251417e31002e8e', 'gender': 2, 'id': 1893, 'name': 'Casey Affleck', 'order': 42, 'profile_path': '/kPNMpiZHsAzeQar4DiNsrekwHBU.jpg'}, {'cast_id': 135, 'character': 'Girl Holding Out', 'credit_id': '598160ce92514151e000c5d8', 'gender': 1, 'id': 1217828, 'name': 'Hilary Angelo', 'order': 43, 'profile_path': '/tvRt3k1ZG6BIN6fO8HgKAM4LWJQ.jpg'}]   \n",
      "9353                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'cast_id': 21, 'character': 'Rocky Balboa', 'credit_id': '52fe42f0c3a36847f802e547', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 22, 'character': 'Adrianna \"Adrian\" Pennino Balboa', 'credit_id': '52fe42f0c3a36847f802e54b', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 1, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 23, 'character': 'Paulie', 'credit_id': '52fe42f0c3a36847f802e54f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 2, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 24, 'character': 'Apollo Creed', 'credit_id': '52fe42f0c3a36847f802e553', 'gender': 0, 'id': 1101, 'name': 'Carl Weathers', 'order': 3, 'profile_path': '/xOpDfVa83R1EdiNkWPNITfCH67e.jpg'}, {'cast_id': 25, 'character': 'Mickey Goldmill', 'credit_id': '52fe42f0c3a36847f802e557', 'gender': 2, 'id': 16523, 'name': 'Burgess Meredith', 'order': 4, 'profile_path': '/lm98oKloU33Q7QDIIMSyc4Pr2jA.jpg'}, {'cast_id': 26, 'character': 'Duke', 'credit_id': '52fe42f0c3a36847f802e55b', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 27, 'character': 'Clubber Lang', 'credit_id': '52fe42f0c3a36847f802e55f', 'gender': 2, 'id': 16619, 'name': 'Mr. T', 'order': 6, 'profile_path': '/l594jKabKzYsak9hoCZ4bUrUv4R.jpg'}, {'cast_id': 28, 'character': 'Thunderlips', 'credit_id': '52fe42f0c3a36847f802e563', 'gender': 2, 'id': 16620, 'name': 'Hulk Hogan', 'order': 7, 'profile_path': '/jDWQ3FLbbPSIHPgfOdmuUaWWnON.jpg'}, {'cast_id': 29, 'character': 'Rocky Junior', 'credit_id': '52fe42f0c3a36847f802e567', 'gender': 2, 'id': 16621, 'name': 'Ian Fried', 'order': 8, 'profile_path': None}, {'cast_id': 30, 'character': 'Al', 'credit_id': '52fe42f0c3a36847f802e56b', 'gender': 2, 'id': 16528, 'name': 'Al Silvani', 'order': 9, 'profile_path': '/tHjzbzaPTDPvkewRwmiXH0zQkdI.jpg'}, {'cast_id': 31, 'character': \"Clubber Lang's manager\", 'credit_id': '52fe42f0c3a36847f802e56f', 'gender': 2, 'id': 6771, 'name': 'Wally Taylor', 'order': 10, 'profile_path': '/nqUN3VZYRiuLRFflvdl50z7Qbsc.jpg'}, {'cast_id': 32, 'character': 'Sportscaster', 'credit_id': '52fe42f0c3a36847f802e573', 'gender': 2, 'id': 16622, 'name': 'Jim Hill', 'order': 11, 'profile_path': None}, {'cast_id': 33, 'character': 'Andy', 'credit_id': '52fe42f0c3a36847f802e577', 'gender': 0, 'id': 16623, 'name': 'Don Sherman', 'order': 12, 'profile_path': '/2C9xC0gyEsmc8xThYh1067RrlZR.jpg'}, {'cast_id': 34, 'character': 'Wrestling commentator 1', 'credit_id': '52fe42f0c3a36847f802e57b', 'gender': 0, 'id': 16624, 'name': 'Dennis James', 'order': 13, 'profile_path': None}, {'cast_id': 35, 'character': 'Wrestling commentator 2', 'credit_id': '52fe42f0c3a36847f802e57f', 'gender': 0, 'id': 16625, 'name': 'Jim Healy', 'order': 14, 'profile_path': None}]   \n",
      "12209                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [{'cast_id': 15, 'character': 'Terry Green', 'credit_id': '52fe433fc3a36847f8045b6f', 'gender': 1, 'id': 22489, 'name': 'Caren Kaye', 'order': 0, 'profile_path': '/u4gW48n5zvCoqAPtHZ7LGMOGDtA.jpg'}, {'cast_id': 16, 'character': 'Bobby Chrystal', 'credit_id': '52fe433fc3a36847f8045b73', 'gender': 0, 'id': 22490, 'name': 'Matt Lattanzi', 'order': 1, 'profile_path': '/ewiB9BXaynLLibBXIrL56DTzOpL.jpg'}, {'cast_id': 23, 'character': 'Mr. Chrystal', 'credit_id': '52fe433fc3a36847f8045b8b', 'gender': 2, 'id': 34597, 'name': 'Kevin McCarthy', 'order': 2, 'profile_path': '/kNEsGIBVMsKXB8qN6W2pFt4Wh8S.jpg'}, {'cast_id': 18, 'character': 'Billy', 'credit_id': '52fe433fc3a36847f8045b77', 'gender': 0, 'id': 22492, 'name': 'Clark Brandon', 'order': 3, 'profile_path': '/xZSzwIJz1zHzbxx4FJBt5iHMHAx.jpg'}, {'cast_id': 19, 'character': 'Don Sylvester', 'credit_id': '52fe433fc3a36847f8045b7b', 'gender': 2, 'id': 22493, 'name': 'Bruce Bauer', 'order': 4, 'profile_path': None}, {'cast_id': 20, 'character': 'Mrs Chrystal', 'credit_id': '52fe433fc3a36847f8045b7f', 'gender': 1, 'id': 22494, 'name': 'Arlene Golonka', 'order': 5, 'profile_path': '/70esvtnNyb5LYOdJQZaSRo3lV8K.jpg'}, {'cast_id': 21, 'character': 'Jack', 'credit_id': '52fe433fc3a36847f8045b83', 'gender': 2, 'id': 1064, 'name': 'Crispin Glover', 'order': 6, 'profile_path': '/thA5rOv5XE1oFpxD9DSp0tDrIIR.jpg'}, {'cast_id': 22, 'character': 'Bonnie', 'credit_id': '52fe433fc3a36847f8045b87', 'gender': 0, 'id': 22495, 'name': 'Amber Denyse Austin', 'order': 7, 'profile_path': None}, {'cast_id': 30, 'character': 'Sylvia', 'credit_id': '551ad360c3a3687666000076', 'gender': 0, 'id': 19180, 'name': 'Graem McGavin', 'order': 8, 'profile_path': None}, {'cast_id': 31, 'character': 'Manuel', 'credit_id': '58f33d459251413d6e00faf3', 'gender': 2, 'id': 104505, 'name': 'John Vargas', 'order': 9, 'profile_path': None}, {'cast_id': 32, 'character': 'Maria', 'credit_id': '58f33d5f9251413da700ee65', 'gender': 0, 'id': 1330738, 'name': 'Maria Melendez', 'order': 10, 'profile_path': None}, {'cast_id': 33, 'character': 'Mud Wrestler (as Kathleen Shea)', 'credit_id': '58f33d6f9251413da700ee78', 'gender': 1, 'id': 102634, 'name': 'Katt Shea', 'order': 11, 'profile_path': None}, {'cast_id': 34, 'character': 'Mrs. Fontana', 'credit_id': '58f33d7b9251413d8400f135', 'gender': 1, 'id': 165570, 'name': 'Brioni Farrell', 'order': 12, 'profile_path': '/nGeaC19WcWCd1Vxeo5yQyPpiO75.jpg'}, {'cast_id': 35, 'character': 'Louisa', 'credit_id': '58f33d85c3a36807bd00d301', 'gender': 1, 'id': 1178618, 'name': 'Shelley Taylor Morgan', 'order': 13, 'profile_path': '/lmPzjiZZqwb3N7CYrJWnyYa0oeM.jpg'}, {'cast_id': 27, 'character': 'Ana Maria', 'credit_id': '52fe433fc3a36847f8045ba1', 'gender': 1, 'id': 41711, 'name': 'Kitten Natividad', 'order': 14, 'profile_path': '/m3wYX0x4ED2shOSYxJ0lqyLvT65.jpg'}, {'cast_id': 36, 'character': 'Biker Boyfriend', 'credit_id': '58f33d91c3a368084500ef60', 'gender': 2, 'id': 156504, 'name': 'Rex Ryon', 'order': 15, 'profile_path': None}, {'cast_id': 37, 'character': 'Girl in Phone Booth', 'credit_id': '58f33da0c3a368086700f822', 'gender': 1, 'id': 106669, 'name': 'Jewel Shepard', 'order': 16, 'profile_path': '/1KinI5YRvHRt3kiF7vscTlbI5py.jpg'}, {'cast_id': 38, 'character': 'Aerobics Instructor', 'credit_id': '58f33dafc3a368081e00f090', 'gender': 1, 'id': 137347, 'name': 'Marilyn Tokuda', 'order': 17, 'profile_path': None}]   \n",
      "15297                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [{'cast_id': 9, 'character': 'Silent Bob', 'credit_id': '52fe434bc3a36847f80493d9', 'gender': 2, 'id': 19303, 'name': 'Kevin Smith', 'order': 0, 'profile_path': '/3XXThSMqHQgQFjM4bMJ25U1EJTj.jpg'}, {'cast_id': 10, 'character': 'Jay', 'credit_id': '52fe434bc3a36847f80493dd', 'gender': 2, 'id': 19302, 'name': 'Jason Mewes', 'order': 1, 'profile_path': '/so3nT2vgSCZMO2QXDVHF3ubxaFX.jpg'}, {'cast_id': 11, 'character': 'Holden McNeil/Himself', 'credit_id': '52fe434bc3a36847f80493e1', 'gender': 2, 'id': 880, 'name': 'Ben Affleck', 'order': 2, 'profile_path': '/cPuPt6mYJ83DjvO3hbjNGug6Fbi.jpg'}, {'cast_id': 12, 'character': 'Randal Graves', 'credit_id': '52fe434bc3a36847f80493e5', 'gender': 2, 'id': 23630, 'name': 'Jeff Anderson', 'order': 3, 'profile_path': '/vjt5WhpJAx0jxvmiGc5PAOBzzb7.jpg'}, {'cast_id': 13, 'character': 'Dante Hicks', 'credit_id': '52fe434bc3a36847f80493e9', 'gender': 2, 'id': 23629, 'name': \"Brian O'Halloran\", 'order': 4, 'profile_path': '/eJsLxovTdcm6QK9PDB2pCe5FMqK.jpg'}, {'cast_id': 14, 'character': 'Justice', 'credit_id': '52fe434bc3a36847f80493ed', 'gender': 1, 'id': 21596, 'name': 'Shannon Elizabeth', 'order': 5, 'profile_path': '/c7l0KsU2PAXXseofmSvsmIMQH1N.jpg'}, {'cast_id': 15, 'character': 'Sissy', 'credit_id': '52fe434bc3a36847f80493f1', 'gender': 1, 'id': 13446, 'name': 'Eliza Dushku', 'order': 6, 'profile_path': '/drQXyoKMVf4IJsCdmnOXpzhBEYL.jpg'}, {'cast_id': 16, 'character': 'Chrissy', 'credit_id': '52fe434bc3a36847f80493f5', 'gender': 1, 'id': 17303, 'name': 'Ali Larter', 'order': 7, 'profile_path': '/bREO6OEipl4y077K0mdBUXVuE3i.jpg'}, {'cast_id': 17, 'character': 'Missy', 'credit_id': '52fe434bc3a36847f80493f9', 'gender': 0, 'id': 23658, 'name': 'Jennifer Schwalbach Smith', 'order': 8, 'profile_path': '/zHyO6fOC7NznQIG2Lg0U1oDizY5.jpg'}, {'cast_id': 18, 'character': 'Federal Wildlife Marshal Willenholly', 'credit_id': '52fe434bc3a36847f80493fd', 'gender': 2, 'id': 23659, 'name': 'Will Ferrell', 'order': 9, 'profile_path': '/jwKrNtRCRqPYHtb5I525VKN1pjv.jpg'}, {'cast_id': 19, 'character': 'Brodie Bruce/Banky Edwards', 'credit_id': '52fe434bc3a36847f8049401', 'gender': 2, 'id': 11662, 'name': 'Jason Lee', 'order': 10, 'profile_path': '/67wSoVHxlOqtRhh3KJFBYf2qrDJ.jpg'}, {'cast_id': 20, 'character': 'Sheriff', 'credit_id': '52fe434bc3a36847f8049405', 'gender': 2, 'id': 21624, 'name': 'Judd Nelson', 'order': 11, 'profile_path': '/9H1TSnBEDYl59tFC1EQHccrINsp.jpg'}, {'cast_id': 21, 'character': 'Hitchhiker', 'credit_id': '52fe434bc3a36847f8049409', 'gender': 2, 'id': 15903, 'name': 'George Carlin', 'order': 12, 'profile_path': '/xmSn6p5QVn66UK2ueEJisrUR5Bg.jpg'}, {'cast_id': 22, 'character': 'Nun', 'credit_id': '52fe434bc3a36847f804940d', 'gender': 1, 'id': 4, 'name': 'Carrie Fisher', 'order': 13, 'profile_path': '/pbleNurCYdrLFQMEnlQB2nkOR1O.jpg'}, {'cast_id': 23, 'character': 'Brent', 'credit_id': '52fe434bc3a36847f8049411', 'gender': 2, 'id': 57599, 'name': 'Seann William Scott', 'order': 14, 'profile_path': '/c7iqFLkgNiTMAS9xGw0GlfJcm4H.jpg'}, {'cast_id': 24, 'character': 'Reg Hartner', 'credit_id': '52fe434bc3a36847f8049415', 'gender': 2, 'id': 12219, 'name': 'Jon Stewart', 'order': 15, 'profile_path': '/88UHrwCXTPOrrsG2A33G4fMvN62.jpg'}, {'cast_id': 25, 'character': 'Cock-Knocker', 'credit_id': '52fe434bc3a36847f8049419', 'gender': 2, 'id': 2, 'name': 'Mark Hamill', 'order': 16, 'profile_path': '/ws544EgE5POxGJqq9LUfhnDrHtV.jpg'}, {'cast_id': 26, 'character': 'Alyssa Jones', 'credit_id': '52fe434bc3a36847f804941d', 'gender': 1, 'id': 16484, 'name': 'Joey Lauren Adams', 'order': 17, 'profile_path': '/hQqqcyUvLQwnqBYCdpGZIfKOpmO.jpg'}, {'cast_id': 27, 'character': 'Pumpkin Escobar', 'credit_id': '52fe434bc3a36847f8049421', 'gender': 2, 'id': 56903, 'name': 'Tracy Morgan', 'order': 18, 'profile_path': '/wXLPjDsy4SfqghEAJ8wybHh04nU.jpg'}, {'cast_id': 28, 'character': 'Himself', 'credit_id': '52fe434bc3a36847f8049425', 'gender': 2, 'id': 5216, 'name': 'Gus Van Sant', 'order': 19, 'profile_path': '/2WsDgxPivXtPHtsXK5QZ8U7zYEb.jpg'}, {'cast_id': 29, 'character': 'Herself', 'credit_id': '52fe434bc3a36847f8049429', 'gender': 1, 'id': 19144, 'name': 'Shannen Doherty', 'order': 20, 'profile_path': '/1q3BKF6vnOFUOCRier8hfH9Nyxo.jpg'}, {'cast_id': 30, 'character': 'Himself', 'credit_id': '52fe434bc3a36847f804942d', 'gender': 2, 'id': 5140, 'name': 'Wes Craven', 'order': 21, 'profile_path': '/vffssPtgNn2ZwoMfLCCDJAxlXGI.jpg'}, {'cast_id': 31, 'character': 'Chaka', 'credit_id': '52fe434bc3a36847f8049431', 'gender': 2, 'id': 2632, 'name': 'Chris Rock', 'order': 22, 'profile_path': '/5JCYKerIL0SdiqygtLUpG9Sw37P.jpg'}, {'cast_id': 32, 'character': 'Pizza Delivery Guy', 'credit_id': '52fe434bc3a36847f8049435', 'gender': 0, 'id': 1187909, 'name': 'Joe Quesada', 'order': 23, 'profile_path': None}, {'cast_id': 33, 'character': 'Himself', 'credit_id': '53b7be1cc3a3685ec10039c1', 'gender': 2, 'id': 1892, 'name': 'Matt Damon', 'order': 24, 'profile_path': '/elSlNgV8xVifsbHpFsqrPGxJToZ.jpg'}, {'cast_id': 34, 'character': 'Baby Silent Bob', 'credit_id': '553e0d329251413f5a009735', 'gender': 1, 'id': 576173, 'name': 'Harley Quinn Smith', 'order': 25, 'profile_path': '/aiPc3fRZ58fAZ0RmiVzuMIbiNGF.jpg'}, {'cast_id': 133, 'character': 'Himself', 'credit_id': '5835f4d4c3a36836ae001053', 'gender': 2, 'id': 57907, 'name': 'Morris Day', 'order': 26, 'profile_path': '/M6VI4lbmAHOQb9bx1qGyCEacXO.jpg'}, {'cast_id': 134, 'character': 'The Smoking Man', 'credit_id': '5835f4ecc3a36836a30011c0', 'gender': 2, 'id': 12643, 'name': 'William B. Davis', 'order': 27, 'profile_path': '/wXEF3GDoRXuYYdrtGlwvfkM6hQd.jpg'}, {'cast_id': 135, 'character': 'The Guy', 'credit_id': '58655a229251412b8d02032b', 'gender': 2, 'id': 46772, 'name': 'Marc Blucas', 'order': 28, 'profile_path': '/1pDk3uISYLyYOb8mHeyEbjqw7i.jpg'}]   \n",
      "24848                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'cast_id': 13, 'character': 'Paxton', 'credit_id': '52fe430cc3a36847f8036a43', 'gender': 2, 'id': 19487, 'name': 'Jay Hernandez', 'order': 0, 'profile_path': '/pRjNOpT41u5lIuNCoi9KAoWteqJ.jpg'}, {'cast_id': 14, 'character': 'Josh', 'credit_id': '52fe430cc3a36847f8036a47', 'gender': 2, 'id': 33934, 'name': 'Derek Richardson', 'order': 1, 'profile_path': '/xjBN6eAAhSmvR4bRfLo6olAncTe.jpg'}, {'cast_id': 15, 'character': 'Oli', 'credit_id': '52fe430cc3a36847f8036a4b', 'gender': 2, 'id': 33935, 'name': 'Eythor Gudjonsson', 'order': 2, 'profile_path': None}, {'cast_id': 16, 'character': 'Natalya', 'credit_id': '52fe430cc3a36847f8036a4f', 'gender': 1, 'id': 33936, 'name': 'Barbara Nedeljakova', 'order': 3, 'profile_path': '/kAS6W6nbliAUnJnvvAFaRtH7PLQ.jpg'}, {'cast_id': 17, 'character': 'Svetlana', 'credit_id': '52fe430cc3a36847f8036a53', 'gender': 0, 'id': 33937, 'name': 'Jana Kaderabkova', 'order': 4, 'profile_path': None}, {'cast_id': 18, 'character': 'The Dutch Businessman', 'credit_id': '52fe430cc3a36847f8036a57', 'gender': 2, 'id': 33938, 'name': 'Jan Vlasák', 'order': 5, 'profile_path': '/yEZ7y8caFgmAIx0QodLXhY95E9J.jpg'}, {'cast_id': 19, 'character': 'Alex', 'credit_id': '52fe430cc3a36847f8036a5b', 'gender': 0, 'id': 33939, 'name': 'Lubomir Bukovy', 'order': 6, 'profile_path': None}, {'cast_id': 20, 'character': 'Miike Takashi', 'credit_id': '52fe430cc3a36847f8036a5f', 'gender': 0, 'id': 17282, 'name': 'Takashi Miike', 'order': 7, 'profile_path': '/d8zPN3H8CKZHdVCpb7wWEm9L8l6.jpg'}, {'cast_id': 22, 'character': 'Yuki', 'credit_id': '52fe430cc3a36847f8036a67', 'gender': 0, 'id': 1265216, 'name': 'Keiko Seiko', 'order': 9, 'profile_path': None}, {'cast_id': 23, 'character': 'Vala', 'credit_id': '52fe430cc3a36847f8036a6b', 'gender': 0, 'id': 1265217, 'name': 'Jana Havlickova', 'order': 10, 'profile_path': None}, {'cast_id': 31, 'character': 'The American Client', 'credit_id': '52fe430cc3a36847f8036a91', 'gender': 2, 'id': 1216133, 'name': 'Rick Hoffman', 'order': 11, 'profile_path': '/owyhrI6Ozf8Jglkz4gXPxpJ8o3M.jpg'}, {'cast_id': 25, 'character': 'The German Surgeon', 'credit_id': '52fe430cc3a36847f8036a6f', 'gender': 0, 'id': 1265218, 'name': 'Petr Janis', 'order': 12, 'profile_path': None}, {'cast_id': 32, 'character': 'Kana', 'credit_id': '54e3bc81c3a368454b00931d', 'gender': 1, 'id': 1154564, 'name': 'Jennifer Lim', 'order': 13, 'profile_path': '/2sxWwQIbR9dyYzYlI95gaZFT0jK.jpg'}, {'cast_id': 46, 'character': 'American Stoner', 'credit_id': '595114d592514128e100b686', 'gender': 2, 'id': 16847, 'name': 'Eli Roth', 'order': 14, 'profile_path': '/lV7xjR2fUXX3u8Ixg8nhKFbuqm3.jpg'}, {'cast_id': 47, 'character': 'The Butcher', 'credit_id': '59be3bd7925141353d025bb0', 'gender': 0, 'id': 1172639, 'name': 'Josef Bradna', 'order': 15, 'profile_path': None}]   \n",
      "\n",
      "                                                   tagline  \\\n",
      "10151               There's nothing like your first piece.   \n",
      "9353                               The greatest challenge.   \n",
      "12209  School's out...But Bobby's education has just begun   \n",
      "15297                              Hollywood had it coming   \n",
      "24848                      Welcome To Your Worst Nightmare   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                           overview  \n",
      "10151                                                                                                                                            At a high-school party, four friends find that losing their collective virginity isn't as easy as they had thought. But they still believe that they need to do so before college. To motivate themselves, they enter a pact to all \"score.\" by their senior prom.  \n",
      "9353   Now the world champion, Rocky Balboa is living in luxury and only fighting opponents who pose no threat to him in the ring. His lifestyle of wealth and idleness is shaken when a powerful young fighter known as Clubber Lang challenges him to a bout. After taking a pounding from Lang, the humbled champ turns to former bitter rival Apollo Creed to help him regain his form for a rematch with Lang.  \n",
      "12209   High school senior Bobby Chrystal fails his French class, which will block him from entering Yale. His rich, authoritarian father hires an attractive 29-year-old to tutor Bobby over the summer and help him pass a make-up exam. While Bobby's friends lead him away into strange excursions aimed at losing their virginity, Bobby finds all the extracurricular activities he needs with his new tutor.  \n",
      "15297                                                                                                                                                             When Jay and Silent Bob learn that their comic-book alter egos, Bluntman and Chronic, have been sold to Hollywood as part of a big-screen movie that leaves them out of any royalties, the pair travels to Tinseltown to sabotage the production.  \n",
      "24848                                                                                                                                                                                                                                                                    Three backpackers head to a Slovakian city that promises to meet their hedonistic expectations, with no idea of the hell that awaits them.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "movies_df = pd.read_csv('./the-movies-dataset/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={'genres':\"string\",\"id\":\"string\",\"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\",\n",
    "                                    \"production_companies\" :\"string\"})[[\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"]]\n",
    "movies_df.dropna(inplace = True)\n",
    "movies_lst = [row for row in movies_df.values.tolist() if not (row[0][len(row[0])  - 2:] == \"[]\" or row[5][len(row[5]) - 2:] == \"[]\")]\n",
    "movies_df = pd.DataFrame(movies_lst, columns = (\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"), dtype = str)\n",
    "\n",
    "\n",
    "#LOOK: trying small dataset for testing\n",
    "\n",
    "ratings_df = pd.read_csv('./the-movies-dataset/ratings_small.csv', usecols = (\"userId\", \"movieId\", \"rating\"),\n",
    "                       dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})[[\"userId\", \"movieId\", \"rating\"]]\n",
    "ratings_df.rename(columns={\"movieId\": \"id\"}, inplace = True)\n",
    "ratings_df.dropna(inplace = True)\n",
    "\n",
    "\n",
    "# Question: What if the removal of duplicate movie ids per user was processed here instead of the cell below???\n",
    "# Answer: The duplicate removal function can be ran here,...\n",
    "# but the complete_list in the cell below can also be iterated over with relative complexity in order to remove duplicates.\n",
    "# The iteration in the next cell also populates the gap list...\n",
    "# which is critical to be ran directly before the function that determines bounds for users rated movies.\n",
    "# So, omitting the no duplicate function in this cell and making it run in the next cell avoids redundant iteration.\n",
    "\n",
    "\n",
    "# Question: What if the test and train ratings bounds was enforced here instead of the cell below???\n",
    "# Answer: The merge functions below needs to be executed before determining test and train users, because merge will remove rows and ratings from users...\n",
    "# before enforcing the users to be in a certain bounds for the number of their ratings. \n",
    "# The current timing of this function will ensure that the final users are within the set train or test bounds.\n",
    "\n",
    "\n",
    "keywords_df = pd.read_csv('./the-movies-dataset/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})[[\"id\", \"keywords\"]]\n",
    "keywords_df.dropna(inplace = True)\n",
    "keywords_lst = [row for row in keywords_df.values.tolist() if not (row[1][len(row[1])  - 2:] == \"[]\")]\n",
    "keywords_df = pd.DataFrame(keywords_lst, columns = (\"id\", \"keywords\"), dtype = str)\n",
    "\n",
    "\n",
    "credits_df = pd.read_csv(\"./the-movies-dataset/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})[[\"cast\", \"id\"]]\n",
    "credits_df.dropna(inplace = True)\n",
    "credits_lst = [row for row in credits_df.values.tolist() if (not row[0][len(row[0])  - 2:] == \"[]\")]\n",
    "credits_df = pd.DataFrame(credits_lst, columns = (\"cast\", \"id\"), dtype = str)\n",
    "\n",
    "\n",
    "# Default merge is inner: This only keeps movies that have the id existing in both dataframes.\n",
    "complete_df =  pd.merge(movies_df, ratings_df, on =\"id\")\n",
    "complete_df =  pd.merge(complete_df,keywords_df, on =\"id\")\n",
    "complete_df  = pd.merge(complete_df,credits_df, on =\"id\")\n",
    "\n",
    "\n",
    "complete_df.sort_values(by = 'userId', inplace = True)\n",
    "\n",
    "\n",
    "# Master dataframe: For each (user id, movie id) row combination there is the combined movie data from movies_df, ratings_df, keywords_df, and credits_df for the movie id in question.\n",
    "# The columns are reordered.\n",
    "complete_df  = complete_df.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "\n",
    "\n",
    "# For testing:\n",
    "print(\"Minutes taken:\", (time.time()-start_time)/60)\n",
    "print(complete_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Tested on personal machine:\n",
    "# Old run with dataframe iteration (old code): 1 minute and 5.7 seconds\n",
    "# New run with list conversion before iteration (current code): 37.1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Selection\n",
    "1. Select data from users that have a number of ratings within a certain bounds.\n",
    "2. Select a random subset of this data and simplify it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete number of users: 671\n",
      "Minutes taken: 0.5788999676704407\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import hist\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# LOOK: To make a fair comparison to the best possible implementation of the netflix data\n",
    "# a closer distribution of user ratings to the netflix data should be selected \n",
    "# perhaps simalir proportion of users in each increment of 10 ratings\n",
    "# problem: this does not correctly represent the population of the non-netflix dataset so it would have weaker applciaiton!!!\n",
    "# But, another question is, is the netflix data biased???\n",
    "# was the whole problem statment more theoretical then practical???\n",
    "# how is it that the two datasets are vastly different???\n",
    "\n",
    "\n",
    "\n",
    "# Also, since these are different datasets, a higher distribution is more extreme for this dataset than the netflix dataset\n",
    "# meaning there is a higher selection bias for this dataset \n",
    "\n",
    "# the right distibution of users ratings should be selected with trial and error\n",
    "\n",
    "\n",
    "# Note: in the netflix data, the distribution of nof user ratings does not change for users tested and users not tested\n",
    "# this should be mimicked with this data\n",
    "\n",
    "\n",
    "\n",
    "SEED_INT = 3\n",
    "# Seed for consistent results across runtimes:\n",
    "random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "def populate_names(item):\n",
    "    \"\"\"Extract names from the syntax of certain data entries:\"\"\"\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    index = 0\n",
    "    for item in jsons:\n",
    "        if(index == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        index += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provide_data(row):\n",
    "    \"\"\"Extract data from row of complete_list:\"\"\"\n",
    "    movie_data = []\n",
    "    movie_data.append(int(row[0]))\n",
    "    movie_data.append(int(row[1]))\n",
    "    movie_data.append(float(row[2]))\n",
    "    movie_data.append(row[3])  \n",
    "\n",
    "    movie_data.append(populate_names(row[4]))\n",
    "    movie_data.append(populate_names(row[5]))\n",
    "    movie_data.append(populate_names(row[6]))\n",
    "    movie_data.append(populate_names(row[7]))\n",
    "\n",
    "    movie_data.append(str(row[8]))\n",
    "    movie_data.append(str(row[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "\n",
    "# The list of rows with users id, the users rating for the movie, and raw data for the movie:\n",
    "# Note: It is sorted by user_id.\n",
    "complete_list = complete_df.values.tolist()\n",
    "\n",
    "print(\"Complete number of users:\", len(list(complete_df[\"userId\"].unique()))) # 260788\n",
    "\n",
    "# The complete list of user rows without ratings of the same movie more than once for a given user:\n",
    "complete_list_no_dups = []\n",
    "\n",
    "# Distinquish the user the row belongs to:\n",
    "last_id = complete_list[0][0]\n",
    "\n",
    "# The set of movies that a user has rated:\n",
    "# It is used to omit later ratings of a movie that the user has already rated.\n",
    "movie_set = set()\n",
    "\n",
    "# The number of rows of movie data a single user takes up for each user:\n",
    "gaps = []\n",
    "\n",
    "# Appended to gaps when all of a users rows of movie data have been counted:\n",
    "gap_len = 0\n",
    "\n",
    "\n",
    "# Populates gaps and complete_list_no_dups by omitting movies that already have a rating in respect to each user:\n",
    "# Note: This code is faster than using dataframe methods.\n",
    "# Example: Filter data by user and then remove duplicate movie ids for each user.\n",
    "# This avoids slow dataframe iteration, but the filter method is also slow.\n",
    "for row in complete_list:\n",
    "    if last_id != row[0]:\n",
    "        movie_set= set()\n",
    "        complete_list_no_dups.append(row)\n",
    "        movie_set.add(row[1])\n",
    "        gaps.append(gap_len)\n",
    "        gap_len = 1\n",
    "    else:\n",
    "        if row[1] not in movie_set:\n",
    "            complete_list_no_dups.append(row)\n",
    "            gap_len+=1\n",
    "            movie_set.add(row[1])\n",
    "    last_id = row[0]\n",
    "\n",
    "# Add the last gap_len:\n",
    "gaps.append(gap_len)\n",
    "\n",
    "\n",
    "\n",
    "# Index in the complete_list_no_dups list:\n",
    "full_index = 0 \n",
    "bounds = [] \n",
    "\n",
    "\n",
    "\n",
    "# Populates bounds_train and bounds_test by testing each user if they are a valid train or test user:\n",
    "for user_index in range(len(gaps)):\n",
    "    bounds.append([full_index, full_index+gaps[user_index]])\n",
    "    full_index+=gaps[user_index]    \n",
    "\n",
    "\n",
    "#LOOK: change back to 1300 when bounds are needed!\n",
    "bounds_train = random.sample(bounds, 671)\n",
    "\n",
    "\n",
    "bounds_test= random.sample(bounds_train, 150)\n",
    "\n",
    "#LOOK: Now with the remaining bounds that were not sampled, iterate through them until...\n",
    "# a number of users within a certain bounds of ratings has been selelcted\n",
    "\n",
    "\n",
    "# commented out to test no trainbounds\n",
    "# random.shuffle(bounds)\n",
    "# bounds_test = []\n",
    "\n",
    "# for item in bounds:\n",
    "#     if item[1]-item[0] >=30 and item[1]-item[0] <=50:\n",
    "#         bounds_test.append(item)\n",
    "#         if len(bounds_test) == 200:\n",
    "#             break\n",
    "\n",
    "\n",
    "\n",
    "# Transformed data of the selected train users and test users (in that order):\n",
    "sampled_data = []\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for bound in bounds_train:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        movie_data[0] = cnt\n",
    "        sampled_data.append(movie_data)\n",
    "    cnt+=1\n",
    "\n",
    "for bound in bounds_test:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        movie_data[0] = cnt\n",
    "        sampled_data.append(movie_data)\n",
    "    cnt+=1\n",
    "\n",
    "\n",
    "print(\"Minutes taken:\", (time.time()-start_time)/60)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data\n",
    "\n",
    "Save selected data in constructed_data.csv file so that cells below it can run without running this cell and above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, 'constructed_data')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "with open(\"constructed_data/constructed_data_2.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    writer.writerows(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "#This cell is for testing how long the ratings small is...\n",
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"ratings_small/ratings_small.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n",
    "\n",
    "cnt =0 \n",
    "id = -1\n",
    "for item in data_list:\n",
    "     if item[0] != id:\n",
    "          cnt+=1\n",
    "          id = item[0]\n",
    "\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "This is the starting cell to run if the data is already saved to the constructed_data.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data_2.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and re-sample Data:\n",
    "\n",
    "Format the data into a list of movie data rows for each movie rated for the user for each user. Then, select a subset of that data for each user type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "SEED_INT = 3\n",
    "\n",
    "random.seed(SEED_INT)\n",
    "\n",
    "user_to_data_train = []\n",
    "user_to_data_test = []\n",
    "\n",
    "user_id = data_list[0][0]\n",
    "\n",
    "ratings = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        if(i<521):\n",
    "            user_to_data_train.append(ratings)\n",
    "        else:\n",
    "            user_to_data_test.append(ratings)\n",
    "        user_id = row[0]\n",
    "        ratings = [row]\n",
    "    else:\n",
    "        ratings.append(row)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "user_to_data_test.append(ratings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: Should try introducing higher rating bounds for train users\n",
    "#in contrast to the other model in complete_11_03_2023.ipynb the test users need to be picked completely randomly \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features and Target values\n",
    "\n",
    "* The train and test version of feature 1,2, and 3 are populated and in the final cell some subset of (feature 1, 2 and 3) is used to train and test the final model.\n",
    "* The target values are ratings for each user from the randomly selected movie that they rated. They are also either train or test ratings used to train or test the the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73469082908731\n",
      "0.19286782477340159\n",
      "[[3.23824892 4.00031962 3.86628608 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "3.690830235439901\n",
      "-12.441134873610771\n",
      "0.738227431848343\n",
      "0.18735604184731924\n",
      "0.7542808714099318\n",
      "0.15866462819353588\n",
      "0.7550506671143457\n",
      "0.15677365008160282\n",
      "0.7958538758702122\n",
      "0.07814078337818142\n",
      "0.7946165173412278\n",
      "0.06020840723032861\n",
      "44.40399932861328\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "from ordered_set import OrderedSet\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from surprise import SVD,Dataset,Reader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "N_VALUE = 100\n",
    "\n",
    "SEED_INT = 3\n",
    "# Seed for consistent results across runtimes:\n",
    "random.seed(SEED_INT)\n",
    "\n",
    "\n",
    "\n",
    "movies_order = OrderedSet()\n",
    "movie_ratings_sum_dict = dict()\n",
    "movie_ratings_count_dict = dict()\n",
    "overall_average = 0\n",
    "cnt = 0\n",
    "\n",
    "train_user_to_movie_to_rating = [] \n",
    "\n",
    "for user in user_to_data_train:\n",
    "    movie_to_rating  = dict()\n",
    "    for movie in user:\n",
    "        movies_order.add(movie[1])\n",
    "        movie_to_rating[movie[1]] = float(movie[2])\n",
    "        if(movie[1] in movie_ratings_sum_dict.keys()):\n",
    "            movie_ratings_sum_dict[movie[1]] += float(movie[2])\n",
    "            movie_ratings_count_dict[movie[1]] += 1\n",
    "        else:\n",
    "            movie_ratings_sum_dict[movie[1]] = float(movie[2])\n",
    "            movie_ratings_count_dict[movie[1]] = 1\n",
    "        overall_average+=float(movie[2])\n",
    "        cnt += 1\n",
    "    train_user_to_movie_to_rating.append(movie_to_rating)\n",
    "\n",
    "\n",
    "test_user_to_movie_to_rating = [] \n",
    "target_movie = []\n",
    "target_rating = []\n",
    "\n",
    "for user in user_to_data_test:\n",
    "    rand_num  = random.randint(0, len(user)-1)\n",
    "    index = 0\n",
    "    movie_to_rating  = dict()\n",
    "    for movie in user:\n",
    "        movies_order.add(movie[1])\n",
    "        if(index == rand_num):\n",
    "            target_movie.append(movie[1])\n",
    "            target_rating.append(float(movie[2]))\n",
    "        else:\n",
    "            if(movie[1] in movie_ratings_sum_dict.keys()):\n",
    "                movie_ratings_sum_dict[movie[1]] += float(movie[2])\n",
    "                movie_ratings_count_dict[movie[1]] += 1\n",
    "            else:\n",
    "                movie_ratings_sum_dict[movie[1]] = float(movie[2])\n",
    "                movie_ratings_count_dict[movie[1]] = 1\n",
    "            movie_to_rating[movie[1]] = float(movie[2])\n",
    "            overall_average+=float(movie[2])\n",
    "            cnt += 1\n",
    "        index+=1\n",
    "    test_user_to_movie_to_rating.append(movie_to_rating)\n",
    "\n",
    "overall_average  = overall_average/cnt\n",
    "\n",
    "movie_ratings_avg_list = []\n",
    "\n",
    "\n",
    "#LOOK: here is where removing movies based on the value of movie_ratings_count_dict[movie] can be done\n",
    "#Note: cant remove movies that are a target rating for a user\n",
    "#this means it is probably better to assign traget ratings after this action\n",
    "\n",
    "\n",
    "for movie in movies_order:\n",
    "    if movie in movie_ratings_sum_dict.keys():\n",
    "        movie_ratings_avg_list.append(movie_ratings_sum_dict[movie]/movie_ratings_count_dict[movie])\n",
    "    else:\n",
    "        movie_ratings_avg_list.append(overall_average)\n",
    "    \n",
    "\n",
    "train_user_averages = []\n",
    "test_user_averages = []\n",
    "for user in train_user_to_movie_to_rating:\n",
    "    if len(user)==0:\n",
    "        train_user_averages.append(overall_average)\n",
    "    else:\n",
    "        train_user_averages.append(sum([user[key] for key in user.keys()])/len(user))\n",
    "for user in test_user_to_movie_to_rating:\n",
    "    if len(user)==0:\n",
    "        test_user_averages.append(overall_average)\n",
    "    else:\n",
    "        test_user_averages.append(sum([user[key] for key in user.keys()])/len(user))\n",
    "        \n",
    "user_averages = train_user_averages + test_user_averages\n",
    "\n",
    "#LOOK: new normalization method\n",
    "\n",
    "# users_to_movie_ratings_transformed = []\n",
    "\n",
    "# for i in range(len(user_to_data_train)):\n",
    "#     j = 0\n",
    "#     lst = []\n",
    "#     for movie in movies_order: \n",
    "#         if movie in train_user_to_movie_to_rating[i].keys():\n",
    "#             lst.append(train_user_to_movie_to_rating[i][movie] - train_user_averages[i])\n",
    "#         else:\n",
    "#             lst.append(0)\n",
    "#         j += 1\n",
    "#     users_to_movie_ratings_transformed.append(lst)\n",
    "\n",
    "# target_movie_index = []\n",
    "\n",
    "# for i in range(len(user_to_data_test)):\n",
    "#     j = 0\n",
    "#     lst = []\n",
    "#     for movie in movies_order: \n",
    "#         if(target_movie[i] == movie):\n",
    "#             lst.append(0)\n",
    "#             target_movie_index.append(j)\n",
    "#         elif movie in test_user_to_movie_to_rating[i].keys():\n",
    "#             lst.append(test_user_to_movie_to_rating[i][movie] - test_user_averages[i])\n",
    "#         else:\n",
    "#             lst.append(0)\n",
    "#         j += 1\n",
    "#     users_to_movie_ratings_transformed.append(lst)\n",
    "\n",
    "\n",
    "\n",
    "#LOOK: old normalization method\n",
    "users_to_movie_ratings_transformed = []\n",
    "train_users_to_movie_ratings_transformed = []\n",
    "test_users_to_movie_ratings_transformed = []\n",
    "\n",
    "users_to_movie_ratings = []\n",
    "train_users_to_movie_ratings = []\n",
    "test_users_to_movie_ratings = []\n",
    "\n",
    "#bit map of raw ratings given by 1 and filled in ratings given by 0\n",
    "rating_map = []\n",
    "\n",
    "for i in range(len(user_to_data_train)):\n",
    "    j = 0\n",
    "    lst_1 = []\n",
    "    lst_2 = []\n",
    "    row_map = []\n",
    "    for movie in movies_order: \n",
    "        if movie in train_user_to_movie_to_rating[i].keys():\n",
    "            lst_1.append(train_user_to_movie_to_rating[i][movie] - movie_ratings_avg_list[j])\n",
    "            lst_2.append(train_user_to_movie_to_rating[i][movie])\n",
    "            row_map.append(1)\n",
    "        else:\n",
    "            lst_1.append(0)\n",
    "            #try adding zero here...\n",
    "            lst_2.append(movie_ratings_avg_list[j])\n",
    "            row_map.append(0)\n",
    "        j += 1\n",
    "    rating_map.append(row_map)\n",
    "    train_users_to_movie_ratings_transformed.append(lst_1)\n",
    "    train_users_to_movie_ratings.append(lst_2)\n",
    "\n",
    "target_movie_index = []\n",
    "\n",
    "for i in range(len(user_to_data_test)):\n",
    "    j = 0\n",
    "    lst_1 = []\n",
    "    lst_2 = []\n",
    "    row_map = []\n",
    "    for movie in movies_order: \n",
    "        if(target_movie[i] == movie):\n",
    "            lst_1.append(0)\n",
    "            #try adding zero here...\n",
    "            lst_2.append(movie_ratings_avg_list[j])\n",
    "            target_movie_index.append(j)\n",
    "            #LOOK: change back if predict function doesn't work!!!\n",
    "            row_map.append(0)\n",
    "        elif movie in test_user_to_movie_to_rating[i].keys():\n",
    "            lst_1.append(test_user_to_movie_to_rating[i][movie] - movie_ratings_avg_list[j])\n",
    "            lst_2.append(test_user_to_movie_to_rating[i][movie])\n",
    "            row_map.append(1)\n",
    "        else:\n",
    "            lst_1.append(0)\n",
    "            #try adding zero here...\n",
    "            lst_2.append(movie_ratings_avg_list[j])\n",
    "            row_map.append(0)\n",
    "        j += 1\n",
    "    rating_map.append(row_map)\n",
    "    test_users_to_movie_ratings_transformed.append(lst_1)\n",
    "    test_users_to_movie_ratings.append(lst_2)\n",
    "\n",
    "users_to_movie_ratings_transformed = train_users_to_movie_ratings_transformed + test_users_to_movie_ratings_transformed\n",
    "users_to_movie_ratings = train_users_to_movie_ratings + test_users_to_movie_ratings\n",
    "\n",
    "\n",
    "def svd_full(user_to_ratings_transformed, n, averages):\n",
    "    \"\"\"\n",
    "    1. Get the svd of the user_to_ratings_full_transform \n",
    "    2. Truncate each factor to n components\n",
    "    3. Multiply the truncated components together (U X s) X V \n",
    "    4. Scale back the values to the orginal rating scale (1-5) and return result\n",
    "    \"\"\"\n",
    "    U, S, V = np.linalg.svd(user_to_ratings_transformed, full_matrices=False)\n",
    "    \n",
    "    # Simplify factors to n components:\n",
    "    U=U[:,0:n]\n",
    "    S=np.diag(S)\n",
    "    S=S[0:n,0:n]\n",
    "    V=V[0:n,:]\n",
    "\n",
    "    # Reconstruct to a new array:\n",
    "    US = np.dot(U,S)\n",
    "    USV = np.dot(US,V)\n",
    "\n",
    "    # This tranforms the UsV row by row into the original rating scale (1-5).\n",
    "    # LOOK: Old normalization method\n",
    "    USV = USV + np.tile(averages, (USV.shape[0],1))\n",
    "\n",
    "    # LOOK: New normalization method\n",
    "    # averages_reshaped = np.reshape(averages,  (len(averages), 1))\n",
    "    # USV = USV + np.repeat(np.array(averages_reshaped), USV.shape[1], 1)\n",
    "\n",
    "    # Be consistent with data structures:\n",
    "    return list(USV)\n",
    "\n",
    "\n",
    "#LOOK: This is where the iterative svd algorithm will reside\n",
    "#LOOK: as expected, the perfomance of this iterative algorithm is the same as\n",
    "# The automatic algorithm, but this is the stepping stone for...\n",
    "# regularized svd...\n",
    "\n",
    "# def svd_full_alt(user_to_ratings_transformed, n, averages):\n",
    "\n",
    "#     R = np.array(user_to_ratings_transformed)\n",
    "#     U = np.zeros((R.shape[0], n))\n",
    "#     V = np.random.uniform(-1, 1, (R.shape[1], n))\n",
    "\n",
    "\n",
    "#     last_error = np.inf\n",
    "#     while(True):\n",
    "#         # E = (norm(R - UVt))^2\n",
    "#         current_error = np.square(np.linalg.norm(R-np.matmul(U, np.transpose(V))))\n",
    "\n",
    "#         if  last_error - current_error <= .001:\n",
    "#             break\n",
    "\n",
    "#         # U = RV((VtV)^-1)\n",
    "#         # V = RtU((UtU)^-1)\n",
    "#         U = np.matmul(np.matmul(R, V),\n",
    "#                        np.linalg.inv(np.matmul(np.transpose(V), V)))\n",
    "#         V = np.matmul(np.matmul(np.transpose(R), U),\n",
    "#                        np.linalg.inv(np.matmul(np.transpose(U), U)))\n",
    "\n",
    "#         last_error  = current_error\n",
    "    \n",
    "#     US = np.dot(U,np.transpose(V))\n",
    "#     US = US + np.tile(averages, (US.shape[0],1))\n",
    "\n",
    "#     return list(US)\n",
    "\n",
    "\n",
    "\n",
    "def svd_full_alt(user_to_ratings, n):\n",
    "\n",
    "    #experiment with this\n",
    "    reg_term = 0.02\n",
    "\n",
    "    R = np.array(user_to_ratings)\n",
    "    U = np.zeros((R.shape[0], n))\n",
    "    #LOOK: This is used with normalization\n",
    "    # V = np.random.uniform(-1, 1, (R.shape[1], n))\n",
    "    V = np.random.uniform(1, 5, (R.shape[1], n))\n",
    "\n",
    "    last_error = np.inf\n",
    "    while(True):\n",
    "        # E = (norm(R - UVt))^2\n",
    "        current_error = np.square(np.linalg.norm(R-np.matmul(U, np.transpose(V)))) \n",
    "        + reg_term*np.square(np.linalg.norm(U))\n",
    "        + reg_term*np.square(np.linalg.norm(V))\n",
    "\n",
    "        if  last_error - current_error <= .001:\n",
    "            break\n",
    "\n",
    "        # U = RV((VtV)^-1)\n",
    "        # V = RtU((UtU)^-1)\n",
    "        U = np.matmul(np.matmul(R, V),\n",
    "                       np.linalg.inv(np.matmul(np.transpose(V), V)+reg_term*np.identity(n)))\n",
    "        V = np.matmul(np.matmul(np.transpose(R), U),\n",
    "                       np.linalg.inv(np.matmul(np.transpose(U), U)+reg_term*np.identity(n)))\n",
    "\n",
    "        last_error  = current_error\n",
    "    \n",
    "    US = np.dot(U,np.transpose(V))\n",
    "    # LOOK: removed to omit pre and post scaling \n",
    "    # US = US + np.tile(averages, (US.shape[0],1))\n",
    "\n",
    "    return list(US)\n",
    "\n",
    "#LOOK: the train predict version is used because including target ratings in the full procedure gives some value to\n",
    "#the training that noramlly wouldn't be there if the movies to predict are unknown before changing\n",
    "\n",
    "def predict(u, i, b1, b2, p, q, R, overall_average):\n",
    "\n",
    "    b1_c = np.copy(b1) \n",
    "    b2_c = np.copy(b2) \n",
    "    p_c = np.copy(p) \n",
    "    q_c = np.copy(q) \n",
    "\n",
    "    rt = .02\n",
    "    lr = .005\n",
    "    prediction = -1\n",
    "\n",
    "\n",
    "    for _ in range(15):\n",
    "        prediction = overall_average+b1_c[u]+b2_c[i]+np.dot(p_c[u],q_c[i])\n",
    "        error = R[u][i]-prediction\n",
    "        b1_c[u] += lr*(error- rt*b1_c[u])\n",
    "        b2_c[i] += lr*(error- rt*b2_c[i])\n",
    "        temp = lr*(error*q_c[i] -rt*p_c[u])\n",
    "        q_c[i] += lr*(error*p_c[u] -rt*q_c[i])\n",
    "        p_c[u] += temp\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "def train(user_to_ratings, n, overall_average, rating_map):\n",
    "\n",
    "    rt = .02\n",
    "    lr = .005\n",
    "\n",
    "    np.random.seed(SEED_INT)\n",
    "    R = np.array(user_to_ratings)\n",
    "    q = np.random.normal(0, .1, (R.shape[1], n))\n",
    "    p = np.random.normal(0, .1, (R.shape[0], n))\n",
    "\n",
    "    #LOOK: these are user and item biases respectively\n",
    "    b1 = [0]*R.shape[0]\n",
    "    b2 = [0]*R.shape[1]\n",
    "\n",
    "\n",
    "    R_hat = np.zeros((R.shape[0], R.shape[1]))\n",
    "    eui = np.zeros((R.shape[0], R.shape[1]))\n",
    "\n",
    "    #LOOK: caching is not done here\n",
    "    for _ in range(20):\n",
    "        for u in range(R.shape[0]):\n",
    "            for i in range(R.shape[1]):\n",
    "                if rating_map[u][i]==1:\n",
    "                    #This should not be computed in order... but at the same time..\n",
    "                    R_hat[u][i] = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "                    eui[u][i] = R[u][i]-R_hat[u][i]\n",
    "                    b1[u] += lr*(eui[u][i]- rt*b1[u])\n",
    "                    b2[i] += lr*(eui[u][i]- rt*b2[i])\n",
    "                    temp = lr*(eui[u][i]*q[i] -rt*p[u])\n",
    "                    q[i] += lr*(eui[u][i]*p[u] -rt*q[i])\n",
    "                    p[u] += temp\n",
    "\n",
    "\n",
    "    return b1, b2, p, q, R\n",
    "\n",
    "def svd_full_alt_sgd(user_to_ratings, n, overall_average, rating_map):\n",
    "\n",
    "    #experiment with this\n",
    "    rt = .02\n",
    "    lr = .005\n",
    "\n",
    "    np.random.seed(SEED_INT)\n",
    "    R = np.array(user_to_ratings)\n",
    "    # q = np.zeros((R.shape[1], n))\n",
    "    # p = np.zeros((R.shape[0], n))\n",
    "    q = np.random.normal(0, .1, (R.shape[1], n))\n",
    "    p = np.random.normal(0, .1, (R.shape[0], n))\n",
    "\n",
    "    #LOOK: these are user and item biases respectively\n",
    "    b1 = [0]*R.shape[0]\n",
    "    b2 = [0]*R.shape[1]\n",
    "\n",
    "\n",
    "    R_hat = np.zeros((R.shape[0], R.shape[1]))\n",
    "    eui = np.zeros((R.shape[0], R.shape[1]))\n",
    "\n",
    "    # last_error = np.inf\n",
    "    # while(True):\n",
    "        # error_sum = 0\n",
    "        # for u in range(R.shape[0]):\n",
    "        #     for i in range(R.shape[1]):\n",
    "        #         R_hat[u][i] = u+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "        #         eui[u][i] = R[u][i]-R_hat[u][i]\n",
    "        #         term_1 = (eui[u][i])**2\n",
    "        #         term_2 = rt*(b1[u]**2 +b2[i]**2\n",
    "        #                     +np.linalg.norm(p[u])**2\n",
    "        #                     +np.linalg.norm(q[i])**2)\n",
    "        #         error_sum+=(term_1+term_2)\n",
    "\n",
    "        # if  last_error - error_sum <= .001:\n",
    "        #     break\n",
    "        # last_error  = error_sum\n",
    "\n",
    "    #with biases:\n",
    "    #try making outer loop the inner loop...\n",
    "    #need to try omitting target movies and just predict them\n",
    "    #LOOK: caching is not done here\n",
    "    for _ in range(20):\n",
    "        for u in range(R.shape[0]):\n",
    "            for i in range(R.shape[1]):\n",
    "                if rating_map[u][i]==1:\n",
    "                    #This should not be computed in order... but at the same time..\n",
    "                    R_hat[u][i] = overall_average+b1[u]+b2[i]+np.dot(p[u],q[i])\n",
    "                    eui[u][i] = R[u][i]-R_hat[u][i]\n",
    "                    b1[u] += lr*(eui[u][i]- rt*b1[u])\n",
    "                    b2[i] += lr*(eui[u][i]- rt*b2[i])\n",
    "                    temp = lr*(eui[u][i]*q[i] -rt*p[u])\n",
    "                    q[i] += lr*(eui[u][i]*p[u] -rt*q[i])\n",
    "                    p[u] += temp\n",
    "\n",
    "\n",
    "    #how can this be optimized with numpy???\n",
    "    #try without biases:\n",
    "    # for a in range(20):\n",
    "    #     for u in range(R.shape[0]):\n",
    "    #         for i in range(R.shape[1]):\n",
    "    #             R_hat[u][i] = np.dot(p[u],q[i])\n",
    "    #             eui[u][i] = R[u][i]-R_hat[u][i]\n",
    "    #             temp = lr*(eui[u][i]*q[i] -rt*p[u])\n",
    "    #             q[i] += lr*(eui[u][i]*p[u] -rt*q[i])\n",
    "    #             p[u] += temp\n",
    "\n",
    "\n",
    "\n",
    "    print(R_hat)\n",
    "    return list(R_hat)\n",
    "\n",
    "#LOOK implementing suprise...\n",
    "\n",
    "train_list = []\n",
    "\n",
    "index =0\n",
    "for user_ratings, user_dict in zip(train_users_to_movie_ratings, train_user_to_movie_to_rating):\n",
    "    for rating, movie_id in zip(user_ratings, list(movies_order)):\n",
    "        if movie_id in user_dict.keys():\n",
    "            train_list.append((index, movie_id, rating))\n",
    "    index+=1\n",
    "\n",
    "i = 0\n",
    "user_movies_to_predict = []\n",
    "for user_ratings, user_dict in zip(test_users_to_movie_ratings, test_user_to_movie_to_rating):\n",
    "    for rating, movie_id in zip(user_ratings, list(movies_order)):\n",
    "        if movie_id in user_dict.keys():\n",
    "            train_list.append((index, movie_id, rating))\n",
    "        elif(movie_id == target_movie[i]):\n",
    "            user_movies_to_predict.append((index, movie_id))\n",
    "    index+=1\n",
    "    i+=1\n",
    "\n",
    "\n",
    "reader = Reader()\n",
    "train_df = pd.DataFrame(train_list, columns=['userId', 'movieId', 'rating'])\n",
    "\n",
    "dataset = Dataset.load_from_df(train_df, reader)\n",
    "svd_model = SVD(random_state = SEED_INT)\n",
    "trainset = dataset.build_full_trainset()\n",
    "svd_model_trained = svd_model.fit(trainset)\n",
    "\n",
    "predictions_0 = []\n",
    "\n",
    "for item in user_movies_to_predict:\n",
    "    predictions_0.append(svd_model_trained.predict(item[0], item[1], verbose=False).est)\n",
    "\n",
    "print(mean_absolute_error(target_rating , predictions_0))\n",
    "print(r2_score(target_rating , predictions_0))\n",
    "#End of suprise\n",
    "\n",
    "#predictions for sgd model:\n",
    "svd_out_full_alt_sdg = svd_full_alt_sgd(users_to_movie_ratings, N_VALUE, overall_average, rating_map)\n",
    "predictions_i = [svd_out_full_alt_sdg[i+len(user_to_data_train)][target_movie_index[i]] for i in range(len(user_to_data_test))]\n",
    "\n",
    "print(mean_absolute_error(target_rating , predictions_i))\n",
    "print(r2_score(target_rating , predictions_i))\n",
    "\n",
    "\n",
    "#train/predict sgd model...\n",
    "b1, b2, p, q, R = train(users_to_movie_ratings, N_VALUE, overall_average, rating_map)\n",
    "predictions_j = [predict(u+len(user_to_data_train), target_movie_index[u], b1, b2, p, q, R, overall_average) for u in range(len(user_to_data_test))]\n",
    "\n",
    "print(mean_absolute_error(target_rating , predictions_j))\n",
    "print(r2_score(target_rating , predictions_j))\n",
    "\n",
    "svd_out_full = svd_full(users_to_movie_ratings_transformed, N_VALUE, movie_ratings_avg_list)\n",
    "# svd_out_full = svd_full(users_to_movie_ratings_transformed, N_VALUE, user_averages)\n",
    "\n",
    "predictions_1 = [svd_out_full[i+len(user_to_data_train)][target_movie_index[i]] for i in range(len(user_to_data_test))]\n",
    "print(mean_absolute_error(target_rating , predictions_1))\n",
    "print(r2_score(target_rating , predictions_1))\n",
    "\n",
    "svd_out_full_alt = svd_full_alt(users_to_movie_ratings, N_VALUE)\n",
    "# svd_out_full_alt = svd_full_alt(users_to_movie_ratings_transformed, N_VALUE, user_averages)\n",
    "\n",
    "predictions_2 = [svd_out_full_alt[i+len(user_to_data_train)][target_movie_index[i]] for i in range(len(user_to_data_test))]\n",
    "print(mean_absolute_error(target_rating , predictions_2))\n",
    "print(r2_score(target_rating , predictions_2))\n",
    "\n",
    "\n",
    "predictions_3 = []\n",
    "for index in target_movie_index:\n",
    "    predictions_3.append(movie_ratings_avg_list[index])\n",
    "print(mean_absolute_error(target_rating , predictions_3))\n",
    "print(r2_score(target_rating , predictions_3))\n",
    "\n",
    "predictions_4 = []\n",
    "for avg in test_user_averages:\n",
    "    predictions_4.append(avg)\n",
    "print(mean_absolute_error(target_rating , predictions_4))\n",
    "print(r2_score(target_rating , predictions_4))\n",
    "\n",
    "print(time.time() - start_time)\n",
    "\n",
    "\n",
    "#LOOK: need to try creating svd from the iterative process and compare the automated one (done)\n",
    "\n",
    "#LOOK: try using r svd without pre and post scaling (done)\n",
    "\n",
    "#LOOK: \n",
    "#sample code: https://www.kaggle.com/code/ankitahankare/collaborative-filtering-based-recommender-system\n",
    "#A difference between his and my implementation is that in mine the target values for test users are never included in training\n",
    "#this is simply because, in a realistic implementation of the model the users dont have these ratings\n",
    "#Another difference is that the target ratings in his are randomly chosen (user,movie) pairs, where in mine they are one per test user\n",
    "\n",
    "#LOOK: Try running the sample code (done) \n",
    "\n",
    "#https://surprise.readthedocs.io/en/stable/model_selection.html#cross-validation\n",
    "\n",
    "#LOOK: need to try with the small dataset (done) \n",
    "\n",
    "#LOOK: need to try removing random seeds (done)\n",
    "\n",
    "#LOOK: Try changing outer and inner loop (done)\n",
    "\n",
    "#LOOK: try less training, more training \n",
    "\n",
    "#LOOK: With train svd_full_alt_sgd how do you train the with the train data only without using the fill in values for target movies???\n",
    "\n",
    "\n",
    "#stock model: 0.73469082908731\n",
    "#other model: 0.7344406498456546 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
