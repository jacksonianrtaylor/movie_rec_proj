{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\the-movies-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "#this cell downloads the data needed for this jupyter notebook from kaggle and stores in the-movies-dataset folder in the current directory\n",
    "#if the files are already in that folder than this cell does nothing and requires no credentials\n",
    "\n",
    "#Data Soruce Information:\n",
    "#https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?select=movies_metadata.csv\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId    id rating               title  \\\n",
      "6566765      1  1246    5.0        Rocky Balboa   \n",
      "6880303      1  2959    4.0      License to Wed   \n",
      "2083077      1  2762    4.5  Young and Innocent   \n",
      "1492304      1  1968    4.0       Fools Rush In   \n",
      "2638962      1   147    4.5       The 400 Blows   \n",
      "\n",
      "                                                                                                genres  \\\n",
      "6566765                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "6880303                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "2083077                                     [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name': 'Crime'}]   \n",
      "1492304  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "2638962                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                production_companies  \\\n",
      "6566765                                                                                                  [{'name': 'Columbia Pictures', 'id': 5}, {'name': 'Revolution Studios', 'id': 497}, {'name': 'Rogue Marble', 'id': 696}, {'name': 'Metro-Goldwyn-Mayer (MGM)', 'id': 8411}]   \n",
      "6880303  [{'name': 'Village Roadshow Pictures', 'id': 79}, {'name': 'Robert Simonds Productions', 'id': 3929}, {'name': 'Warner Bros.', 'id': 6194}, {'name': 'Phoenix Pictures', 'id': 11317}, {'name': 'Underground', 'id': 49326}, {'name': 'Proposal Productions', 'id': 49327}]   \n",
      "2083077                                                                                                                                                                                                                [{'name': 'Gaumont British Picture Corporation', 'id': 4978}]   \n",
      "1492304                                                                                                                                                                                                                                     [{'name': 'Columbia Pictures', 'id': 5}]   \n",
      "2638962                                                                                                                                 [{'name': 'Les Films du Carrosse', 'id': 53}, {'name': 'SÃ©dif Productions', 'id': 10897}, {'name': 'The Criterion Collection', 'id': 10932}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
      "6566765  [{'id': 276, 'name': 'philadelphia'}, {'id': 396, 'name': 'transporter'}, {'id': 1721, 'name': 'fight'}, {'id': 2038, 'name': \"love of one's life\"}, {'id': 2416, 'name': 'publicity'}, {'id': 2792, 'name': 'boxer'}, {'id': 2968, 'name': 'grave'}, {'id': 3393, 'name': 'tombstone'}, {'id': 3586, 'name': 'tv station'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5167, 'name': 'restaurant owner'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5380, 'name': 'virtual fight'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 10163, 'name': 'cancer'}, {'id': 155464, 'name': 'over-the-hill fighter'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                             [{'id': 1605, 'name': 'new love'}, {'id': 2856, 'name': 'ten commandments'}, {'id': 3582, 'name': 'bride'}, {'id': 3583, 'name': 'bridegroom'}, {'id': 6038, 'name': 'marriage'}, {'id': 6192, 'name': 'relation'}, {'id': 6281, 'name': 'partnership'}, {'id': 6704, 'name': 'civil registry office'}, {'id': 10093, 'name': 'priest'}, {'id': 13027, 'name': 'wedding'}, {'id': 14765, 'name': 'church'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'id': 769, 'name': 'falsely accused'}, {'id': 1655, 'name': 'country house'}, {'id': 9826, 'name': 'murder'}, {'id': 9937, 'name': 'suspense'}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'id': 828, 'name': 'waitress'}, {'id': 1463, 'name': 'culture clash'}, {'id': 9799, 'name': 'romantic comedy'}, {'id': 13149, 'name': 'pregnancy'}]   \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                      [{'id': 6930, 'name': 'fondling'}, {'id': 10183, 'name': 'independent film'}, {'id': 155518, 'name': 'nouvelle vague'}, {'id': 170268, 'name': 'skipping school'}, {'id': 170272, 'name': 'mise en scene'}, {'id': 170273, 'name': 'fingerprinting'}, {'id': 170279, 'name': '\\xa0mugshot'}, {'id': 170286, 'name': 'strict teacher'}, {'id': 170293, 'name': 'montmartre paris'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        cast  \\\n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'cast_id': 24, 'character': 'Rocky Balboa', 'credit_id': '52fe42e9c3a36847f802c61b', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 25, 'character': 'Paulie', 'credit_id': '52fe42e9c3a36847f802c61f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 1, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 26, 'character': 'Rocky Jr.', 'credit_id': '52fe42e9c3a36847f802c623', 'gender': 2, 'id': 16501, 'name': 'Milo Ventimiglia', 'order': 2, 'profile_path': '/maJeS6bA6ku21rSRceISQtwHL2h.jpg'}, {'cast_id': 27, 'character': 'Marie', 'credit_id': '52fe42e9c3a36847f802c627', 'gender': 1, 'id': 16502, 'name': 'Geraldine Hughes', 'order': 3, 'profile_path': '/bTXux3EJq25Fh2ixbet6MjdG3Fb.jpg'}, {'cast_id': 28, 'character': 'Steps', 'credit_id': '52fe42e9c3a36847f802c62b', 'gender': 2, 'id': 16503, 'name': 'James Francis Kelly III', 'order': 4, 'profile_path': '/iZyTQ2UlwNXrqLqPeNHbofFXubP.jpg'}, {'cast_id': 29, 'character': 'Duke', 'credit_id': '52fe42e9c3a36847f802c62f', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 30, 'character': 'L.C.', 'credit_id': '52fe42e9c3a36847f802c633', 'gender': 2, 'id': 16505, 'name': 'A. J. Benza', 'order': 6, 'profile_path': '/5hVinC6C1ZyD7c8EmZFTiEaF7vH.jpg'}, {'cast_id': 31, 'character': 'Adrian', 'credit_id': '52fe42e9c3a36847f802c637', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 7, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 32, 'character': 'Martin', 'credit_id': '52fe42e9c3a36847f802c63b', 'gender': 2, 'id': 16506, 'name': 'Henry G. Sanders', 'order': 8, 'profile_path': '/2SU75g2CAIzGWbgfIlNvKZQhYTZ.jpg'}, {'cast_id': 33, 'character': \"Mason 'The Line' Dixon\", 'credit_id': '52fe42e9c3a36847f802c63f', 'gender': 2, 'id': 16507, 'name': 'Antonio Tarver', 'order': 9, 'profile_path': '/kJEljjHwBvrjoxqcSVntXlejgl1.jpg'}, {'cast_id': 34, 'character': 'Spider Rico', 'credit_id': '52fe42e9c3a36847f802c643', 'gender': 2, 'id': 16508, 'name': 'Pedro Lovell', 'order': 10, 'profile_path': None}, {'cast_id': 35, 'character': 'Isabel', 'credit_id': '52fe42e9c3a36847f802c647', 'gender': 1, 'id': 16509, 'name': 'Ana Gerena', 'order': 11, 'profile_path': None}, {'cast_id': 36, 'character': 'Angie', 'credit_id': '52fe42e9c3a36847f802c64b', 'gender': 1, 'id': 16510, 'name': 'Angela Boyd', 'order': 12, 'profile_path': None}, {'cast_id': 37, 'character': 'Bar Thug', 'credit_id': '52fe42e9c3a36847f802c64f', 'gender': 0, 'id': 16511, 'name': 'Louis Giansante', 'order': 13, 'profile_path': None}, {'cast_id': 38, 'character': \"Lucky's Bartender\", 'credit_id': '52fe42e9c3a36847f802c653', 'gender': 0, 'id': 16512, 'name': 'Maureen Schilling', 'order': 14, 'profile_path': None}, {'cast_id': 40, 'character': 'X-Cell', 'credit_id': '5761db05c3a3682f20000302', 'gender': 2, 'id': 98298, 'name': 'Lahmard J. Tate', 'order': 15, 'profile_path': '/4WcFReePSxyGQJWV5wXGNfY0Y7o.jpg'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'cast_id': 18, 'character': 'Reverend Frank', 'credit_id': '52fe4376c3a36847f8056039', 'gender': 2, 'id': 2157, 'name': 'Robin Williams', 'order': 0, 'profile_path': '/sojtJyIV3lkUeThD7A2oHNm8183.jpg'}, {'cast_id': 19, 'character': 'Sadie Jones', 'credit_id': '52fe4376c3a36847f805603d', 'gender': 1, 'id': 16855, 'name': 'Mandy Moore', 'order': 1, 'profile_path': '/15sDtRpe301tZWrRYV31wjMuFpx.jpg'}, {'cast_id': 20, 'character': 'Ben Murphy', 'credit_id': '52fe4376c3a36847f8056041', 'gender': 2, 'id': 17697, 'name': 'John Krasinski', 'order': 2, 'profile_path': '/nOWwdZURikW22qo6OUSGFCTukgc.jpg'}, {'cast_id': 21, 'character': 'Carlisle', 'credit_id': '52fe4376c3a36847f8056045', 'gender': 2, 'id': 29020, 'name': 'Eric Christian Olsen', 'order': 3, 'profile_path': '/clbouet8o9IJlUd8WILD0lzHAtG.jpg'}, {'cast_id': 22, 'character': 'Lindsey Jones', 'credit_id': '52fe4376c3a36847f8056049', 'gender': 1, 'id': 15286, 'name': 'Christine Taylor', 'order': 4, 'profile_path': '/99OssnGmgGjduXFA7syxjNqt9tQ.jpg'}, {'cast_id': 23, 'character': 'Choir Boy', 'credit_id': '52fe4376c3a36847f805604d', 'gender': 2, 'id': 216, 'name': 'Josh Flitter', 'order': 5, 'profile_path': '/6RCA8tDWBxIVk9N3IqUjJEAzYGv.jpg'}, {'cast_id': 24, 'character': 'Joel', 'credit_id': '52fe4376c3a36847f8056051', 'gender': 2, 'id': 11827, 'name': 'DeRay Davis', 'order': 6, 'profile_path': '/w2JYPRLwXhNCpxpJc2v4UQYyMv8.jpg'}, {'cast_id': 25, 'character': 'Mr. Jones', 'credit_id': '52fe4376c3a36847f8056055', 'gender': 2, 'id': 21368, 'name': 'Peter Strauss', 'order': 7, 'profile_path': '/ufx1trct43k7UcT4DpoIMPZXi5A.jpg'}, {'cast_id': 26, 'character': 'Grandma Jones', 'credit_id': '52fe4376c3a36847f8056059', 'gender': 1, 'id': 6465, 'name': 'Grace Zabriskie', 'order': 8, 'profile_path': '/ibBabuSM1UyPYFFo0wBXhGbqElk.jpg'}, {'cast_id': 27, 'character': 'Mrs. Jones', 'credit_id': '52fe4376c3a36847f805605d', 'gender': 1, 'id': 29021, 'name': 'Roxanne Hart', 'order': 9, 'profile_path': '/yWGMW6HdhUGT2oIcQ4jmnkw7ZAM.jpg'}, {'cast_id': 28, 'character': 'Shelly', 'credit_id': '5586ee469251417f6f0059c8', 'gender': 1, 'id': 125167, 'name': 'Mindy Kaling', 'order': 10, 'profile_path': '/Agpd4tJyZ95hk74RifjnfnJpn9U.jpg'}, {'cast_id': 30, 'character': 'Expectant Father', 'credit_id': '56c3467cc3a36847c5001f66', 'gender': 2, 'id': 1368801, 'name': 'David Quinlan', 'order': 11, 'profile_path': '/2m75rrBhvOTtdUS9jlKW8GOHCBV.jpg'}, {'cast_id': 31, 'character': 'Judith', 'credit_id': '58e26093c3a36872f600dcf2', 'gender': 1, 'id': 113867, 'name': 'Angela Kinsey', 'order': 12, 'profile_path': '/omLdRLdwMLliVeVIualEnWVhm1a.jpg'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'cast_id': 18, 'character': 'Erica Burgoyne', 'credit_id': '52fe436bc3a36847f8052cd5', 'gender': 1, 'id': 27939, 'name': 'Nova Pilbeam', 'order': 0, 'profile_path': '/l6oHJaRYrVxsvoTSmMS5wIXaei5.jpg'}, {'cast_id': 19, 'character': 'Robert Tisdall', 'credit_id': '52fe436bc3a36847f8052cd9', 'gender': 0, 'id': 27940, 'name': 'Derrick De Marney', 'order': 1, 'profile_path': '/7VRZ7K0EZ50haOlbVr7DHZ5550O.jpg'}, {'cast_id': 20, 'character': 'Col. Burgoyne', 'credit_id': '52fe436bc3a36847f8052cdd', 'gender': 2, 'id': 27929, 'name': 'Percy Marmont', 'order': 2, 'profile_path': '/p3DIyvlxx6B0SVIxcDaPUPlEV0U.jpg'}, {'cast_id': 21, 'character': 'Old Will', 'credit_id': '52fe436bc3a36847f8052ce1', 'gender': 2, 'id': 27941, 'name': 'Edward Rigby', 'order': 3, 'profile_path': '/B7GJ0jPtODqZVgVtZHPtvZl2tO.jpg'}, {'cast_id': 22, 'character': 'Ericas Tante Margaret', 'credit_id': '52fe436bc3a36847f8052ce5', 'gender': 1, 'id': 14304, 'name': 'Mary Clare', 'order': 4, 'profile_path': '/lAdEwCGiSUj9CCMPB4L9X4oujLe.jpg'}, {'cast_id': 23, 'character': 'Det. Insp. Kent', 'credit_id': '52fe436bc3a36847f8052ce9', 'gender': 2, 'id': 7383, 'name': 'John Longden', 'order': 5, 'profile_path': '/rsCoUEx2ThNIz12fBR6vPncCICk.jpg'}, {'cast_id': 24, 'character': 'Guy', 'credit_id': '52fe436bc3a36847f8052ced', 'gender': 2, 'id': 27942, 'name': 'George Curzon', 'order': 6, 'profile_path': None}, {'cast_id': 25, 'character': 'Ericas Onkel Basil', 'credit_id': '52fe436bc3a36847f8052cf1', 'gender': 2, 'id': 14303, 'name': 'Basil Radford', 'order': 7, 'profile_path': '/9STo7Tgdutplo78ZtyeINGWkXUk.jpg'}, {'cast_id': 26, 'character': 'Christine Clay', 'credit_id': '52fe436bc3a36847f8052cf5', 'gender': 1, 'id': 27943, 'name': 'Pamela Carme', 'order': 8, 'profile_path': None}, {'cast_id': 27, 'character': 'Detective Sergeant Miller', 'credit_id': '52fe436bc3a36847f8052cf9', 'gender': 2, 'id': 27944, 'name': 'George Merritt', 'order': 9, 'profile_path': None}, {'cast_id': 28, 'character': 'Henry Briggs', 'credit_id': '52fe436bc3a36847f8052cfd', 'gender': 2, 'id': 27945, 'name': 'J.H. Roberts', 'order': 10, 'profile_path': None}, {'cast_id': 29, 'character': \"Truckfahrer bei Tom's Hat\", 'credit_id': '52fe436bc3a36847f8052d01', 'gender': 2, 'id': 27946, 'name': 'Jerry Verno', 'order': 11, 'profile_path': None}, {'cast_id': 30, 'character': 'Police Sergeant Ruddock', 'credit_id': '52fe436bc3a36847f8052d05', 'gender': 2, 'id': 27947, 'name': 'H.F. Maltby', 'order': 12, 'profile_path': None}, {'cast_id': 31, 'character': 'Police Constable', 'credit_id': '52fe436bc3a36847f8052d09', 'gender': 2, 'id': 27948, 'name': 'John Miller', 'order': 13, 'profile_path': None}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'cast_id': 2, 'character': 'Alex Whitman', 'credit_id': '52fe4327c3a36847f803e629', 'gender': 2, 'id': 14408, 'name': 'Matthew Perry', 'order': 0, 'profile_path': '/oSKEEDXDNnwWdQ68qfDVD6Q7Pxp.jpg'}, {'cast_id': 3, 'character': 'Isabel Fuentes', 'credit_id': '52fe4327c3a36847f803e62d', 'gender': 1, 'id': 3136, 'name': 'Salma Hayek', 'order': 1, 'profile_path': '/u5mg73xKVqm8oT93HoMmsgQHyoK.jpg'}, {'cast_id': 4, 'character': 'Jeff', 'credit_id': '52fe4327c3a36847f803e631', 'gender': 2, 'id': 4602, 'name': 'Jon Tenney', 'order': 2, 'profile_path': '/fiG1bW6DX1szsRDPIYjfIKPQ0kV.jpg'}, {'cast_id': 5, 'character': 'Lanie', 'credit_id': '52fe4327c3a36847f803e635', 'gender': 1, 'id': 6751, 'name': 'Siobhan Fallon', 'order': 3, 'profile_path': '/wVFa8GiY0xdOLFsvGygy9RMtcBc.jpg'}, {'cast_id': 16, 'character': 'Great Grandma', 'credit_id': '52fe4327c3a36847f803e675', 'gender': 1, 'id': 20360, 'name': 'Angelina Torres', 'order': 4, 'profile_path': None}, {'cast_id': 17, 'character': 'Richard Whitman', 'credit_id': '52fe4327c3a36847f803e679', 'gender': 2, 'id': 20361, 'name': 'John Bennett Perry', 'order': 5, 'profile_path': '/bzFhwuXsdZiOHRtBgz4XVELIFYO.jpg'}, {'cast_id': 18, 'character': 'Nan Whitman', 'credit_id': '52fe4327c3a36847f803e67d', 'gender': 1, 'id': 20362, 'name': 'Jill Clayburgh', 'order': 6, 'profile_path': '/twrfhIvbqHuJ7nXVpehvU6nyi6R.jpg'}, {'cast_id': 19, 'character': 'Cathy Stewart', 'credit_id': '52fe4327c3a36847f803e681', 'gender': 1, 'id': 20363, 'name': 'Suzanne Snyder', 'order': 7, 'profile_path': '/90FrTcjJudpeIYUjUzlO6XAmvnt.jpg'}, {'cast_id': 20, 'character': 'Amalia', 'credit_id': '52fe4327c3a36847f803e685', 'gender': 0, 'id': 13029, 'name': 'Anne Betancourt', 'order': 8, 'profile_path': '/6UU5P4DzjJTSBFztIu1nALT2tk0.jpg'}, {'cast_id': 21, 'character': 'Juan Fuentes', 'credit_id': '52fe4327c3a36847f803e689', 'gender': 2, 'id': 4511, 'name': 'Mark Adair-Rios', 'order': 9, 'profile_path': '/rX4d1e5jlF5P73qynjjUzJslB0c.jpg'}, {'cast_id': 22, 'character': 'Judd Marshall', 'credit_id': '52fe4327c3a36847f803e68d', 'gender': 2, 'id': 4171, 'name': 'Stanley DeSantis', 'order': 10, 'profile_path': '/4cHxkhTd7oklyNkdva9WJp0FLrX.jpg'}, {'cast_id': 23, 'character': 'Antonio Fuentes', 'credit_id': '52fe4327c3a36847f803e691', 'gender': 0, 'id': 4665, 'name': 'Josh Cruze', 'order': 11, 'profile_path': '/v3QrQzH0uGV9pd1dNR5Ue6a74qO.jpg'}, {'cast_id': 24, 'character': 'Petra', 'credit_id': '52fe4327c3a36847f803e695', 'gender': 0, 'id': 4666, 'name': 'Angela Lanza', 'order': 12, 'profile_path': '/zmf6TMWMVCdnuUfpgdnioaICk1L.jpg'}, {'cast_id': 25, 'character': 'Phil', 'credit_id': '52fe4327c3a36847f803e699', 'gender': 2, 'id': 4445, 'name': 'Chris Bauer', 'order': 13, 'profile_path': '/3KYVMaGkWTEDQ0T9lsu85pVbP4T.jpg'}, {'cast_id': 26, 'character': 'Chuy', 'credit_id': '577e438f925141440c000d63', 'gender': 0, 'id': 115874, 'name': 'Carlos GÃ³mez', 'order': 14, 'profile_path': '/nBxwoMv1zrhNXyEjYXbcdmAdmF0.jpg'}]   \n",
      "2638962  [{'cast_id': 6, 'character': 'Antoine Doinel', 'credit_id': '52fe421ec3a36847f8005661', 'gender': 2, 'id': 1653, 'name': 'Jean-Pierre LÃ©aud', 'order': 0, 'profile_path': '/dzkPODapVe4CSubEqI9ytTCqnZ7.jpg'}, {'cast_id': 7, 'character': 'Gilberte Doinel', 'credit_id': '52fe421ec3a36847f8005665', 'gender': 1, 'id': 1654, 'name': 'Claire Maurier', 'order': 1, 'profile_path': '/cP1n7zMsMKr77xJeR3CncomxEZ0.jpg'}, {'cast_id': 8, 'character': 'Julien Doinel', 'credit_id': '52fe421ec3a36847f8005669', 'gender': 0, 'id': 1655, 'name': 'Albert RÃ©my', 'order': 2, 'profile_path': '/6b8eyIXAV6oA5eX6ltc3hF7ZB3d.jpg'}, {'cast_id': 10, 'character': 'Mr. Bigey', 'credit_id': '52fe421ec3a36847f8005673', 'gender': 2, 'id': 1658, 'name': 'Georges Flamant', 'order': 3, 'profile_path': '/lQwmtPsFWME63x5M7IRF6g8bLrR.jpg'}, {'cast_id': 11, 'character': 'RenÃ©', 'credit_id': '52fe421ec3a36847f8005677', 'gender': 0, 'id': 1659, 'name': 'Patrick Auffay', 'order': 4, 'profile_path': None}, {'cast_id': 12, 'character': 'Director of the school', 'credit_id': '52fe421ec3a36847f800567b', 'gender': 0, 'id': 1660, 'name': 'Robert Beauvais', 'order': 5, 'profile_path': None}, {'cast_id': 13, 'character': 'Mme Bigey', 'credit_id': '52fe421ec3a36847f800567f', 'gender': 0, 'id': 1661, 'name': 'Yvonne Claudie', 'order': 6, 'profile_path': None}, {'cast_id': 14, 'character': 'English Teacher', 'credit_id': '52fe421ec3a36847f8005683', 'gender': 0, 'id': 1662, 'name': 'Pierre Repp', 'order': 7, 'profile_path': '/1AUhiNGBAR0C6AU9iK1IXBs3QTz.jpg'}, {'cast_id': 17, 'character': 'French Teacher', 'credit_id': '52fe421ec3a36847f8005693', 'gender': 0, 'id': 1656, 'name': 'Guy Decomble', 'order': 8, 'profile_path': '/34iexAuqI1asyFounbSXSCFphen.jpg'}, {'cast_id': 20, 'character': 'Betrand Mauricet', 'credit_id': '52fe421ec3a36847f8005697', 'gender': 0, 'id': 1077237, 'name': 'Daniel Couturier', 'order': 9, 'profile_path': None}, {'cast_id': 21, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569b', 'gender': 0, 'id': 1077238, 'name': 'FranÃ§ois Nocher', 'order': 10, 'profile_path': None}, {'cast_id': 22, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569f', 'gender': 2, 'id': 150939, 'name': 'Richard Kanayan', 'order': 11, 'profile_path': '/vCMDk3ifj2vJKZYCISXT3K6DYXF.jpg'}, {'cast_id': 23, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a3', 'gender': 0, 'id': 1077239, 'name': 'Renaud Fontanarosa', 'order': 12, 'profile_path': None}, {'cast_id': 24, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a7', 'gender': 0, 'id': 1077240, 'name': 'Michel Girard', 'order': 13, 'profile_path': None}, {'cast_id': 25, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056ab', 'gender': 0, 'id': 71997, 'name': 'Serge Moati', 'order': 14, 'profile_path': '/wccRQKHrX61sH4WlOtM1KBP4qaq.jpg'}, {'cast_id': 26, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056af', 'gender': 0, 'id': 1077241, 'name': 'Bernard Abbou', 'order': 15, 'profile_path': None}, {'cast_id': 27, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b3', 'gender': 0, 'id': 1077242, 'name': 'Jean-FranÃ§ois Bergouignan', 'order': 16, 'profile_path': None}, {'cast_id': 28, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b7', 'gender': 0, 'id': 1077243, 'name': 'Michel Lesignor', 'order': 17, 'profile_path': None}, {'cast_id': 31, 'character': 'Man in Street', 'credit_id': '5457f0a1c3a3683993000156', 'gender': 2, 'id': 24299, 'name': 'Jean-Claude Brialy', 'order': 18, 'profile_path': '/g3kkYcAvq90tALMErxmdAIcIXsE.jpg'}, {'cast_id': 32, 'character': 'Woman with Dog', 'credit_id': '5457f0bec3a36839a0000144', 'gender': 1, 'id': 14812, 'name': 'Jeanne Moreau', 'order': 19, 'profile_path': '/uHJnVwCzehEoz0mIlwN7xkymql8.jpg'}, {'cast_id': 33, 'character': 'Man in Funfair', 'credit_id': '5457f0d3c3a368399300015b', 'gender': 2, 'id': 34613, 'name': 'Philippe de Broca', 'order': 20, 'profile_path': '/yrvmXE2SJBX659r2Y7eWwlmwfYd.jpg'}, {'cast_id': 34, 'character': 'Man in Funfair', 'credit_id': '5457f0e5c3a368399d00014c', 'gender': 0, 'id': 1650, 'name': 'FranÃ§ois Truffaut', 'order': 21, 'profile_path': '/apCCV99N3FqB5NsEPqOzetlkprL.jpg'}]   \n",
      "\n",
      "                                                                               tagline  \\\n",
      "6566765                                                  It ain't over 'til it's over.   \n",
      "6880303                                   First came love... then came Reverend Frank.   \n",
      "2083077                                                          A Brilliant Melodrama   \n",
      "1492304  What if finding the love of your life meant changing the life that you loved?   \n",
      "2638962                                            Angel faces hell-bent for violence.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        overview  \n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When he loses a highly publicized virtual boxing match to ex-champ Rocky Balboa, reigning heavyweight titleholder, Mason Dixon retaliates by challenging Rocky to a nationally televised, 10-round exhibition bout. To the surprise of his son and friends, Rocky agrees to come out of retirement and face an opponent who's faster, stronger and thirty years his junior.  \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Newly engaged, Ben and Sadie can't wait to start their life together and live happily ever after. However Sadie's family church's Reverend Frank won't bless their union until they pass his patented, \"foolproof\" marriage prep course consisting of outrageous classes, outlandish homework assignments and some outright invasion of privacy.  \n",
      "2083077  Derrick De Marney finds himself in a 39 Steps situation when he is wrongly accused of murder. While a fugitive from the law, De Marney is helped by heroine Nova Pilbeam, who three years earlier had played the adolescent kidnap victim in Hitchcock's The Man Who Knew Too Much. The obligatory \"fish out of water\" scene, in which the principals are briefly slowed down by a banal everyday event, occurs during a child's birthday party. The actual villain, whose identity is never in doubt (Hitchcock made thrillers, not mysteries) is played by George Curzon, who suffers from a twitching eye. Curzon's revelation during an elaborate nightclub sequence is a Hitchcockian tour de force, the sort of virtuoso sequence taken for granted in these days of flexible cameras and computer enhancement, but which in 1937 took a great deal of time, patience and talent to pull off. Released in the US as The Girl Was Young, Young and Innocent was based on a novel by Josephine Tey.  \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alex Whitman (Matthew Perry) is a designer from New York City who is sent to Las Vegas to supervise the construction of a nightclub that his firm has been hired to build. Alex is a straight-laced WASP-ish type who, while enjoying a night on the town, meets Isabel Fuentes (Salma Hayek), a free-spirited Mexican-American photographer. Alex and Isabel are overtaken by lust at first sight and end up sp  \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For young Parisian boy Antoine Doinel, life is one difficult situation after another. Surrounded by inconsiderate adults, including his neglectful parents, Antoine spends his days with his best friend, Rene, trying to plan for a better life. When one of their schemes goes awry, Antoine ends up in trouble with the law, leading to even more conflicts with unsympathetic authority figures.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#This cell is for combining certain data from the necessary csv files into a single dataframe (complete)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "movies = pd.read_csv('./the-movies-dataset/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={\"tagline\": \"string\", \"id\":\"string\", 'genres':\"string\", \"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\", \"production_companies\" :\"string\"})\n",
    "movies = movies.dropna()\n",
    "movies = movies.reset_index()\n",
    "\n",
    "\n",
    "#filter rows of empty data from movies on the columns: \"genres\", \"production_companies\"\n",
    "drop_indices = []\n",
    "for i in range(len(movies)):\n",
    "    len_1 = len(movies.iloc[i].loc[\"genres\"])                   \n",
    "    if(movies.iloc[i].loc[\"genres\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "        continue\n",
    "    len_2 = len(movies.iloc[i].loc[\"production_companies\"])\n",
    "    if(movies.iloc[i].loc[\"production_companies\"][len_2 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)    \n",
    "        continue   \n",
    "\n",
    "movies = movies.drop(labels=drop_indices, axis = 0)\n",
    "movies = movies.reset_index(names = \"index_1\")\n",
    "\n",
    "\n",
    "ratings = pd.read_csv('./the-movies-dataset/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"), dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})\n",
    "ratings = ratings.rename(columns={\"movieId\": \"id\"})\n",
    "ratings.dropna()\n",
    "ratings = ratings.reset_index(names = \"index_2\")\n",
    "\n",
    "\n",
    "keywords = pd.read_csv('./the-movies-dataset/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})\n",
    "keywords.dropna()\n",
    "keywords = keywords.reset_index()\n",
    "\n",
    "#filter rows of empty data from keyword on the keywords column\n",
    "drop_indices = []\n",
    "for i in range(len(keywords)):\n",
    "    len_1 = len(keywords.iloc[i].loc[\"keywords\"])                   \n",
    "    if(keywords.iloc[i].loc[\"keywords\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "\n",
    "keywords = keywords.drop(labels=drop_indices, axis = 0)\n",
    "keywords = keywords.reset_index(names = \"index_3\")\n",
    "\n",
    "\n",
    "credits = pd.read_csv(\"./the-movies-dataset/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})\n",
    "credits.dropna()\n",
    "credits = credits.reset_index()\n",
    "\n",
    "#filter rows of empty data from credits on the cast column \n",
    "drop_indices = []\n",
    "for i in range(len(credits)):\n",
    "    len_1 = len(credits.iloc[i].loc[\"cast\"])                   \n",
    "    if(credits.iloc[i].loc[\"cast\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "\n",
    "credits = credits.drop(labels=drop_indices, axis = 0)\n",
    "credits = credits.reset_index(names = \"index_4\")\n",
    "\n",
    "\n",
    "#default merge is inner: this only keeps movies that have the id existing in both dataframes\n",
    "complete =  pd.merge(movies, ratings, on =\"id\")\n",
    "complete =  pd.merge(complete,keywords, on =\"id\")\n",
    "complete  = pd.merge(complete,credits, on =\"id\")\n",
    "\n",
    "\n",
    "complete = complete.sort_values(by = 'userId')\n",
    "\n",
    "\n",
    "#use only certain types of columns\n",
    "complete  = complete.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "#just for code clarity\n",
    "del movies\n",
    "del ratings\n",
    "del keywords\n",
    "del credits\n",
    "\n",
    "#for testing\n",
    "print(complete.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete number of users: 260788\n",
      "Number of train users before random selection: 14314\n",
      "Number of test users before random selection: 68048\n",
      "Average number of ratings for the users chosen: 50.236\n",
      "Minutes taken: 4.779916667938233\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "def populate_names(item):\n",
    "    \"\"\"used to extract names from the syntax of certain data entries\"\"\"\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    index = 0\n",
    "    for item in jsons:\n",
    "        if(index == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        index += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provide_data(array):\n",
    "    \"\"\"extract data from row of complete_array\"\"\"\n",
    "    movie_data = []\n",
    "    movie_data.append(int(array[0]))\n",
    "    movie_data.append(int(array[1]))\n",
    "    movie_data.append(float(array[2]))\n",
    "    movie_data.append(array[3])  \n",
    "\n",
    "    movie_data.append(populate_names(array[4]))\n",
    "    movie_data.append(populate_names(array[5]))\n",
    "    movie_data.append(populate_names(array[6]))\n",
    "    movie_data.append(populate_names(array[7]))\n",
    "\n",
    "    movie_data.append(str(array[8]))\n",
    "    movie_data.append(str(array[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "#LOOK: \n",
    "#https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "#iterating over pandas objects is slow!!!\n",
    "#should check for other datastructures below\n",
    "\n",
    "\n",
    "#the list of rows with users id and raw movie data\n",
    "complete_list = complete.values.tolist()\n",
    "\n",
    "print(\"Complete number of users:\", len(list(complete[\"userId\"].unique()))) #260788\n",
    "\n",
    "del complete\n",
    "\n",
    "#the complete list of user rows without ratings of the same movie more than once for a given user\n",
    "complete_list_no_dups = []\n",
    "\n",
    "#distinquish the users the row belongs to \n",
    "last_id = complete_list[0][0]\n",
    "\n",
    "#the set of movies that a user has rated\n",
    "#used to omit later ratings of a movie that the user has already rated\n",
    "movie_set = set()\n",
    "\n",
    "#how many rows a single user takes up for each user in the order of their occurance\n",
    "gaps = []\n",
    "\n",
    "#appended to gaps when all of a users rows have been counted\n",
    "gap_len = 0\n",
    "\n",
    "\n",
    "#populates gaps and complete_list_no_dups by omitting movies that already have a rating in respect to each user\n",
    "for row in complete_list:\n",
    "    if last_id != row[0]:\n",
    "        movie_set= set()\n",
    "        complete_list_no_dups.append(row)\n",
    "        movie_set.add(row[1])\n",
    "        gaps.append(gap_len)\n",
    "        gap_len = 1\n",
    "    else:\n",
    "        if row[1] not in movie_set:\n",
    "            complete_list_no_dups.append(row)\n",
    "            gap_len+=1\n",
    "            movie_set.add(row[1])\n",
    "    last_id = row[0]\n",
    "\n",
    "#add the last gap_len\n",
    "gaps.append(gap_len)\n",
    "\n",
    "\n",
    "#for clarity\n",
    "del complete_list\n",
    "\n",
    "\n",
    "full_index = 0 #index in the complete_list_no_dups list\n",
    "\n",
    "bounds_train = [] #bounds of the indices of a trains users movies for each train user (train users fall into 50 <= gaps[user_index] and 70 >= gaps[user_index])\n",
    "bounds_test = [] #bounds of the indices of a test users movies for each test user (test users fall into 5 <= gaps[user_index] and 10 >= gaps[user_index])\n",
    "\n",
    "\n",
    "#populates bounds_train and bounds_test\n",
    "for user_index in range(len(gaps)):\n",
    "    if 50 <= gaps[user_index] and 70 >= gaps[user_index]:\n",
    "        bounds_train.append([full_index, full_index+gaps[user_index]])\n",
    "\n",
    "    elif 5 <= gaps[user_index] and 10 >= gaps[user_index]:\n",
    "        bounds_test.append([full_index, full_index+gaps[user_index]])\n",
    "\n",
    "    full_index+=gaps[user_index]    \n",
    "\n",
    "\n",
    "print(\"Number of train users before random selection:\",len(bounds_train)) #14314\n",
    "print(\"Number of test users before random selection:\", len(bounds_test)) #68048\n",
    "\n",
    "#for clarity\n",
    "del gaps\n",
    "\n",
    "\n",
    "nof_train_bounds_to_select = 5000\n",
    "nof_test_bounds_to_select = 1000\n",
    "\n",
    "bounds_train_sample = random.sample(bounds_train, nof_train_bounds_to_select)\n",
    "bounds_test_sample = random.sample(bounds_test, nof_test_bounds_to_select)\n",
    "\n",
    "#for clarity\n",
    "del bounds_train\n",
    "del bounds_test\n",
    "\n",
    "\n",
    "sampled_data = []\n",
    "avg = 0\n",
    "cnt = 0\n",
    "\n",
    "for bound in bounds_train_sample:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        movie_data[0] = cnt\n",
    "        sampled_data.append(movie_data)\n",
    "        avg += 1\n",
    "    cnt+=1\n",
    "\n",
    "for bound in bounds_test_sample:\n",
    "    for movie in complete_list_no_dups[bound[0]:bound[1]]:\n",
    "        movie_data = provide_data(movie)\n",
    "        movie_data[0] = cnt\n",
    "        sampled_data.append(movie_data)\n",
    "        avg += 1\n",
    "    cnt+=1\n",
    "\n",
    "\n",
    "#for clarity\n",
    "del complete_list_no_dups\n",
    "del bounds_train_sample\n",
    "del bounds_test_sample\n",
    "\n",
    "\n",
    "\n",
    "#average number of ratings per user\n",
    "print(\"Average number of ratings for the users chosen:\", float(avg/cnt))\n",
    "\n",
    "\n",
    "print(\"Minutes taken:\", float((time.time()-start_time)/60))\n",
    "\n",
    "\n",
    "# using older code:\n",
    "# Complete number of users: 260788\n",
    "# Number of train users before random selection: 14314\n",
    "# Number of test users before random selection: 68048\n",
    "# Number of users chosen: 6390\n",
    "# Average number of ratings for the users chosen: 49.07151799687011\n",
    "# Minutes taken:  12.13312626282374\n",
    "\n",
    "#using newer code:\n",
    "# Complete number of users: 260788\n",
    "# Number of train users before random selection: 14314\n",
    "# Number of test users before random selection: 68048\n",
    "# Number of users chosen: 6390\n",
    "# Average number of ratings for the users chosen: 49.07151799687011\n",
    "# Minutes taken:  5.005980257193247\n",
    "\n",
    "#using newer newer code:\n",
    "# Complete number of users: 260788\n",
    "# Number of train users before random selection: 14314\n",
    "# Number of test users before random selection: 68048\n",
    "# Number of users chosen: 301416\n",
    "# Average number of ratings for the users chosen: 50.236\n",
    "# Minutes taken: 4.950916175047556\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in a constructed_data/constructed_data.csv file so that cells below can run without running this cell and above\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, 'constructed_data')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    writer.writerows(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a starting point if the data is already saved to the constructed_data/constructed_data.csv\n",
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", 'r', encoding=\"utf-8\") as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "#for each user, distinuish whether they are a test or train user\n",
    "#note: technically in the second cell there is clearly distinquished test and train users\n",
    "#so this is technically somewhat of a redundant process\n",
    "#but, this cell executes instantly so there is no need to include the user label in constructed.csv\n",
    "\n",
    "user_to_data_train = []\n",
    "user_to_data_test = []\n",
    "\n",
    "user_id = data_list[0][0]\n",
    "ratings = []\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        if(5 <= len(ratings) and 10 >= len(ratings)):\n",
    "            user_to_data_test.append(ratings)\n",
    "        else:\n",
    "            user_to_data_train.append(ratings)\n",
    "        user_id = row[0]\n",
    "        ratings = [row]\n",
    "    else:\n",
    "        ratings.append(row)\n",
    "\n",
    "\n",
    "#distinuish whether the last user is a test or train user\n",
    "if(5 <= len(ratings) and 10 >= len(ratings)):\n",
    "    user_to_data_test.append(ratings)\n",
    "else:\n",
    "    user_to_data_train.append(ratings)\n",
    "\n",
    "\n",
    "\n",
    "user_to_data_train = random.sample(user_to_data_train, 5000)\n",
    "user_to_data_test = random.sample(user_to_data_test, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_1 to target comparison (train):\n",
      "[3.6440677966101696, 3.830188679245283, 3.925, 4.292307692307692, 2.694915254237288]\n",
      "[4.0, 4.0, 4.0, 4.0, 1.0]\n",
      "Feature_1 to target comparison (test):\n",
      "[3.875, 2.5714285714285716, 4.25, 2.5, 3.5714285714285716]\n",
      "[4.0, 3.0, 5.0, 2.0, 5.0]\n",
      "Feature_2 to target comparison (train):\n",
      "[3.745144639601795, 3.8076768875564437, 3.9182777682591516, 4.335568335872769, 2.8208415705890246]\n",
      "[4.0, 4.0, 4.0, 4.0, 1.0]\n",
      "Feature_2 to target comparison (test):\n",
      "[3.3499243716804292, 2.432058151190643, 4.485467687220292, 2.0, 3.197617080180566]\n",
      "[4.0, 3.0, 5.0, 2.0, 5.0]\n",
      "Feature_3 to target comparison (train):\n",
      "[4.030184398469862, 4.205698935046528, 3.793402238618873, 4.174767174650713, 3.0054013377449036]\n",
      "[4.0, 4.0, 4.0, 4.0, 1.0]\n",
      "Feature_3 to target comparison (test):\n",
      "[3.239058885293259, 4.197714366341513, 3.269048587799359, 3.51315448216471, 4.222877788398437]\n",
      "[4.0, 3.0, 5.0, 2.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "from ordered_set import OrderedSet\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "class user_type_vars():\n",
    "    \"\"\"Each of the variables in this class represent the data structures for a user type\"\"\"\n",
    "    def __init__(self):\n",
    "        #for each user, a dictionary of movie_id to the movies rating for each movie the user watched\n",
    "        self.user_to_movie_id_to_rating = [] \n",
    "\n",
    "        #for each user, a random choice of movie_id from all the movies the user watched to represent the target movie\n",
    "        self.user_to_target_movie_id = [] \n",
    "\n",
    "        #for each user, this is the index of the users target movie in the order of train movies_in_order\n",
    "        #(train_users only)\n",
    "        self.user_to_target_index_full = [] \n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set \n",
    "        #missing ratings and target movie ratings are set to that movies average rating\n",
    "        #(train_users only)\n",
    "        self.user_to_ratings_full = [] \n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set\n",
    "        #the movies mean rating is subtracted from each rating\n",
    "        #missing ratings and target movie ratings are set to zero\n",
    "        #(train_users only)\n",
    "        self.user_to_ratings_full_transform = []\n",
    "\n",
    "        #this is a set of every unique target movie for the train set\n",
    "        #this is used to check if a movie is in the train set but only as a target movie\n",
    "        #(train_users only)\n",
    "        self.target_movies = set()\n",
    "\n",
    "        #for every movie watched by the user_type, a list of ratings\n",
    "        self.movie_id_to_ratings = dict()\n",
    "\n",
    "        #all the movie ids in the order of where they appear first in the list of user ratings (either train or test users) \n",
    "        self.movies_in_order = OrderedSet()\n",
    "\n",
    "        #model input features x for each user\n",
    "        self.feature_1 = []\n",
    "        self.feature_2 = []\n",
    "        self.feature_3 = []\n",
    "\n",
    "        #model output feature y for each user\n",
    "        self.user_to_target_rating  = [] \n",
    "\n",
    "\n",
    "#user_type_vars can represent a group of train users and a group of test users\n",
    "train_users = user_type_vars()\n",
    "test_users = user_type_vars()\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def load_feature_1_and_2(target_movies, movies_in_order, user_to_data, movie_id_to_ratings, user_to_movie_id_to_rating, user_to_target_movie_id, user_to_target_rating, feature_1, feature_2):\n",
    "    \"\"\"\n",
    "    This is ran once to be used to populate features 1 and 2 for the train_users...\n",
    "    and ran again to be used to populate features 1 and 2 for the test_users\n",
    "    It also populates the train and test version of these variables: target_movies, movies_in_order, movie_id_to_ratings,\n",
    "    user_to_movie_id_to_rating, user_to_target_movie_id, user_to_target_rating\n",
    "    These variables are used in the load_feature_3 function \n",
    "    \"\"\" \n",
    "    #these are used to calculate the overall train rating\n",
    "    #the overall_average_train which is overall_rating_sum/overall_rating_count is only set to the output of the \"train\" function call\n",
    "    #this is used to fill in ratings for movies that are only target movies for a certain set of users \n",
    "    overall_rating_sum = 0\n",
    "    overall_rating_count = 0\n",
    "\n",
    "    for i in range(len(user_to_data)):\n",
    "        movie_id_to_words = dict()\n",
    "        movie_id_to_rating = dict()\n",
    "        index = 0\n",
    "        rand_int = random.randint(0, len(user_to_data[i])-1)\n",
    "        for movie_data in user_to_data[i]:\n",
    "            if index == rand_int:    \n",
    "                target_movies.add(movie_data[1])\n",
    "                user_to_target_movie_id.append(movie_data[1])\n",
    "            else:\n",
    "                #the program should train and test while simulating the possibility of\n",
    "                #some new movies having no existing rating data in the database.\n",
    "                #This is critical if the resulting model were to be tried on completely new data.\n",
    "                \n",
    "                #this is why target ratings are omitted from movie_id_to_ratings\n",
    "                #the same logic stands for overall_average_train which is formed by overall_rating_sum and overall_rating_count\n",
    "                overall_rating_sum += float(movie_data[2])\n",
    "                overall_rating_count += 1\n",
    "\n",
    "                if movie_data[1] in movie_id_to_ratings.keys():\n",
    "                    movie_id_to_ratings[movie_data[1]].append(float(movie_data[2]))\n",
    "                else:\n",
    "                    movie_id_to_ratings[movie_data[1]] = [float(movie_data[2])]\n",
    "\n",
    "            movie_string = \"\"\n",
    "\n",
    "            #use this to apply all the text data and combine in to a single list of words (repeats allowed):\n",
    "            # for index in range (3,len(movie_data)):\n",
    "            #     if(index!= len(movie_data)-1):\n",
    "            #         movie_string+= movie_data[index]+\" \"\n",
    "            #     else:\n",
    "            #         movie_string+= movie_data[index]\n",
    "\n",
    "\n",
    "            #all of the text columns and a few combinations of certain text columns were tested but they were not helpful in...\n",
    "            #increasing model performance (see README.md)\n",
    "\n",
    "            #Use this truncated code to only include the genre column strings:\n",
    "            movie_string = movie_data[4]\n",
    "\n",
    "            #lematization and conversion to lists of words\n",
    "            cleaned = remove_stopwords(movie_string)\n",
    "            cleaned = [wnl.lemmatize(word) for word in cleaned.split(\" \")]\n",
    "            cleaned = [word[:-1] for word in cleaned if word.endswith(\".\")] + [word for word in cleaned if not word.endswith(\".\")]\n",
    "\n",
    "            movie_id_to_words[movie_data[1]] = cleaned\n",
    "            movie_id_to_rating[movie_data[1]] = float(movie_data[2])\n",
    "            movies_in_order.add(movie_data[1])\n",
    "            index+=1\n",
    "\n",
    "        user_to_movie_id_to_rating.append(movie_id_to_rating)\n",
    "\n",
    "        #the current users set of words from all the movies they rated\n",
    "        users_words_in_order = OrderedSet()\n",
    "        for movie_id in movie_id_to_words.keys():\n",
    "            for word in movie_id_to_words[movie_id]:\n",
    "                users_words_in_order.add(word)\n",
    "\n",
    "\n",
    "        word_counts = [] #list of word counts for the users_words_in_order for each movie (excluding target)\n",
    "        target_word_counts = [] #word counts for the users_words_in_order for the target movie\n",
    "\n",
    "\n",
    "        #for each movie the user watched record the wordcount for each word in users_words_in_order\n",
    "        for movie_id in movie_id_to_words.keys():\n",
    "            if movie_id != user_to_target_movie_id[-1]:\n",
    "                temp_dict = Counter(movie_id_to_words[movie_id])\n",
    "                temp_list = []\n",
    "                for word in users_words_in_order:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])\n",
    "                    else:\n",
    "                        temp_list.append(0)  \n",
    "                word_counts.append(temp_list)  \n",
    "            else:\n",
    "                temp_dict = Counter(movie_id_to_words[movie_id])\n",
    "                temp_list = []\n",
    "                for word in users_words_in_order:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])             \n",
    "                    else:\n",
    "                        temp_list.append(0) \n",
    "                target_word_counts = temp_list\n",
    "        \n",
    "\n",
    "        #construct the normalized tf-idf before applying cossine similairity\n",
    "        #this places value on terms that are un-common in alot of documents,\n",
    "        #while still placing value on how common they are in the document at hand\n",
    "        #in this case documents are word counts for the corpuses of a single movie the user rated\n",
    "        #this leads to a more powerful quantifier for cossine similairity between documents\n",
    "\n",
    "        complete_word_counts = word_counts.copy()\n",
    "        complete_word_counts.append(target_word_counts)\n",
    "        transformed_word_counts = TfidfTransformer().fit_transform(complete_word_counts).toarray()\n",
    "\n",
    "\n",
    "        #populate ratings without the target rating\n",
    "        ratings = []\n",
    "        for movie_id in movie_id_to_rating.keys():\n",
    "            if movie_id != user_to_target_movie_id[-1]:\n",
    "                ratings.append(movie_id_to_rating[movie_id])\n",
    "            else:\n",
    "                #add the target movie rating for a single user (each user has only one target movie rating)\n",
    "                user_to_target_rating.append(movie_id_to_rating[movie_id])\n",
    "    \n",
    "\n",
    "        def predict():\n",
    "            \"Use the word counts and ratings to add prediction to feature_1 list and feature_2 list\"\n",
    "            #pred_1 is unweighted average of all of the users movie\n",
    "            pred_1 = 0 \n",
    "            #pred_2 is weighted average of all the users movies (weights are based on (cossine similarity/linear kernel))\n",
    "            #unless denominator is zero (see below)\n",
    "            pred_2 = 0\n",
    "\n",
    "            sum = 0\n",
    "            for i in range(len(ratings)):\n",
    "                sum += ratings[i]\n",
    "            pred_1 = float(sum/len(ratings))\n",
    "\n",
    "            cosine_sim = linear_kernel(X = transformed_word_counts[0:-1],Y = [transformed_word_counts[-1]])\n",
    "            cosine_sim = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            pred_2 = pred_1\n",
    "            for i in range(len(ratings)):\n",
    "                numerator += float(cosine_sim[i]*ratings[i])\n",
    "                denominator += cosine_sim[i]\n",
    "    \n",
    "            #in case of potential division by zero\n",
    "            if denominator != 0:\n",
    "                pred_2 = float(numerator/denominator)\n",
    "    \n",
    "            return (pred_1, pred_2)\n",
    "        \n",
    "        predictions = predict()\n",
    "\n",
    "        feature_1.append(predictions[0])\n",
    "        feature_2.append(predictions[1])\n",
    "            \n",
    "        \n",
    "    return float(overall_rating_sum/overall_rating_count)\n",
    "\n",
    "#populate train data (feature 1 and feature 2)\n",
    "#the overall_average_train which is overall_rating_sum/overall_rating_count is only set to the output of the \"train\" function call\n",
    "#this is used to fill in ratings for movies that are only target movies for a certain set of users\n",
    "overall_average_train = load_feature_1_and_2(train_users.target_movies, train_users.movies_in_order, user_to_data_train, train_users.movie_id_to_ratings, train_users.user_to_movie_id_to_rating, \n",
    "                                                         train_users.user_to_target_movie_id, train_users.user_to_target_rating, train_users.feature_1, train_users.feature_2)\n",
    "\n",
    "#populate test data (feature 1 and feature 2)\n",
    "load_feature_1_and_2(set(), test_users.movies_in_order, user_to_data_test, test_users.movie_id_to_ratings, test_users.user_to_movie_id_to_rating, \n",
    "               test_users.user_to_target_movie_id,\n",
    "               test_users.user_to_target_rating, test_users.feature_1, test_users.feature_2)\n",
    "\n",
    "\n",
    "def pre_svd(movie_id_to_average_rating, movies_in_order, user_to_ratings_full_transform, user_to_ratings_full, user_to_target_index_full, \n",
    "               user_to_movie_id_to_rating, user_to_target_movie_id):\n",
    "    \"\"\"\n",
    "    Populate the lists user_to_ratings_full and user_to_ratings_full_transform \n",
    "    User_to_ratings_full_transform is used for svd because it includes entries from all movies in movies_in_order\n",
    "    It also transforms the data in user_to_ratings_full by subtracting the movie rating mean\n",
    "    This means that the transformed value at the indices of unwatched movies and index coresponding to target movies are zero\n",
    "    \"\"\"\n",
    "    for i in range(len(user_to_movie_id_to_rating)):\n",
    "        ratings = []\n",
    "        transformed_ratings = []\n",
    "\n",
    "        #the index of the target movie within the entire movies_in_order ordered set\n",
    "        index = 0\n",
    "\n",
    "        for movie_id in movies_in_order:\n",
    "            if movie_id == user_to_target_movie_id[i]:\n",
    "                user_to_target_index_full.append(index)\n",
    "                ratings.append(movie_id_to_average_rating[movie_id])\n",
    "                transformed_ratings.append(movie_id_to_average_rating[movie_id] - movie_id_to_average_rating[movie_id]) \n",
    "            elif movie_id in user_to_movie_id_to_rating[i].keys():\n",
    "                ratings.append(user_to_movie_id_to_rating[i][movie_id])\n",
    "                transformed_ratings.append(user_to_movie_id_to_rating[i][movie_id] - movie_id_to_average_rating[movie_id])\n",
    "            else:\n",
    "                ratings.append(movie_id_to_average_rating[movie_id])\n",
    "                transformed_ratings.append(movie_id_to_average_rating[movie_id] - movie_id_to_average_rating[movie_id])\n",
    "            index +=1\n",
    "        #user_to_ratings_full is just for demonstration\n",
    "        user_to_ratings_full.append(ratings)\n",
    "        #per movie averages have been subtracted (data is ready for svd)\n",
    "        user_to_ratings_full_transform.append(transformed_ratings)\n",
    "\n",
    "\n",
    "\n",
    "def svd_full(user_to_ratings_full_transform, n, movie_id_to_average_rating):\n",
    "    \"\"\"\n",
    "    1. get the svd of the user_to_ratings_full_transform \n",
    "    2. truncate each factor to 20 components\n",
    "    3. multiply the trauncated components together (U X s) X V \n",
    "    4. scale back the values to the orginal rating scale (1-5) and return result\n",
    "    \"\"\"\n",
    "    U, s, V = np.linalg.svd(user_to_ratings_full_transform, full_matrices=False)\n",
    "    \n",
    "    #simplify factors to n features\n",
    "    s=np.diag(s)\n",
    "    s=s[0:n,0:n]\n",
    "    U=U[:,0:n]\n",
    "    V=V[0:n,:]\n",
    "\n",
    "    #reconstruct to a new array\n",
    "    Us = np.dot(U,s)\n",
    "    UsV = np.dot(Us,V)\n",
    "\n",
    "    x = np.tile(list(movie_id_to_average_rating.values()), (UsV.shape[0],1))\n",
    "\n",
    "    #this tranforms the UsV row by row into the original rating scale (1-5)\n",
    "    UsV = UsV + x\n",
    "\n",
    "    #be consistent with data structures...\n",
    "    return list(UsV)\n",
    "\n",
    "\n",
    "\n",
    "def load_feature_3():\n",
    "    \"\"\"\n",
    "    populate feature_3 with a method loosely outlined here:\n",
    "    1. find the average ratings for movies \n",
    "    2. pre_svd writes a rating for every movie for every user as well as a transformed version of those rating with the averages found above\n",
    "    3. then use the output of the svd_full function by row for user and by column for the target movie rating prediction\n",
    "    \"\"\"\n",
    "\n",
    "    #Every movie ever seen by any user in either the test and train sets\n",
    "    all_movies_in_order = train_users.movies_in_order|test_users.movies_in_order\n",
    "\n",
    "\n",
    "    #When a movie has a number of target ratings and non-target ratings, then only the non-target ratings are used...\n",
    "    #to form the movies average rating\n",
    "\n",
    "    #There is a difference between non-target ratings between movie_id_to_average_rating_train and movie_id_to_average_rating_full.\n",
    "    #movie_id_to_average_rating_train considers the train set and movie_id_to_average_rating_full considers the train and test set\n",
    "\n",
    "    #When a movie has only target ratings for movie_id_to_average_rating_train or movie_id_to_average_rating_full...\n",
    "    #instead of using the mean of the actual target ratings, the movies average rating takes on the value of overall_average_train.\n",
    "    #this is used to simlulate the potential movies to be rated for a new user that have no ratings in the existing data.\n",
    "\n",
    "    #The code below deliniates two different averages for valid movies, a train average and a train+test or full average.\n",
    "    #The train average is used to normalize the ratings of the movies for train users in the first pre_svd call.\n",
    "    #The train+test averages are used to normalize the ratings of the movies for train+test users in the second pre_svd call.\n",
    "\n",
    "    movie_id_to_average_rating_train = dict()\n",
    "    movie_id_to_average_rating_full = dict()\n",
    "\n",
    "    for movie in all_movies_in_order:\n",
    "        temp = 0\n",
    "        if(movie in train_users.movie_id_to_ratings and movie in test_users.movie_id_to_ratings):\n",
    "            for rating in train_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_train[movie] = float(temp/len(train_users.movie_id_to_ratings[movie])) \n",
    "\n",
    "            for rating in test_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_full[movie] = float(temp/(len(train_users.movie_id_to_ratings[movie])+len(test_users.movie_id_to_ratings[movie])))  \n",
    "\n",
    "        elif(movie in train_users.movie_id_to_ratings):\n",
    "            for rating in train_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_train[movie] = float(temp/len(train_users.movie_id_to_ratings[movie]))\n",
    "            movie_id_to_average_rating_full[movie] = movie_id_to_average_rating_train[movie]\n",
    "\n",
    "        elif(movie in test_users.movie_id_to_ratings):        \n",
    "            if(movie in train_users.target_movies):\n",
    "                movie_id_to_average_rating_train[movie] = overall_average_train\n",
    "\n",
    "            for rating in test_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_full[movie] = float(temp/len(test_users.movie_id_to_ratings[movie]))\n",
    "        else:\n",
    "            if(movie in train_users.target_movies):\n",
    "                movie_id_to_average_rating_train[movie] = overall_average_train\n",
    "                movie_id_to_average_rating_full[movie] = overall_average_train\n",
    "            else:\n",
    "                movie_id_to_average_rating_full[movie] = overall_average_train\n",
    "   \n",
    "\n",
    "    #note: the three variables below are mirrored in the train_users object\n",
    "    #these variables are for the full set (all_movies_in_order)\n",
    "\n",
    "    #all the ratings for each user for the movies corresponding to the order of the ordered set (all_movies_in_order)\n",
    "    full_user_to_ratings_full = []\n",
    "    #all the transformed ratings for each user for the movies corresponding to the order of the ordered set (all_movies_in_order)\n",
    "    full_user_to_ratings_full_transform = [] \n",
    "    #for each user, the index of the target movie corresponding to the order of (all_movies_in_order)\n",
    "    full_user_to_target_index_full = [] \n",
    "\n",
    "\n",
    "    #combining the watched movies in this order (train and then test users)\n",
    "    full_user_to_movie_id_to_rating  = train_users.user_to_movie_id_to_rating + test_users.user_to_movie_id_to_rating\n",
    "    #combining the id of the target movie in this order (train and then test users)\n",
    "    full_user_to_target_movie_id = train_users.user_to_target_movie_id + test_users.user_to_target_movie_id\n",
    "\n",
    "\n",
    "    #the two function calls below are used to populate user_to_ratings_full_transform, user_to_ratings_full, and user_to_target_index_full (both train and full versions). \n",
    "    #user_to_ratings_full_transform is scaled with the movie_id_to_average_rating (both train and full versions).\n",
    "\n",
    "    pre_svd(movie_id_to_average_rating_train, train_users.movies_in_order, train_users.user_to_ratings_full_transform, train_users.user_to_ratings_full, \n",
    "            train_users.user_to_target_index_full, train_users.user_to_movie_id_to_rating, train_users.user_to_target_movie_id)\n",
    "\n",
    "    pre_svd(movie_id_to_average_rating_full, all_movies_in_order, full_user_to_ratings_full_transform, full_user_to_ratings_full, full_user_to_target_index_full, \n",
    "                full_user_to_movie_id_to_rating, full_user_to_target_movie_id)\n",
    "\n",
    "\n",
    "    #In practice, there is a train and a test set, the train set is a selection of what the database has on record.\n",
    "    #The test data will usually be data that hasn't been seen before that can include any number of test users.\n",
    "    #When train_users.user_to_ratings_full_transform is used as the input of the svd function below, \n",
    "    #svd_out_train is used to produce predictions used to train the model\n",
    "    #When full_user_to_ratings_full_transform is used as the input of the svd function below,\n",
    "    #svd_out_full is used to produce predictions used to test the model\n",
    "\n",
    "    #LOOK: this is not valid with the current model of making best preidctions with few sample ratings for test users and many ratings for train users\n",
    "    #n = 20 is close to the highest performing constant for 100 min ratings for train and test users\n",
    "    #n = 10 is close to the highest performing constant for 50-75 min rating per train users and 5-10 min ratings per test user\n",
    "\n",
    "    #Note: different values of n per function call below were tested with 50-75 min rating per train users and 5-10 min ratings per test user\n",
    "    #this did not lead to performance benefits, it was best that both values of n were 10 for perfrormance\n",
    "\n",
    "    svd_out_train = svd_full(train_users.user_to_ratings_full_transform, 10, movie_id_to_average_rating_train)\n",
    "    svd_out_full = svd_full(full_user_to_ratings_full_transform, 10, movie_id_to_average_rating_full)\n",
    "\n",
    "    #here the smaller svd provides predictions used to train the model\n",
    "    for i in range(len(train_users.user_to_ratings_full_transform)):\n",
    "        train_users.feature_3.append(svd_out_train[i][train_users.user_to_target_index_full[i]])\n",
    "\n",
    "    #here the larger svd provides predictions used to test the model\n",
    "    for i in range(len(full_user_to_ratings_full_transform) - len(train_users.user_to_ratings_full_transform)):\n",
    "        test_users.feature_3.append(svd_out_full[i+len(train_users.user_to_ratings_full_transform)][full_user_to_target_index_full[i+len(train_users.user_to_ratings_full_transform)]])\n",
    "\n",
    "#populate train and test data (feature 3)\n",
    "load_feature_3()\n",
    "\n",
    "\n",
    "#this is just used to show how the features approximate the target rating\n",
    "print(\"Feature_1 to target comparison (train):\")\n",
    "print(train_users.feature_1[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_1 to target comparison (test):\")\n",
    "print(test_users.feature_1[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_2 to target comparison (train):\")\n",
    "print(train_users.feature_2[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_2 to target comparison (test):\")\n",
    "print(test_users.feature_2[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_3 to target comparison (train):\")\n",
    "print(train_users.feature_3[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_3 to target comparison (test):\")\n",
    "print(test_users.feature_3[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "\n",
    "#just for code clarity\n",
    "del user_to_data_train\n",
    "del user_to_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance scores: First feature: 0.16567171779917836 Second feature: 0.34734592033255274\n",
      "Feature Importance scores: First feature: 0.16272612858249966 Second feature: 0.34744576280927475\n",
      "Feature Importance scores: First feature: 0.1670734590853333 Second feature: 0.3505821049021449\n",
      "Feature Importance scores: First feature: 0.1584754607560154 Second feature: 0.3492271977437901\n",
      "Feature Importance scores: First feature: 0.16147415865523915 Second feature: 0.3458062265243723\n",
      "Feature Importance scores: First feature: 0.15430377716859991 Second feature: 0.3404401245575671\n",
      "Feature Importance scores: First feature: 0.16317198305737013 Second feature: 0.35115765474541105\n",
      "Feature Importance scores: First feature: 0.16140724052007333 Second feature: 0.3425638703553283\n",
      "Feature Importance scores: First feature: 0.15911519702610422 Second feature: 0.35391137698447317\n",
      "Feature Importance scores: First feature: 0.158868970412046 Second feature: 0.3463169384605201\n",
      "Feature Importance scores: First feature: 0.15168114563415702 Second feature: 0.3433833163050435\n",
      "Feature Importance scores: First feature: 0.16074573277755488 Second feature: 0.3451637736350127\n",
      "Feature Importance scores: First feature: 0.15967365698384478 Second feature: 0.3472734234478098\n",
      "Feature Importance scores: First feature: 0.15995250309683462 Second feature: 0.3452644022770285\n",
      "Feature Importance scores: First feature: 0.16234379531779566 Second feature: 0.34335149411464544\n",
      "Feature Importance scores: First feature: 0.1608465147061124 Second feature: 0.3389044980149108\n",
      "Feature Importance scores: First feature: 0.1598772763317274 Second feature: 0.35538356521506703\n",
      "Feature Importance scores: First feature: 0.16284650796138553 Second feature: 0.35005889750729346\n",
      "Feature Importance scores: First feature: 0.15973335529911778 Second feature: 0.35381263403503865\n",
      "Feature Importance scores: First feature: 0.15609407759955402 Second feature: 0.33632657325493664\n",
      "Feature Importance scores: First feature: 0.16158156304831672 Second feature: 0.3561956812757627\n",
      "Feature Importance scores: First feature: 0.15649159933682405 Second feature: 0.343284103706715\n",
      "Feature Importance scores: First feature: 0.15654733094318254 Second feature: 0.357586011981173\n",
      "Feature Importance scores: First feature: 0.16017469993751174 Second feature: 0.34336920515249353\n",
      "Feature Importance scores: First feature: 0.1628076469568887 Second feature: 0.3414098852884039\n",
      "Feature Importance scores: First feature: 0.16037433045469907 Second feature: 0.3498823710557738\n",
      "Feature Importance scores: First feature: 0.1625921215031288 Second feature: 0.34147489672459425\n",
      "Feature Importance scores: First feature: 0.16043783777817971 Second feature: 0.34140157862355613\n",
      "Feature Importance scores: First feature: 0.16219290757807597 Second feature: 0.34564191937245836\n",
      "Feature Importance scores: First feature: 0.15466784899134373 Second feature: 0.3389513847459281\n",
      "Feature Importance scores: First feature: 0.16257882714700975 Second feature: 0.34916969849907054\n",
      "Feature Importance scores: First feature: 0.15943313138059553 Second feature: 0.3374682805875734\n",
      "Feature Importance scores: First feature: 0.15753905238109991 Second feature: 0.344581223592155\n",
      "Feature Importance scores: First feature: 0.16184804315048382 Second feature: 0.3528080300862765\n",
      "Feature Importance scores: First feature: 0.16243442532687585 Second feature: 0.3485627641292129\n",
      "Feature Importance scores: First feature: 0.16027647019300206 Second feature: 0.3409552899410873\n",
      "Feature Importance scores: First feature: 0.15624259996472106 Second feature: 0.3498334971542357\n",
      "Feature Importance scores: First feature: 0.1628927263555457 Second feature: 0.34239812327417996\n",
      "Feature Importance scores: First feature: 0.1551934147808276 Second feature: 0.3479936060350072\n",
      "Feature Importance scores: First feature: 0.1641629333685613 Second feature: 0.34360193689106616\n",
      "Feature Importance scores: First feature: 0.15582471469016035 Second feature: 0.3460861758011876\n",
      "Feature Importance scores: First feature: 0.16265559606591576 Second feature: 0.35155602339458314\n",
      "Feature Importance scores: First feature: 0.16043032630361634 Second feature: 0.3498599658537231\n",
      "Feature Importance scores: First feature: 0.16298899545794332 Second feature: 0.358129239211109\n",
      "Feature Importance scores: First feature: 0.1546432349081952 Second feature: 0.3502332727730125\n",
      "Feature Importance scores: First feature: 0.1553190279584092 Second feature: 0.3380614569161196\n",
      "Feature Importance scores: First feature: 0.15992950195361152 Second feature: 0.3483405352736416\n",
      "Feature Importance scores: First feature: 0.16253939274559628 Second feature: 0.3524695312570216\n",
      "Feature Importance scores: First feature: 0.15598456031608912 Second feature: 0.34846222555377715\n",
      "Feature Importance scores: First feature: 0.1543959314052969 Second feature: 0.3452320904358262\n",
      "Feature Importance scores: First feature: 0.15857663865869465 Second feature: 0.3453240484581878\n",
      "Feature Importance scores: First feature: 0.16234636803077623 Second feature: 0.34313155224526837\n",
      "Feature Importance scores: First feature: 0.15727328100296756 Second feature: 0.34740655131342185\n",
      "Feature Importance scores: First feature: 0.16151469807840105 Second feature: 0.3521837024454263\n",
      "Feature Importance scores: First feature: 0.1562560052088991 Second feature: 0.35425589015633735\n",
      "Feature Importance scores: First feature: 0.15700427288624294 Second feature: 0.34258521177962853\n",
      "Feature Importance scores: First feature: 0.15661420975304385 Second feature: 0.34521861845855345\n",
      "Feature Importance scores: First feature: 0.16304973222866576 Second feature: 0.334329664595275\n",
      "Feature Importance scores: First feature: 0.162767200109498 Second feature: 0.3549177562137675\n",
      "Feature Importance scores: First feature: 0.15716199011092785 Second feature: 0.331940932062914\n",
      "Feature Importance scores: First feature: 0.15502192961390843 Second feature: 0.3528177856695908\n",
      "Feature Importance scores: First feature: 0.1558896645401607 Second feature: 0.3497674317732889\n",
      "Feature Importance scores: First feature: 0.15671202262679107 Second feature: 0.3470295595856428\n",
      "Feature Importance scores: First feature: 0.15715773694201485 Second feature: 0.34274351921287277\n",
      "Feature Importance scores: First feature: 0.16178045762670992 Second feature: 0.34171916075285036\n",
      "Feature Importance scores: First feature: 0.15314152563682618 Second feature: 0.34647966258830887\n",
      "Feature Importance scores: First feature: 0.15516205731108074 Second feature: 0.3524714906142393\n",
      "Feature Importance scores: First feature: 0.1618924461862511 Second feature: 0.3421692498085091\n",
      "Feature Importance scores: First feature: 0.165280830899781 Second feature: 0.3493134957087384\n",
      "Feature Importance scores: First feature: 0.1619080785697215 Second feature: 0.34237938150290326\n",
      "Feature Importance scores: First feature: 0.16235332948943385 Second feature: 0.34172445392631157\n",
      "Feature Importance scores: First feature: 0.1558560200557315 Second feature: 0.3406806994737045\n",
      "Feature Importance scores: First feature: 0.16023611240584684 Second feature: 0.3377104543413808\n",
      "Feature Importance scores: First feature: 0.15999938864092983 Second feature: 0.35436232983837135\n",
      "Feature Importance scores: First feature: 0.15918489770101127 Second feature: 0.3449892781527608\n",
      "Feature Importance scores: First feature: 0.16489445268991917 Second feature: 0.3504268884737119\n",
      "Feature Importance scores: First feature: 0.15838916145968993 Second feature: 0.3353658614321656\n",
      "Feature Importance scores: First feature: 0.16420242244034458 Second feature: 0.35046765867446383\n",
      "Feature Importance scores: First feature: 0.15556662667924703 Second feature: 0.3465574207029174\n",
      "Feature Importance scores: First feature: 0.15373840324892857 Second feature: 0.34086665475941524\n",
      "Feature Importance scores: First feature: 0.15519351403265888 Second feature: 0.3540449152254571\n",
      "Feature Importance scores: First feature: 0.15711504212435623 Second feature: 0.34182850701668155\n",
      "Feature Importance scores: First feature: 0.15677982187611 Second feature: 0.3474263752243224\n",
      "Feature Importance scores: First feature: 0.16897907546409158 Second feature: 0.34821590127904095\n",
      "Feature Importance scores: First feature: 0.15767441382680186 Second feature: 0.35054466464855955\n",
      "Feature Importance scores: First feature: 0.15789459327161162 Second feature: 0.34921386244362906\n",
      "Feature Importance scores: First feature: 0.1617351289360886 Second feature: 0.34963439576208943\n",
      "Feature Importance scores: First feature: 0.15305214013119753 Second feature: 0.33366097514224263\n",
      "Feature Importance scores: First feature: 0.16021742647486192 Second feature: 0.33911758863921937\n",
      "Feature Importance scores: First feature: 0.1514236387036555 Second feature: 0.3436162204147636\n",
      "Feature Importance scores: First feature: 0.15538979732129438 Second feature: 0.3415435618652918\n",
      "Feature Importance scores: First feature: 0.15640216446436872 Second feature: 0.34994555213137174\n",
      "Feature Importance scores: First feature: 0.15630765645486785 Second feature: 0.34610139445582744\n",
      "Feature Importance scores: First feature: 0.15727832493026225 Second feature: 0.3417544946275005\n",
      "Feature Importance scores: First feature: 0.15585223833706058 Second feature: 0.34299103958125027\n",
      "Feature Importance scores: First feature: 0.16153487416042206 Second feature: 0.34409752610484856\n",
      "Feature Importance scores: First feature: 0.1550805288072292 Second feature: 0.34366797061058985\n",
      "Feature Importance scores: First feature: 0.15918472679434184 Second feature: 0.34665825994037214\n",
      "Feature Importance scores: First feature: 0.16063116163764785 Second feature: 0.3461386086707615\n",
      "Feature Importance scores: First feature: 0.16114164170702927 Second feature: 0.3460525927297563\n",
      "Average r2_score without rounding: 0.25426664596078186\n",
      "Average r2_score with rounded prediction to nearest .5 (note: the actual ratings a user makes must be divisable by .5): 0.22858769671550502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#the mlp model is not currently being used\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#feature scaling is not necessary because linear regression converges fast enough\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score\n",
    "#the alternative evaluation metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def test_parameters(nof_runs, layers, train_input_features, test_input_features):\n",
    "    \"\"\"Test_parameters for a number of runs and return performance results\"\"\"\n",
    "    train_inputs = [list(pair) for pair in train_input_features]\n",
    "    test_inputs = [list(pair) for pair in test_input_features]\n",
    "    return average_results(nof_runs, layers, train_inputs, test_inputs)\n",
    "    \n",
    "\n",
    "def average_results(nof_runs, layers, train_inputs, text_inputs):\n",
    "    \"\"\"Average the performance results for a number of models with identical inputs\"\"\"\n",
    "    no_rounding = 0\n",
    "    rounding = 0\n",
    "    for _ in range(nof_runs):\n",
    "        pair = train_and_test(layers, train_inputs, text_inputs)\n",
    "        no_rounding+=pair[0]\n",
    "        rounding+=pair[1]\n",
    "    return float(no_rounding/nof_runs), float(rounding/nof_runs)\n",
    "\n",
    "\n",
    "def train_and_test(layers, train_inputs, test_inputs):\n",
    "    \"\"\"Build, train, and test a model, then return accuracy scores\"\"\"\n",
    "\n",
    "    # nn model (worse performance):\n",
    "    # reg = MLPRegressor(hidden_layer_sizes = layers, solver = \"adam\",  max_iter = 1000)\n",
    "\n",
    "    # linear regression (better performance):\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    #train model\n",
    "    reg.fit(train_inputs, train_users.user_to_target_rating)\n",
    "\n",
    "    #print importance of the different input features to the model\n",
    "    results = permutation_importance(reg, train_inputs, train_users.user_to_target_rating)\n",
    "    importances = results[\"importances_mean\"]\n",
    "    print(\"Feature Importance scores:\", \"First feature:\", importances[0],\"Second feature:\", importances[1])\n",
    "\n",
    "    #make predictions for test inputs\n",
    "    predictions = reg.predict(test_inputs)\n",
    "\n",
    "    #test with and without roundings...\n",
    "    #note: the actual ratings a user makes must be divisable by .5 \n",
    "    rounded_predictions = []\n",
    "    for item in predictions:\n",
    "        rounded_predictions.append(float(round(item*2)/2.0))\n",
    "\n",
    "    #evaluation metric 1:\n",
    "    return(r2_score(test_users.user_to_target_rating, predictions), \n",
    "        r2_score(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "    #evaluation metric 2:\n",
    "    # return(mean_squared_error(test_users.user_to_target_rating, predictions), \n",
    "    #         mean_squared_error(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "\n",
    "\n",
    "# the current test is the average accuracy scores (currently r2_score) for 100 models trained on the same inputs\n",
    "# the hidden layers are (10,10,10) but the linear model is the current model being used which does not user layers\n",
    "# and the highest scoring inputs features (feature_1 and feature_3) are used here\n",
    "\n",
    "avg_scores = test_parameters(100, (10,10,10), \n",
    "    zip(train_users.feature_1, train_users.feature_3),\n",
    "      zip(test_users.feature_1, test_users.feature_3))\n",
    "\n",
    "\n",
    "print(\"Average r2_score without rounding:\",avg_scores[0])\n",
    "print(\"Average r2_score with rounded prediction to nearest .5 (note: the actual ratings a user makes must be divisable by .5):\",avg_scores[1])\n",
    "\n",
    "\n",
    "\n",
    "# misc... \n",
    "# results:\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 20 for svd_full\n",
    "# Average r2_score without rounding:  \n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  \n",
    "\n",
    "# BEST:\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 10 for svd_full\n",
    "# Average r2_score without rounding:  0.15453027266541675\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.13160695282014914\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 5 for svd_full\n",
    "# Average r2_score without rounding:  0.1531792173890736\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.13107484923731846\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 15 for svd_full\n",
    "# Average r2_score without rounding:  0.14856750114822856\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.13160695282014914\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = (20,10) for svd_full\n",
    "# Average r2_score without rounding:  0.14704697205805803\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.12415750266051795\n",
    "#Note: two different n values leads to worse results...\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = (15,10) for svd_full\n",
    "# Average r2_score without rounding:  0.1497370871224573\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.12841433132316396\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
