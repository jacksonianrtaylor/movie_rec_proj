{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\the-movies-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "#this cell downloads the data needed for this jupyter notebook from kaggle and stores in the-movies-dataset folder in the current directory\n",
    "#if the files are already in that folder than this cell does nothing and requires no credentials\n",
    "\n",
    "#Data Soruce Information:\n",
    "#https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?select=movies_metadata.csv\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId    id rating               title  \\\n",
      "6566765      1  1246    5.0        Rocky Balboa   \n",
      "6880303      1  2959    4.0      License to Wed   \n",
      "2083077      1  2762    4.5  Young and Innocent   \n",
      "1492304      1  1968    4.0       Fools Rush In   \n",
      "2638962      1   147    4.5       The 400 Blows   \n",
      "\n",
      "                                                                                                genres  \\\n",
      "6566765                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "6880303                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "2083077                                     [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name': 'Crime'}]   \n",
      "1492304  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "2638962                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                production_companies  \\\n",
      "6566765                                                                                                  [{'name': 'Columbia Pictures', 'id': 5}, {'name': 'Revolution Studios', 'id': 497}, {'name': 'Rogue Marble', 'id': 696}, {'name': 'Metro-Goldwyn-Mayer (MGM)', 'id': 8411}]   \n",
      "6880303  [{'name': 'Village Roadshow Pictures', 'id': 79}, {'name': 'Robert Simonds Productions', 'id': 3929}, {'name': 'Warner Bros.', 'id': 6194}, {'name': 'Phoenix Pictures', 'id': 11317}, {'name': 'Underground', 'id': 49326}, {'name': 'Proposal Productions', 'id': 49327}]   \n",
      "2083077                                                                                                                                                                                                                [{'name': 'Gaumont British Picture Corporation', 'id': 4978}]   \n",
      "1492304                                                                                                                                                                                                                                     [{'name': 'Columbia Pictures', 'id': 5}]   \n",
      "2638962                                                                                                                                 [{'name': 'Les Films du Carrosse', 'id': 53}, {'name': 'Sédif Productions', 'id': 10897}, {'name': 'The Criterion Collection', 'id': 10932}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
      "6566765  [{'id': 276, 'name': 'philadelphia'}, {'id': 396, 'name': 'transporter'}, {'id': 1721, 'name': 'fight'}, {'id': 2038, 'name': \"love of one's life\"}, {'id': 2416, 'name': 'publicity'}, {'id': 2792, 'name': 'boxer'}, {'id': 2968, 'name': 'grave'}, {'id': 3393, 'name': 'tombstone'}, {'id': 3586, 'name': 'tv station'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5167, 'name': 'restaurant owner'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5380, 'name': 'virtual fight'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 10163, 'name': 'cancer'}, {'id': 155464, 'name': 'over-the-hill fighter'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                             [{'id': 1605, 'name': 'new love'}, {'id': 2856, 'name': 'ten commandments'}, {'id': 3582, 'name': 'bride'}, {'id': 3583, 'name': 'bridegroom'}, {'id': 6038, 'name': 'marriage'}, {'id': 6192, 'name': 'relation'}, {'id': 6281, 'name': 'partnership'}, {'id': 6704, 'name': 'civil registry office'}, {'id': 10093, 'name': 'priest'}, {'id': 13027, 'name': 'wedding'}, {'id': 14765, 'name': 'church'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'id': 769, 'name': 'falsely accused'}, {'id': 1655, 'name': 'country house'}, {'id': 9826, 'name': 'murder'}, {'id': 9937, 'name': 'suspense'}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'id': 828, 'name': 'waitress'}, {'id': 1463, 'name': 'culture clash'}, {'id': 9799, 'name': 'romantic comedy'}, {'id': 13149, 'name': 'pregnancy'}]   \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                      [{'id': 6930, 'name': 'fondling'}, {'id': 10183, 'name': 'independent film'}, {'id': 155518, 'name': 'nouvelle vague'}, {'id': 170268, 'name': 'skipping school'}, {'id': 170272, 'name': 'mise en scene'}, {'id': 170273, 'name': 'fingerprinting'}, {'id': 170279, 'name': '\\xa0mugshot'}, {'id': 170286, 'name': 'strict teacher'}, {'id': 170293, 'name': 'montmartre paris'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        cast  \\\n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'cast_id': 24, 'character': 'Rocky Balboa', 'credit_id': '52fe42e9c3a36847f802c61b', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 25, 'character': 'Paulie', 'credit_id': '52fe42e9c3a36847f802c61f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 1, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 26, 'character': 'Rocky Jr.', 'credit_id': '52fe42e9c3a36847f802c623', 'gender': 2, 'id': 16501, 'name': 'Milo Ventimiglia', 'order': 2, 'profile_path': '/maJeS6bA6ku21rSRceISQtwHL2h.jpg'}, {'cast_id': 27, 'character': 'Marie', 'credit_id': '52fe42e9c3a36847f802c627', 'gender': 1, 'id': 16502, 'name': 'Geraldine Hughes', 'order': 3, 'profile_path': '/bTXux3EJq25Fh2ixbet6MjdG3Fb.jpg'}, {'cast_id': 28, 'character': 'Steps', 'credit_id': '52fe42e9c3a36847f802c62b', 'gender': 2, 'id': 16503, 'name': 'James Francis Kelly III', 'order': 4, 'profile_path': '/iZyTQ2UlwNXrqLqPeNHbofFXubP.jpg'}, {'cast_id': 29, 'character': 'Duke', 'credit_id': '52fe42e9c3a36847f802c62f', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 30, 'character': 'L.C.', 'credit_id': '52fe42e9c3a36847f802c633', 'gender': 2, 'id': 16505, 'name': 'A. J. Benza', 'order': 6, 'profile_path': '/5hVinC6C1ZyD7c8EmZFTiEaF7vH.jpg'}, {'cast_id': 31, 'character': 'Adrian', 'credit_id': '52fe42e9c3a36847f802c637', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 7, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 32, 'character': 'Martin', 'credit_id': '52fe42e9c3a36847f802c63b', 'gender': 2, 'id': 16506, 'name': 'Henry G. Sanders', 'order': 8, 'profile_path': '/2SU75g2CAIzGWbgfIlNvKZQhYTZ.jpg'}, {'cast_id': 33, 'character': \"Mason 'The Line' Dixon\", 'credit_id': '52fe42e9c3a36847f802c63f', 'gender': 2, 'id': 16507, 'name': 'Antonio Tarver', 'order': 9, 'profile_path': '/kJEljjHwBvrjoxqcSVntXlejgl1.jpg'}, {'cast_id': 34, 'character': 'Spider Rico', 'credit_id': '52fe42e9c3a36847f802c643', 'gender': 2, 'id': 16508, 'name': 'Pedro Lovell', 'order': 10, 'profile_path': None}, {'cast_id': 35, 'character': 'Isabel', 'credit_id': '52fe42e9c3a36847f802c647', 'gender': 1, 'id': 16509, 'name': 'Ana Gerena', 'order': 11, 'profile_path': None}, {'cast_id': 36, 'character': 'Angie', 'credit_id': '52fe42e9c3a36847f802c64b', 'gender': 1, 'id': 16510, 'name': 'Angela Boyd', 'order': 12, 'profile_path': None}, {'cast_id': 37, 'character': 'Bar Thug', 'credit_id': '52fe42e9c3a36847f802c64f', 'gender': 0, 'id': 16511, 'name': 'Louis Giansante', 'order': 13, 'profile_path': None}, {'cast_id': 38, 'character': \"Lucky's Bartender\", 'credit_id': '52fe42e9c3a36847f802c653', 'gender': 0, 'id': 16512, 'name': 'Maureen Schilling', 'order': 14, 'profile_path': None}, {'cast_id': 40, 'character': 'X-Cell', 'credit_id': '5761db05c3a3682f20000302', 'gender': 2, 'id': 98298, 'name': 'Lahmard J. Tate', 'order': 15, 'profile_path': '/4WcFReePSxyGQJWV5wXGNfY0Y7o.jpg'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'cast_id': 18, 'character': 'Reverend Frank', 'credit_id': '52fe4376c3a36847f8056039', 'gender': 2, 'id': 2157, 'name': 'Robin Williams', 'order': 0, 'profile_path': '/sojtJyIV3lkUeThD7A2oHNm8183.jpg'}, {'cast_id': 19, 'character': 'Sadie Jones', 'credit_id': '52fe4376c3a36847f805603d', 'gender': 1, 'id': 16855, 'name': 'Mandy Moore', 'order': 1, 'profile_path': '/15sDtRpe301tZWrRYV31wjMuFpx.jpg'}, {'cast_id': 20, 'character': 'Ben Murphy', 'credit_id': '52fe4376c3a36847f8056041', 'gender': 2, 'id': 17697, 'name': 'John Krasinski', 'order': 2, 'profile_path': '/nOWwdZURikW22qo6OUSGFCTukgc.jpg'}, {'cast_id': 21, 'character': 'Carlisle', 'credit_id': '52fe4376c3a36847f8056045', 'gender': 2, 'id': 29020, 'name': 'Eric Christian Olsen', 'order': 3, 'profile_path': '/clbouet8o9IJlUd8WILD0lzHAtG.jpg'}, {'cast_id': 22, 'character': 'Lindsey Jones', 'credit_id': '52fe4376c3a36847f8056049', 'gender': 1, 'id': 15286, 'name': 'Christine Taylor', 'order': 4, 'profile_path': '/99OssnGmgGjduXFA7syxjNqt9tQ.jpg'}, {'cast_id': 23, 'character': 'Choir Boy', 'credit_id': '52fe4376c3a36847f805604d', 'gender': 2, 'id': 216, 'name': 'Josh Flitter', 'order': 5, 'profile_path': '/6RCA8tDWBxIVk9N3IqUjJEAzYGv.jpg'}, {'cast_id': 24, 'character': 'Joel', 'credit_id': '52fe4376c3a36847f8056051', 'gender': 2, 'id': 11827, 'name': 'DeRay Davis', 'order': 6, 'profile_path': '/w2JYPRLwXhNCpxpJc2v4UQYyMv8.jpg'}, {'cast_id': 25, 'character': 'Mr. Jones', 'credit_id': '52fe4376c3a36847f8056055', 'gender': 2, 'id': 21368, 'name': 'Peter Strauss', 'order': 7, 'profile_path': '/ufx1trct43k7UcT4DpoIMPZXi5A.jpg'}, {'cast_id': 26, 'character': 'Grandma Jones', 'credit_id': '52fe4376c3a36847f8056059', 'gender': 1, 'id': 6465, 'name': 'Grace Zabriskie', 'order': 8, 'profile_path': '/ibBabuSM1UyPYFFo0wBXhGbqElk.jpg'}, {'cast_id': 27, 'character': 'Mrs. Jones', 'credit_id': '52fe4376c3a36847f805605d', 'gender': 1, 'id': 29021, 'name': 'Roxanne Hart', 'order': 9, 'profile_path': '/yWGMW6HdhUGT2oIcQ4jmnkw7ZAM.jpg'}, {'cast_id': 28, 'character': 'Shelly', 'credit_id': '5586ee469251417f6f0059c8', 'gender': 1, 'id': 125167, 'name': 'Mindy Kaling', 'order': 10, 'profile_path': '/Agpd4tJyZ95hk74RifjnfnJpn9U.jpg'}, {'cast_id': 30, 'character': 'Expectant Father', 'credit_id': '56c3467cc3a36847c5001f66', 'gender': 2, 'id': 1368801, 'name': 'David Quinlan', 'order': 11, 'profile_path': '/2m75rrBhvOTtdUS9jlKW8GOHCBV.jpg'}, {'cast_id': 31, 'character': 'Judith', 'credit_id': '58e26093c3a36872f600dcf2', 'gender': 1, 'id': 113867, 'name': 'Angela Kinsey', 'order': 12, 'profile_path': '/omLdRLdwMLliVeVIualEnWVhm1a.jpg'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'cast_id': 18, 'character': 'Erica Burgoyne', 'credit_id': '52fe436bc3a36847f8052cd5', 'gender': 1, 'id': 27939, 'name': 'Nova Pilbeam', 'order': 0, 'profile_path': '/l6oHJaRYrVxsvoTSmMS5wIXaei5.jpg'}, {'cast_id': 19, 'character': 'Robert Tisdall', 'credit_id': '52fe436bc3a36847f8052cd9', 'gender': 0, 'id': 27940, 'name': 'Derrick De Marney', 'order': 1, 'profile_path': '/7VRZ7K0EZ50haOlbVr7DHZ5550O.jpg'}, {'cast_id': 20, 'character': 'Col. Burgoyne', 'credit_id': '52fe436bc3a36847f8052cdd', 'gender': 2, 'id': 27929, 'name': 'Percy Marmont', 'order': 2, 'profile_path': '/p3DIyvlxx6B0SVIxcDaPUPlEV0U.jpg'}, {'cast_id': 21, 'character': 'Old Will', 'credit_id': '52fe436bc3a36847f8052ce1', 'gender': 2, 'id': 27941, 'name': 'Edward Rigby', 'order': 3, 'profile_path': '/B7GJ0jPtODqZVgVtZHPtvZl2tO.jpg'}, {'cast_id': 22, 'character': 'Ericas Tante Margaret', 'credit_id': '52fe436bc3a36847f8052ce5', 'gender': 1, 'id': 14304, 'name': 'Mary Clare', 'order': 4, 'profile_path': '/lAdEwCGiSUj9CCMPB4L9X4oujLe.jpg'}, {'cast_id': 23, 'character': 'Det. Insp. Kent', 'credit_id': '52fe436bc3a36847f8052ce9', 'gender': 2, 'id': 7383, 'name': 'John Longden', 'order': 5, 'profile_path': '/rsCoUEx2ThNIz12fBR6vPncCICk.jpg'}, {'cast_id': 24, 'character': 'Guy', 'credit_id': '52fe436bc3a36847f8052ced', 'gender': 2, 'id': 27942, 'name': 'George Curzon', 'order': 6, 'profile_path': None}, {'cast_id': 25, 'character': 'Ericas Onkel Basil', 'credit_id': '52fe436bc3a36847f8052cf1', 'gender': 2, 'id': 14303, 'name': 'Basil Radford', 'order': 7, 'profile_path': '/9STo7Tgdutplo78ZtyeINGWkXUk.jpg'}, {'cast_id': 26, 'character': 'Christine Clay', 'credit_id': '52fe436bc3a36847f8052cf5', 'gender': 1, 'id': 27943, 'name': 'Pamela Carme', 'order': 8, 'profile_path': None}, {'cast_id': 27, 'character': 'Detective Sergeant Miller', 'credit_id': '52fe436bc3a36847f8052cf9', 'gender': 2, 'id': 27944, 'name': 'George Merritt', 'order': 9, 'profile_path': None}, {'cast_id': 28, 'character': 'Henry Briggs', 'credit_id': '52fe436bc3a36847f8052cfd', 'gender': 2, 'id': 27945, 'name': 'J.H. Roberts', 'order': 10, 'profile_path': None}, {'cast_id': 29, 'character': \"Truckfahrer bei Tom's Hat\", 'credit_id': '52fe436bc3a36847f8052d01', 'gender': 2, 'id': 27946, 'name': 'Jerry Verno', 'order': 11, 'profile_path': None}, {'cast_id': 30, 'character': 'Police Sergeant Ruddock', 'credit_id': '52fe436bc3a36847f8052d05', 'gender': 2, 'id': 27947, 'name': 'H.F. Maltby', 'order': 12, 'profile_path': None}, {'cast_id': 31, 'character': 'Police Constable', 'credit_id': '52fe436bc3a36847f8052d09', 'gender': 2, 'id': 27948, 'name': 'John Miller', 'order': 13, 'profile_path': None}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'cast_id': 2, 'character': 'Alex Whitman', 'credit_id': '52fe4327c3a36847f803e629', 'gender': 2, 'id': 14408, 'name': 'Matthew Perry', 'order': 0, 'profile_path': '/oSKEEDXDNnwWdQ68qfDVD6Q7Pxp.jpg'}, {'cast_id': 3, 'character': 'Isabel Fuentes', 'credit_id': '52fe4327c3a36847f803e62d', 'gender': 1, 'id': 3136, 'name': 'Salma Hayek', 'order': 1, 'profile_path': '/u5mg73xKVqm8oT93HoMmsgQHyoK.jpg'}, {'cast_id': 4, 'character': 'Jeff', 'credit_id': '52fe4327c3a36847f803e631', 'gender': 2, 'id': 4602, 'name': 'Jon Tenney', 'order': 2, 'profile_path': '/fiG1bW6DX1szsRDPIYjfIKPQ0kV.jpg'}, {'cast_id': 5, 'character': 'Lanie', 'credit_id': '52fe4327c3a36847f803e635', 'gender': 1, 'id': 6751, 'name': 'Siobhan Fallon', 'order': 3, 'profile_path': '/wVFa8GiY0xdOLFsvGygy9RMtcBc.jpg'}, {'cast_id': 16, 'character': 'Great Grandma', 'credit_id': '52fe4327c3a36847f803e675', 'gender': 1, 'id': 20360, 'name': 'Angelina Torres', 'order': 4, 'profile_path': None}, {'cast_id': 17, 'character': 'Richard Whitman', 'credit_id': '52fe4327c3a36847f803e679', 'gender': 2, 'id': 20361, 'name': 'John Bennett Perry', 'order': 5, 'profile_path': '/bzFhwuXsdZiOHRtBgz4XVELIFYO.jpg'}, {'cast_id': 18, 'character': 'Nan Whitman', 'credit_id': '52fe4327c3a36847f803e67d', 'gender': 1, 'id': 20362, 'name': 'Jill Clayburgh', 'order': 6, 'profile_path': '/twrfhIvbqHuJ7nXVpehvU6nyi6R.jpg'}, {'cast_id': 19, 'character': 'Cathy Stewart', 'credit_id': '52fe4327c3a36847f803e681', 'gender': 1, 'id': 20363, 'name': 'Suzanne Snyder', 'order': 7, 'profile_path': '/90FrTcjJudpeIYUjUzlO6XAmvnt.jpg'}, {'cast_id': 20, 'character': 'Amalia', 'credit_id': '52fe4327c3a36847f803e685', 'gender': 0, 'id': 13029, 'name': 'Anne Betancourt', 'order': 8, 'profile_path': '/6UU5P4DzjJTSBFztIu1nALT2tk0.jpg'}, {'cast_id': 21, 'character': 'Juan Fuentes', 'credit_id': '52fe4327c3a36847f803e689', 'gender': 2, 'id': 4511, 'name': 'Mark Adair-Rios', 'order': 9, 'profile_path': '/rX4d1e5jlF5P73qynjjUzJslB0c.jpg'}, {'cast_id': 22, 'character': 'Judd Marshall', 'credit_id': '52fe4327c3a36847f803e68d', 'gender': 2, 'id': 4171, 'name': 'Stanley DeSantis', 'order': 10, 'profile_path': '/4cHxkhTd7oklyNkdva9WJp0FLrX.jpg'}, {'cast_id': 23, 'character': 'Antonio Fuentes', 'credit_id': '52fe4327c3a36847f803e691', 'gender': 0, 'id': 4665, 'name': 'Josh Cruze', 'order': 11, 'profile_path': '/v3QrQzH0uGV9pd1dNR5Ue6a74qO.jpg'}, {'cast_id': 24, 'character': 'Petra', 'credit_id': '52fe4327c3a36847f803e695', 'gender': 0, 'id': 4666, 'name': 'Angela Lanza', 'order': 12, 'profile_path': '/zmf6TMWMVCdnuUfpgdnioaICk1L.jpg'}, {'cast_id': 25, 'character': 'Phil', 'credit_id': '52fe4327c3a36847f803e699', 'gender': 2, 'id': 4445, 'name': 'Chris Bauer', 'order': 13, 'profile_path': '/3KYVMaGkWTEDQ0T9lsu85pVbP4T.jpg'}, {'cast_id': 26, 'character': 'Chuy', 'credit_id': '577e438f925141440c000d63', 'gender': 0, 'id': 115874, 'name': 'Carlos Gómez', 'order': 14, 'profile_path': '/nBxwoMv1zrhNXyEjYXbcdmAdmF0.jpg'}]   \n",
      "2638962  [{'cast_id': 6, 'character': 'Antoine Doinel', 'credit_id': '52fe421ec3a36847f8005661', 'gender': 2, 'id': 1653, 'name': 'Jean-Pierre Léaud', 'order': 0, 'profile_path': '/dzkPODapVe4CSubEqI9ytTCqnZ7.jpg'}, {'cast_id': 7, 'character': 'Gilberte Doinel', 'credit_id': '52fe421ec3a36847f8005665', 'gender': 1, 'id': 1654, 'name': 'Claire Maurier', 'order': 1, 'profile_path': '/cP1n7zMsMKr77xJeR3CncomxEZ0.jpg'}, {'cast_id': 8, 'character': 'Julien Doinel', 'credit_id': '52fe421ec3a36847f8005669', 'gender': 0, 'id': 1655, 'name': 'Albert Rémy', 'order': 2, 'profile_path': '/6b8eyIXAV6oA5eX6ltc3hF7ZB3d.jpg'}, {'cast_id': 10, 'character': 'Mr. Bigey', 'credit_id': '52fe421ec3a36847f8005673', 'gender': 2, 'id': 1658, 'name': 'Georges Flamant', 'order': 3, 'profile_path': '/lQwmtPsFWME63x5M7IRF6g8bLrR.jpg'}, {'cast_id': 11, 'character': 'René', 'credit_id': '52fe421ec3a36847f8005677', 'gender': 0, 'id': 1659, 'name': 'Patrick Auffay', 'order': 4, 'profile_path': None}, {'cast_id': 12, 'character': 'Director of the school', 'credit_id': '52fe421ec3a36847f800567b', 'gender': 0, 'id': 1660, 'name': 'Robert Beauvais', 'order': 5, 'profile_path': None}, {'cast_id': 13, 'character': 'Mme Bigey', 'credit_id': '52fe421ec3a36847f800567f', 'gender': 0, 'id': 1661, 'name': 'Yvonne Claudie', 'order': 6, 'profile_path': None}, {'cast_id': 14, 'character': 'English Teacher', 'credit_id': '52fe421ec3a36847f8005683', 'gender': 0, 'id': 1662, 'name': 'Pierre Repp', 'order': 7, 'profile_path': '/1AUhiNGBAR0C6AU9iK1IXBs3QTz.jpg'}, {'cast_id': 17, 'character': 'French Teacher', 'credit_id': '52fe421ec3a36847f8005693', 'gender': 0, 'id': 1656, 'name': 'Guy Decomble', 'order': 8, 'profile_path': '/34iexAuqI1asyFounbSXSCFphen.jpg'}, {'cast_id': 20, 'character': 'Betrand Mauricet', 'credit_id': '52fe421ec3a36847f8005697', 'gender': 0, 'id': 1077237, 'name': 'Daniel Couturier', 'order': 9, 'profile_path': None}, {'cast_id': 21, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569b', 'gender': 0, 'id': 1077238, 'name': 'François Nocher', 'order': 10, 'profile_path': None}, {'cast_id': 22, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569f', 'gender': 2, 'id': 150939, 'name': 'Richard Kanayan', 'order': 11, 'profile_path': '/vCMDk3ifj2vJKZYCISXT3K6DYXF.jpg'}, {'cast_id': 23, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a3', 'gender': 0, 'id': 1077239, 'name': 'Renaud Fontanarosa', 'order': 12, 'profile_path': None}, {'cast_id': 24, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a7', 'gender': 0, 'id': 1077240, 'name': 'Michel Girard', 'order': 13, 'profile_path': None}, {'cast_id': 25, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056ab', 'gender': 0, 'id': 71997, 'name': 'Serge Moati', 'order': 14, 'profile_path': '/wccRQKHrX61sH4WlOtM1KBP4qaq.jpg'}, {'cast_id': 26, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056af', 'gender': 0, 'id': 1077241, 'name': 'Bernard Abbou', 'order': 15, 'profile_path': None}, {'cast_id': 27, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b3', 'gender': 0, 'id': 1077242, 'name': 'Jean-François Bergouignan', 'order': 16, 'profile_path': None}, {'cast_id': 28, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b7', 'gender': 0, 'id': 1077243, 'name': 'Michel Lesignor', 'order': 17, 'profile_path': None}, {'cast_id': 31, 'character': 'Man in Street', 'credit_id': '5457f0a1c3a3683993000156', 'gender': 2, 'id': 24299, 'name': 'Jean-Claude Brialy', 'order': 18, 'profile_path': '/g3kkYcAvq90tALMErxmdAIcIXsE.jpg'}, {'cast_id': 32, 'character': 'Woman with Dog', 'credit_id': '5457f0bec3a36839a0000144', 'gender': 1, 'id': 14812, 'name': 'Jeanne Moreau', 'order': 19, 'profile_path': '/uHJnVwCzehEoz0mIlwN7xkymql8.jpg'}, {'cast_id': 33, 'character': 'Man in Funfair', 'credit_id': '5457f0d3c3a368399300015b', 'gender': 2, 'id': 34613, 'name': 'Philippe de Broca', 'order': 20, 'profile_path': '/yrvmXE2SJBX659r2Y7eWwlmwfYd.jpg'}, {'cast_id': 34, 'character': 'Man in Funfair', 'credit_id': '5457f0e5c3a368399d00014c', 'gender': 0, 'id': 1650, 'name': 'François Truffaut', 'order': 21, 'profile_path': '/apCCV99N3FqB5NsEPqOzetlkprL.jpg'}]   \n",
      "\n",
      "                                                                               tagline  \\\n",
      "6566765                                                  It ain't over 'til it's over.   \n",
      "6880303                                   First came love... then came Reverend Frank.   \n",
      "2083077                                                          A Brilliant Melodrama   \n",
      "1492304  What if finding the love of your life meant changing the life that you loved?   \n",
      "2638962                                            Angel faces hell-bent for violence.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        overview  \n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When he loses a highly publicized virtual boxing match to ex-champ Rocky Balboa, reigning heavyweight titleholder, Mason Dixon retaliates by challenging Rocky to a nationally televised, 10-round exhibition bout. To the surprise of his son and friends, Rocky agrees to come out of retirement and face an opponent who's faster, stronger and thirty years his junior.  \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Newly engaged, Ben and Sadie can't wait to start their life together and live happily ever after. However Sadie's family church's Reverend Frank won't bless their union until they pass his patented, \"foolproof\" marriage prep course consisting of outrageous classes, outlandish homework assignments and some outright invasion of privacy.  \n",
      "2083077  Derrick De Marney finds himself in a 39 Steps situation when he is wrongly accused of murder. While a fugitive from the law, De Marney is helped by heroine Nova Pilbeam, who three years earlier had played the adolescent kidnap victim in Hitchcock's The Man Who Knew Too Much. The obligatory \"fish out of water\" scene, in which the principals are briefly slowed down by a banal everyday event, occurs during a child's birthday party. The actual villain, whose identity is never in doubt (Hitchcock made thrillers, not mysteries) is played by George Curzon, who suffers from a twitching eye. Curzon's revelation during an elaborate nightclub sequence is a Hitchcockian tour de force, the sort of virtuoso sequence taken for granted in these days of flexible cameras and computer enhancement, but which in 1937 took a great deal of time, patience and talent to pull off. Released in the US as The Girl Was Young, Young and Innocent was based on a novel by Josephine Tey.  \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alex Whitman (Matthew Perry) is a designer from New York City who is sent to Las Vegas to supervise the construction of a nightclub that his firm has been hired to build. Alex is a straight-laced WASP-ish type who, while enjoying a night on the town, meets Isabel Fuentes (Salma Hayek), a free-spirited Mexican-American photographer. Alex and Isabel are overtaken by lust at first sight and end up sp  \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For young Parisian boy Antoine Doinel, life is one difficult situation after another. Surrounded by inconsiderate adults, including his neglectful parents, Antoine spends his days with his best friend, Rene, trying to plan for a better life. When one of their schemes goes awry, Antoine ends up in trouble with the law, leading to even more conflicts with unsympathetic authority figures.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#This cell is for combining certain data from the necessary csv files into a single dataframe (complete)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "movies = pd.read_csv('./the-movies-dataset/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={\"tagline\": \"string\", \"id\":\"string\", 'genres':\"string\", \"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\", \"production_companies\" :\"string\"})\n",
    "movies = movies.dropna()\n",
    "movies = movies.reset_index()\n",
    "\n",
    "\n",
    "#filter rows of empty data from movies on the columns: \"genres\", \"production_companies\"\n",
    "drop_indices = []\n",
    "for i in range(len(movies)):\n",
    "    len_1 = len(movies.iloc[i].loc[\"genres\"])                   \n",
    "    if(movies.iloc[i].loc[\"genres\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "        continue\n",
    "    len_2 = len(movies.iloc[i].loc[\"production_companies\"])\n",
    "    if(movies.iloc[i].loc[\"production_companies\"][len_2 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)    \n",
    "        continue   \n",
    "\n",
    "movies = movies.drop(labels=drop_indices, axis = 0)\n",
    "movies = movies.reset_index(names = \"index_1\")\n",
    "\n",
    "\n",
    "ratings = pd.read_csv('./the-movies-dataset/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"), dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})\n",
    "ratings = ratings.rename(columns={\"movieId\": \"id\"})\n",
    "ratings.dropna()\n",
    "ratings = ratings.reset_index(names = \"index_2\")\n",
    "\n",
    "\n",
    "keywords = pd.read_csv('./the-movies-dataset/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})\n",
    "keywords.dropna()\n",
    "keywords = keywords.reset_index()\n",
    "\n",
    "#filter rows of empty data from keyword on the keywords column\n",
    "drop_indices = []\n",
    "for i in range(len(keywords)):\n",
    "    len_1 = len(keywords.iloc[i].loc[\"keywords\"])                   \n",
    "    if(keywords.iloc[i].loc[\"keywords\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "\n",
    "keywords = keywords.drop(labels=drop_indices, axis = 0)\n",
    "keywords = keywords.reset_index(names = \"index_3\")\n",
    "\n",
    "\n",
    "credits = pd.read_csv(\"./the-movies-dataset/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})\n",
    "credits.dropna()\n",
    "credits = credits.reset_index()\n",
    "\n",
    "#filter rows of empty data from credits on the cast column \n",
    "drop_indices = []\n",
    "for i in range(len(credits)):\n",
    "    len_1 = len(credits.iloc[i].loc[\"cast\"])                   \n",
    "    if(credits.iloc[i].loc[\"cast\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "\n",
    "credits = credits.drop(labels=drop_indices, axis = 0)\n",
    "credits = credits.reset_index(names = \"index_4\")\n",
    "\n",
    "\n",
    "#default merge is inner: this only keeps movies that have the id existing in both dataframes\n",
    "complete =  pd.merge(movies, ratings, on =\"id\")\n",
    "complete =  pd.merge(complete,keywords, on =\"id\")\n",
    "complete  = pd.merge(complete,credits, on =\"id\")\n",
    "\n",
    "\n",
    "complete = complete.sort_values(by = 'userId')\n",
    "\n",
    "\n",
    "#use only certain types of columns\n",
    "complete  = complete.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "#for testing\n",
    "print(complete.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete number of users: 260788\n",
      "Number of train users before random selection: 14314\n",
      "Number of test users before random selection: 68048\n",
      "Number of users chosen: 6390\n",
      "Average number of ratings for the users chosen: 49.07151799687011\n",
      "Minutes taken:  12.13312626282374\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "def condition(array):\n",
    "    \"\"\"\"\n",
    "    originally used to filter out the rows of data with empty entries for certain columns\n",
    "    a method simlair to this is used in the previous cell above to reduce the number of checks\n",
    "    \"\"\"\n",
    "    length = len(array[4])\n",
    "    if(array[4][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[5])\n",
    "    if(array[5][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[6])\n",
    "    if(array[6][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[7])\n",
    "    if(array[7][length-2:] == \"[]\"):\n",
    "        return False   \n",
    "    #this is this unecessary with the dropNa function in the previous cell:\n",
    "    # length = len(array[8])\n",
    "    # if(array[8][length-4:]==\"<NA>\"):\n",
    "    #     return False\n",
    "    # length = len(array[9])\n",
    "    # if(array[9][length-4:]==\"<NA>\"):\n",
    "    #     return False \n",
    "    return True\n",
    "\n",
    "\n",
    "def populate_names(item):\n",
    "    \"\"\"used to extract names from the syntax of certain data entries\"\"\"\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    index = 0\n",
    "    for item in jsons:\n",
    "        if(index == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        index += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provide_data(array):\n",
    "    \"\"\"extract data from row of complete_array\"\"\"\n",
    "    movie_data = []\n",
    "    movie_data.append(int(array[0]))\n",
    "    movie_data.append(int(array[1]))\n",
    "    movie_data.append(float(array[2]))\n",
    "    movie_data.append(array[3])  \n",
    "\n",
    "    movie_data.append(populate_names(array[4]))\n",
    "    movie_data.append(populate_names(array[5]))\n",
    "    movie_data.append(populate_names(array[6]))\n",
    "    movie_data.append(populate_names(array[7]))\n",
    "\n",
    "    movie_data.append(str(array[8]))\n",
    "    movie_data.append(str(array[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "#LOOK: \n",
    "#https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "#iterating over pandas objects is slow!!!\n",
    "#should check for other datastructures below\n",
    "\n",
    "\n",
    "#LOOK:\n",
    "#there is an issue with this!!!\n",
    "#complete.loc[complete['userId'] == user_id] is too slow since it observes the entire dataframe\n",
    "#should try to make use of the fact that rows are in user order\n",
    "#there can be an initial list that is the copy of the dataframe...\n",
    "#another idea...\n",
    "#need to populate gaps and list_of_user_ids...\n",
    "\n",
    "\n",
    "\n",
    "list_of_user_ids = list(complete[\"userId\"].unique())\n",
    "complete_list = complete.values.tolist()\n",
    "\n",
    "print(\"Complete number of users:\", len(list_of_user_ids)) #260788\n",
    "\n",
    "#the complete list of user rows without ratings of the same movie more than once\n",
    "complete_list_no_dups = []\n",
    "#distinquish the users the row belongs to \n",
    "last_id = -1\n",
    "#the set of movies that a user has rated\n",
    "#used to prevent later ratings of a movie that the user has already rated\n",
    "movie_set = set()\n",
    "#how many rows a single user takes up for each user in the order of their occurance\n",
    "gaps = []\n",
    "#added to gaps when all of a users rows have been counted\n",
    "gap_len = 0\n",
    "#prevent adding gap_len to gaps until a real user has been iterated over\n",
    "first_it = True\n",
    "\n",
    "#populates gaps and complete_list_no_dups by omitting movies that already have a rating in respect to each user\n",
    "for row in complete_list:\n",
    "    if last_id != row[0]:\n",
    "        movie_set= set()\n",
    "        complete_list_no_dups.append(row)\n",
    "        movie_set.add(row[1])\n",
    "        if not first_it:    \n",
    "            gaps.append(gap_len)\n",
    "        gap_len = 1\n",
    "        first_it = False\n",
    "    else:\n",
    "        if row[1] not in movie_set:\n",
    "            complete_list_no_dups.append(row)\n",
    "            gap_len+=1\n",
    "            movie_set.add(row[1])\n",
    "    last_id = row[0]\n",
    "\n",
    "#add the last gap_len\n",
    "gaps.append(gap_len)\n",
    "\n",
    "user_index = 0\n",
    "full_index = 0\n",
    "\n",
    "nof_train_users = 0\n",
    "nof_test_users =0\n",
    "train_or_test = []\n",
    "\n",
    "#LOOK: there is an issue here since del is a costly function on a list!!!\n",
    "#instead, \n",
    "\n",
    "#Reduce gaps, list_of_user_ids, and complete_list_no_dups to force users to to have a certain range of ratings...\n",
    "#to be a train or test user\n",
    "#also populates nof_train_users, nof_test_users, and train_or_test\n",
    "for _ in range(len(gaps)):\n",
    "    if 50 <= gaps[user_index] and 70 >= gaps[user_index]:\n",
    "        full_index+=gaps[user_index]\n",
    "        user_index+=1\n",
    "        train_or_test.append(1)\n",
    "        nof_train_users+=1\n",
    "    elif 5 <= gaps[user_index] and 10 >= gaps[user_index]:\n",
    "        full_index+=gaps[user_index]\n",
    "        user_index+=1\n",
    "        train_or_test.append(0)\n",
    "        nof_test_users+=1\n",
    "    else:\n",
    "        temp = gaps[user_index]\n",
    "        del gaps[user_index]\n",
    "        del list_of_user_ids[user_index]\n",
    "        del complete_list_no_dups[full_index:full_index+temp]\n",
    "\n",
    "print(\"Number of train users before random selection:\", nof_train_users) #14314\n",
    "print(\"Number of test users before random selection:\", nof_test_users) #68048\n",
    "\n",
    "#LOOK: does the below operation really need to run for the entire data set???\n",
    "#instead the above operation can include the random selection\n",
    "#answer: this does not improve processing speed because it will make the the else portion run more\n",
    "#which is an expensive task. Note: each delete is O(n)\n",
    "\n",
    "#LOOK: What about filtering users randomly before selecting train and test users??? \n",
    "#the problem with this is that it is unknown how many users will be produced of each user type and if it is enough\n",
    "#the users need to be seperated into train and test users to find out which would \n",
    "\n",
    "\n",
    "#These are the average number of ratings to select from each user type\n",
    "#note since the target is 5000 train users and 1000 test users the extra 200 users leaves room for error to avoid...\n",
    "#passing less than 5000 or 1000 users\n",
    "#this would be a problem since cell 5 needs to select (5000 and 1000) users of each type from the pool\n",
    "avg_nof_train_users_to_select = 5200\n",
    "avg_nof_test_users_to_select = 1200\n",
    "\n",
    "#this is a list for all selected users to rows of transformed data for each movie they rated\n",
    "user_to_data = []\n",
    "\n",
    "#index of the current movie row \n",
    "index  = 0\n",
    "\n",
    "#this is collected for insight\n",
    "avg = 0.0\n",
    "cnt = 0.0\n",
    "\n",
    "#populate user_to_data from complete_array\n",
    "for i in range(0, len(list_of_user_ids)):\n",
    "    #generate a random float to determine a pass for the user\n",
    "    if(((train_or_test[i]) and (random.random()<float(avg_nof_train_users_to_select/nof_train_users)))\n",
    "       or ((not train_or_test[i]) and (random.random()<float(avg_nof_test_users_to_select/nof_test_users)))):\n",
    "        user_to_data.append([])\n",
    "        last_index = len(user_to_data) -1\n",
    "        for j in range(index, len(complete_list_no_dups)):\n",
    "            if complete_list_no_dups[j][0] == list_of_user_ids[i]:\n",
    "                #orginally: the condition function checked if the movie row had missing values for certain columns and...\n",
    "                #omitted the movie if it had missing values   \n",
    "                # if(condition(complete_array[j])):\n",
    "                    #transform data...\n",
    "                #a more efficient method is used instead in the second cell  \n",
    "                transformed = provide_data(complete_list_no_dups[j])\n",
    "                user_to_data[last_index].append(transformed)    \n",
    "            else:\n",
    "                avg += len(user_to_data[last_index])\n",
    "                cnt+=1\n",
    "                index = j\n",
    "                break           \n",
    "    else:\n",
    "        index += gaps[i]\n",
    "\n",
    "\n",
    "\n",
    "#Go through user_to_data and re-index the users in list order since certain users were omitted\n",
    "#this is for simplicity, readability, and usage in cell 5\n",
    "for i in range(len(user_to_data)):\n",
    "    for j in range(len(user_to_data[i])):\n",
    "        user_to_data[i][j][0] = i\n",
    "\n",
    "\n",
    "#How many users are in the final user_to_data \n",
    "print(\"Number of users chosen:\", len(user_to_data))\n",
    "\n",
    "#average number of ratings per users\n",
    "#note: omits the very last user but this makes little difference\n",
    "print(\"Average number of ratings for the users chosen:\", float(avg/cnt))\n",
    "\n",
    "\n",
    "print(\"Minutes taken: \", float((time.time()-start_time)/60))\n",
    "\n",
    "\n",
    "# recent run:\n",
    "# time to complete: 12 (minutes)\n",
    "# Complete number of users: 260788\n",
    "# Number of train users before random selection: 14314\n",
    "# Number of test users before random selection: 68048\n",
    "# Number of users chosen: 6390\n",
    "# Average number of ratings for the users chosen: 49.07151799687011\n",
    "# Minutes taken:  12.13312626282374\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in a constructed_data/constructed_data.csv file so that cells below can run without running this cell and above\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, 'constructed_data')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    for i in range(len(user_to_data)):\n",
    "        writer.writerows(user_to_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a starting point if the data is already saved to the constructed_data/constructed_data.csv\n",
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", 'r', encoding=\"utf-8\") as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "#for each user, distinuish whether they are a test or train user\n",
    "#note: tehcincally in the second cell there is clearly distinquished test and train users\n",
    "#so this is technically somewhat of a redundant process\n",
    "#but, this cell executes instantly so there is no need to include the user label in constructed.csv\n",
    " \n",
    "\n",
    "user_to_data_train = []\n",
    "user_to_data_test = []\n",
    "\n",
    "user_id = data_list[0][0]\n",
    "ratings = []\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        if(5 <= len(ratings) and 10 >= len(ratings)):\n",
    "            user_to_data_test.append(ratings)\n",
    "        else:\n",
    "            user_to_data_train.append(ratings)\n",
    "        user_id = row[0]\n",
    "        ratings = [row]\n",
    "    else:\n",
    "        ratings.append(row)\n",
    "\n",
    "\n",
    "#distinuish whether the last user is a test or train user\n",
    "if(5 <= len(ratings) and 10 >= len(ratings)):\n",
    "    user_to_data_test.append(ratings)\n",
    "else:\n",
    "    user_to_data_train.append(ratings)\n",
    "\n",
    "\n",
    "\n",
    "user_to_data_train = random.sample(user_to_data_train, 5000)\n",
    "user_to_data_test = random.sample(user_to_data_test, 1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_1 to target comparison (train):\n",
      "[3.411290322580645, 3.896551724137931, 3.1557377049180326, 3.347457627118644, 3.588235294117647]\n",
      "[4.0, 4.0, 4.0, 4.0, 3.0]\n",
      "Feature_1 to target comparison (test):\n",
      "[2.111111111111111, 3.5714285714285716, 3.5625, 3.0, 4.277777777777778]\n",
      "[4.0, 3.0, 0.5, 4.0, 3.0]\n",
      "Feature_2 to target comparison (train):\n",
      "[3.50229426239177, 3.8492242609426492, 3.289531210338809, 3.2428965419785527, 3.5535379743743403]\n",
      "[4.0, 4.0, 4.0, 4.0, 3.0]\n",
      "Feature_2 to target comparison (test):\n",
      "[1.4905347168091443, 3.9911113691973883, 3.5795614530307445, 3.0, 3.8349874609669294]\n",
      "[4.0, 3.0, 0.5, 4.0, 3.0]\n",
      "Feature_3 to target comparison (train):\n",
      "[3.66343402724995, 4.681204850399807, 4.064005992354782, 3.906940282821642, 3.6928982120765412]\n",
      "[4.0, 4.0, 4.0, 4.0, 3.0]\n",
      "Feature_3 to target comparison (test):\n",
      "[3.674843692449676, 3.4624587716560424, 3.7614638757649885, 3.468908744158921, 3.5556344589271047]\n",
      "[4.0, 3.0, 0.5, 4.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "from ordered_set import OrderedSet\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "class user_type_vars():\n",
    "    \"\"\"Each of the variables in this class represent the data structures for a user type\"\"\"\n",
    "    def __init__(self):\n",
    "        #for each user, a dictionary of movie_id to the movies rating for each movie the user watched\n",
    "        self.user_to_movie_id_to_rating = [] \n",
    "\n",
    "        #for each user, a random choice of movie_id from all the movies the user watched to represent the target movie\n",
    "        self.user_to_target_movie_id = [] \n",
    "\n",
    "        #for each user, this is the index of the users target movie in the order of train movies_in_order\n",
    "        #(train_users only)\n",
    "        self.user_to_target_index_full = [] \n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set \n",
    "        #missing ratings and target movie ratings are set to that movies average rating\n",
    "        #(train_users only)\n",
    "        self.user_to_ratings_full = [] \n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set\n",
    "        #the movies mean rating is subtracted from each rating\n",
    "        #missing ratings and target movie ratings are set to zero\n",
    "        #(train_users only)\n",
    "        self.user_to_ratings_full_transform = []\n",
    "\n",
    "        #this is a set of every unique target movie for the train set\n",
    "        #this is used to check if a movie is in the train set but only as a target movie\n",
    "        #(train_users only)\n",
    "        self.target_movies = set()\n",
    "\n",
    "        #for every movie watched by the user_type, a list of ratings\n",
    "        self.movie_id_to_ratings = dict()\n",
    "\n",
    "        #all the movie ids in the order of where they appear first in the list of user ratings (either train or test users) \n",
    "        self.movies_in_order = OrderedSet()\n",
    "\n",
    "        #model input features x for each user\n",
    "        self.feature_1 = []\n",
    "        self.feature_2 = []\n",
    "        self.feature_3 = []\n",
    "\n",
    "        #model output feature y for each user\n",
    "        self.user_to_target_rating  = [] \n",
    "\n",
    "\n",
    "#user_type_vars can represent a group of train users and a group of test users\n",
    "train_users = user_type_vars()\n",
    "test_users = user_type_vars()\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def load_feature_1_and_2(target_movies, movies_in_order, user_to_data, movie_id_to_ratings, user_to_movie_id_to_rating, user_to_target_movie_id, user_to_target_rating, feature_1, feature_2):\n",
    "    \"\"\"\n",
    "    This is ran once to be used to populate features 1 and 2 for the train_users...\n",
    "    and ran again to be used to populate features 1 and 2 for the test_users\n",
    "    It also populates the train and test version of these variables: target_movies, movies_in_order, movie_id_to_ratings,\n",
    "    user_to_movie_id_to_rating, user_to_target_movie_id, user_to_target_rating\n",
    "    These variables are used in the load_feature_3 function \n",
    "    \"\"\" \n",
    "    #these are used to calculate the overall train rating\n",
    "    #the overall_average_train which is overall_rating_sum/overall_rating_count is only set to the output of the \"train\" function call\n",
    "    #this is used to fill in ratings for movies that are only target movies for a certain set of users \n",
    "    overall_rating_sum = 0\n",
    "    overall_rating_count = 0\n",
    "\n",
    "    for i in range(len(user_to_data)):\n",
    "        movie_id_to_words = dict()\n",
    "        movie_id_to_rating = dict()\n",
    "        index = 0\n",
    "        rand_int = random.randint(0, len(user_to_data[i])-1)\n",
    "        for movie_data in user_to_data[i]:\n",
    "            if index == rand_int:    \n",
    "                target_movies.add(movie_data[1])\n",
    "                user_to_target_movie_id.append(movie_data[1])\n",
    "            else:\n",
    "                #the program should train and test while simulating the possibility of\n",
    "                #some new movies having no existing rating data in the database.\n",
    "                #This is critical if the resulting model were to be tried on completely new data.\n",
    "                \n",
    "                #this is why target ratings are omitted from movie_id_to_ratings\n",
    "                #the same logic stands for overall_average_train which is formed by overall_rating_sum and overall_rating_count\n",
    "                overall_rating_sum += float(movie_data[2])\n",
    "                overall_rating_count += 1\n",
    "\n",
    "                if movie_data[1] in movie_id_to_ratings.keys():\n",
    "                    movie_id_to_ratings[movie_data[1]].append(float(movie_data[2]))\n",
    "                else:\n",
    "                    movie_id_to_ratings[movie_data[1]] = [float(movie_data[2])]\n",
    "\n",
    "            movie_string = \"\"\n",
    "\n",
    "            #use this to apply all the text data and combine in to a single list of words (repeats allowed):\n",
    "            # for index in range (3,len(movie_data)):\n",
    "            #     if(index!= len(movie_data)-1):\n",
    "            #         movie_string+= movie_data[index]+\" \"\n",
    "            #     else:\n",
    "            #         movie_string+= movie_data[index]\n",
    "\n",
    "\n",
    "            #all of the text columns and a few combinations of certain text columns were tested but they were not helpful in...\n",
    "            #increasing model performance (see README.md)\n",
    "\n",
    "            #Use this truncated code to only include the genre column strings:\n",
    "            movie_string = movie_data[4]\n",
    "\n",
    "            #lematization and conversion to lists of words\n",
    "            cleaned = remove_stopwords(movie_string)\n",
    "            cleaned = [wnl.lemmatize(word) for word in cleaned.split(\" \")]\n",
    "            cleaned = [word[:-1] for word in cleaned if word.endswith(\".\")] + [word for word in cleaned if not word.endswith(\".\")]\n",
    "\n",
    "            movie_id_to_words[movie_data[1]] = cleaned\n",
    "            movie_id_to_rating[movie_data[1]] = float(movie_data[2])\n",
    "            movies_in_order.add(movie_data[1])\n",
    "            index+=1\n",
    "\n",
    "        user_to_movie_id_to_rating.append(movie_id_to_rating)\n",
    "\n",
    "        #the current users set of words from all the movies they rated\n",
    "        users_words_in_order = OrderedSet()\n",
    "        for movie_id in movie_id_to_words.keys():\n",
    "            for word in movie_id_to_words[movie_id]:\n",
    "                users_words_in_order.add(word)\n",
    "\n",
    "\n",
    "        word_counts = [] #list of word counts for the users_words_in_order for each movie (excluding target)\n",
    "        target_word_counts = [] #word counts for the users_words_in_order for the target movie\n",
    "\n",
    "\n",
    "        #for each movie the user watched record the wordcount for each word in users_words_in_order\n",
    "        for movie_id in movie_id_to_words.keys():\n",
    "            if movie_id != user_to_target_movie_id[-1]:\n",
    "                temp_dict = Counter(movie_id_to_words[movie_id])\n",
    "                temp_list = []\n",
    "                for word in users_words_in_order:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])\n",
    "                    else:\n",
    "                        temp_list.append(0)  \n",
    "                word_counts.append(temp_list)  \n",
    "            else:\n",
    "                temp_dict = Counter(movie_id_to_words[movie_id])\n",
    "                temp_list = []\n",
    "                for word in users_words_in_order:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])             \n",
    "                    else:\n",
    "                        temp_list.append(0) \n",
    "                target_word_counts = temp_list\n",
    "        \n",
    "\n",
    "        #construct the normalized tf-idf before applying cossine similairity\n",
    "        #this places value on terms that are un-common in alot of documents,\n",
    "        #while still placing value on how common they are in the document at hand\n",
    "        #in this case documents are word counts for the corpuses of a single movie the user rated\n",
    "        #this leads to a more powerful quantifier for cossine similairity between documents\n",
    "\n",
    "        complete_word_counts = word_counts.copy()\n",
    "        complete_word_counts.append(target_word_counts)\n",
    "        transformed_word_counts = TfidfTransformer().fit_transform(complete_word_counts).toarray()\n",
    "\n",
    "\n",
    "        #populate ratings without the target rating\n",
    "        ratings = []\n",
    "        for movie_id in movie_id_to_rating.keys():\n",
    "            if movie_id != user_to_target_movie_id[-1]:\n",
    "                ratings.append(movie_id_to_rating[movie_id])\n",
    "            else:\n",
    "                #add the target movie rating for a single user (each user has only one target movie rating)\n",
    "                user_to_target_rating.append(movie_id_to_rating[movie_id])\n",
    "    \n",
    "\n",
    "        def predict():\n",
    "            \"Use the word counts and ratings to add prediction to feature_1 list and feature_2 list\"\n",
    "            #pred_1 is unweighted average of all of the users movie\n",
    "            pred_1 = 0 \n",
    "            #pred_2 is weighted average of all the users movies (weights are based on (cossine similarity/linear kernel))\n",
    "            #unless denominator is zero (see below)\n",
    "            pred_2 = 0\n",
    "\n",
    "            sum = 0\n",
    "            for i in range(len(ratings)):\n",
    "                sum += ratings[i]\n",
    "            pred_1 = float(sum/len(ratings))\n",
    "\n",
    "            cosine_sim = linear_kernel(X = transformed_word_counts[0:-1],Y = [transformed_word_counts[-1]])\n",
    "            cosine_sim = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            pred_2 = pred_1\n",
    "            for i in range(len(ratings)):\n",
    "                numerator += float(cosine_sim[i]*ratings[i])\n",
    "                denominator += cosine_sim[i]\n",
    "    \n",
    "            #in case of potential division by zero\n",
    "            if denominator != 0:\n",
    "                pred_2 = float(numerator/denominator)\n",
    "    \n",
    "            return (pred_1, pred_2)\n",
    "        \n",
    "        predictions = predict()\n",
    "\n",
    "        feature_1.append(predictions[0])\n",
    "        feature_2.append(predictions[1])\n",
    "            \n",
    "        \n",
    "    return float(overall_rating_sum/overall_rating_count)\n",
    "\n",
    "#populate train data (feature 1 and feature 2)\n",
    "#the overall_average_train which is overall_rating_sum/overall_rating_count is only set to the output of the \"train\" function call\n",
    "#this is used to fill in ratings for movies that are only target movies for a certain set of users\n",
    "overall_average_train = load_feature_1_and_2(train_users.target_movies, train_users.movies_in_order, user_to_data_train, train_users.movie_id_to_ratings, train_users.user_to_movie_id_to_rating, \n",
    "                                                         train_users.user_to_target_movie_id, train_users.user_to_target_rating, train_users.feature_1, train_users.feature_2)\n",
    "\n",
    "#populate test data (feature 1 and feature 2)\n",
    "load_feature_1_and_2(set(), test_users.movies_in_order, user_to_data_test, test_users.movie_id_to_ratings, test_users.user_to_movie_id_to_rating, \n",
    "               test_users.user_to_target_movie_id,\n",
    "               test_users.user_to_target_rating, test_users.feature_1, test_users.feature_2)\n",
    "\n",
    "\n",
    "def pre_svd(movie_id_to_average_rating, movies_in_order, user_to_ratings_full_transform, user_to_ratings_full, user_to_target_index_full, \n",
    "               user_to_movie_id_to_rating, user_to_target_movie_id):\n",
    "    \"\"\"\n",
    "    Populate the lists user_to_ratings_full and user_to_ratings_full_transform \n",
    "    User_to_ratings_full_transform is used for svd because it includes entries from all movies in movies_in_order\n",
    "    It also transforms the data in user_to_ratings_full by subtracting the movie rating mean\n",
    "    This means that the transformed value at the indices of unwatched movies and index coresponding to target movies are zero\n",
    "    \"\"\"\n",
    "    for i in range(len(user_to_movie_id_to_rating)):\n",
    "        ratings = []\n",
    "        transformed_ratings = []\n",
    "\n",
    "        #the index of the target movie within the entire movies_in_order ordered set\n",
    "        index = 0\n",
    "\n",
    "        for movie_id in movies_in_order:\n",
    "            if movie_id == user_to_target_movie_id[i]:\n",
    "                user_to_target_index_full.append(index)\n",
    "                ratings.append(movie_id_to_average_rating[movie_id])\n",
    "                transformed_ratings.append(movie_id_to_average_rating[movie_id] - movie_id_to_average_rating[movie_id]) \n",
    "            elif movie_id in user_to_movie_id_to_rating[i].keys():\n",
    "                ratings.append(user_to_movie_id_to_rating[i][movie_id])\n",
    "                transformed_ratings.append(user_to_movie_id_to_rating[i][movie_id] - movie_id_to_average_rating[movie_id])\n",
    "            else:\n",
    "                ratings.append(movie_id_to_average_rating[movie_id])\n",
    "                transformed_ratings.append(movie_id_to_average_rating[movie_id] - movie_id_to_average_rating[movie_id])\n",
    "            index +=1\n",
    "        #user_to_ratings_full is just for demonstration\n",
    "        user_to_ratings_full.append(ratings)\n",
    "        #per movie averages have been subtracted (data is ready for svd)\n",
    "        user_to_ratings_full_transform.append(transformed_ratings)\n",
    "\n",
    "\n",
    "\n",
    "def svd_full(user_to_ratings_full_transform, n, movie_id_to_average_rating):\n",
    "    \"\"\"\n",
    "    1. get the svd of the user_to_ratings_full_transform \n",
    "    2. truncate each factor to 20 components\n",
    "    3. multiply the trauncated components together (U X s) X V \n",
    "    4. scale back the values to the orginal rating scale (1-5) and return result\n",
    "    \"\"\"\n",
    "    U, s, V = np.linalg.svd(user_to_ratings_full_transform, full_matrices=False)\n",
    "    \n",
    "    #simplify factors to n features\n",
    "    s=np.diag(s)\n",
    "    s=s[0:n,0:n]\n",
    "    U=U[:,0:n]\n",
    "    V=V[0:n,:]\n",
    "\n",
    "    #reconstruct to a new array\n",
    "    Us = np.dot(U,s)\n",
    "    UsV = np.dot(Us,V)\n",
    "\n",
    "    x = np.tile(list(movie_id_to_average_rating.values()), (UsV.shape[0],1))\n",
    "\n",
    "    #this tranforms the UsV row by row into the original rating scale (1-5)\n",
    "    UsV = UsV + x\n",
    "\n",
    "    #be consistent with data structures...\n",
    "    return list(UsV)\n",
    "\n",
    "\n",
    "\n",
    "def load_feature_3():\n",
    "    \"\"\"\n",
    "    populate feature_3 with a method loosely outlined here:\n",
    "    1. find the average ratings for movies \n",
    "    2. pre_svd writes a rating for every movie for every user as well as a transformed version of those rating with the averages found above\n",
    "    3. then use the output of the svd_full function by row for user and by column for the target movie rating prediction\n",
    "    \"\"\"\n",
    "\n",
    "    #Every movie ever seen by any user in either the test and train sets\n",
    "    all_movies_in_order = train_users.movies_in_order|test_users.movies_in_order\n",
    "\n",
    "\n",
    "    #When a movie has a number of target ratings and non-target ratings, then only the non-target ratings are used...\n",
    "    #to form the movies average rating\n",
    "\n",
    "    #There is a difference between non-target ratings between movie_id_to_average_rating_train and movie_id_to_average_rating_full.\n",
    "    #movie_id_to_average_rating_train considers the train set and movie_id_to_average_rating_full considers the train and test set\n",
    "\n",
    "    #When a movie has only target ratings for movie_id_to_average_rating_train or movie_id_to_average_rating_full...\n",
    "    #instead of using the mean of the actual target ratings, the movies average rating takes on the value of overall_average_train.\n",
    "    #this is used to simlulate the potential movies to be rated for a new user that have no ratings in the existing data.\n",
    "\n",
    "    #The code below deliniates two different averages for valid movies, a train average and a train+test or full average.\n",
    "    #The train average is used to normalize the ratings of the movies for train users in the first pre_svd call.\n",
    "    #The train+test averages are used to normalize the ratings of the movies for train+test users in the second pre_svd call.\n",
    "\n",
    "    movie_id_to_average_rating_train = dict()\n",
    "    movie_id_to_average_rating_full = dict()\n",
    "\n",
    "    for movie in all_movies_in_order:\n",
    "        temp = 0\n",
    "        if(movie in train_users.movie_id_to_ratings and movie in test_users.movie_id_to_ratings):\n",
    "            for rating in train_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_train[movie] = float(temp/len(train_users.movie_id_to_ratings[movie])) \n",
    "\n",
    "            for rating in test_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_full[movie] = float(temp/(len(train_users.movie_id_to_ratings[movie])+len(test_users.movie_id_to_ratings[movie])))  \n",
    "\n",
    "        elif(movie in train_users.movie_id_to_ratings):\n",
    "            for rating in train_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_train[movie] = float(temp/len(train_users.movie_id_to_ratings[movie]))\n",
    "            movie_id_to_average_rating_full[movie] = movie_id_to_average_rating_train[movie]\n",
    "\n",
    "        elif(movie in test_users.movie_id_to_ratings):        \n",
    "            if(movie in train_users.target_movies):\n",
    "                movie_id_to_average_rating_train[movie] = overall_average_train\n",
    "\n",
    "            for rating in test_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_full[movie] = float(temp/len(test_users.movie_id_to_ratings[movie]))\n",
    "        else:\n",
    "            if(movie in train_users.target_movies):\n",
    "                movie_id_to_average_rating_train[movie] = overall_average_train\n",
    "                movie_id_to_average_rating_full[movie] = overall_average_train\n",
    "            else:\n",
    "                movie_id_to_average_rating_full[movie] = overall_average_train\n",
    "   \n",
    "\n",
    "    #note: the three variables below are mirrored in the train_users object\n",
    "    #these variables are for the full set (all_movies_in_order)\n",
    "\n",
    "    #all the ratings for each user for the movies corresponding to the order of the ordered set (all_movies_in_order)\n",
    "    full_user_to_ratings_full = []\n",
    "    #all the transformed ratings for each user for the movies corresponding to the order of the ordered set (all_movies_in_order)\n",
    "    full_user_to_ratings_full_transform = [] \n",
    "    #for each user, the index of the target movie corresponding to the order of (all_movies_in_order)\n",
    "    full_user_to_target_index_full = [] \n",
    "\n",
    "\n",
    "    #combining the watched movies in this order (train and then test users)\n",
    "    full_user_to_movie_id_to_rating  = train_users.user_to_movie_id_to_rating + test_users.user_to_movie_id_to_rating\n",
    "    #combining the id of the target movie in this order (train and then test users)\n",
    "    full_user_to_target_movie_id = train_users.user_to_target_movie_id + test_users.user_to_target_movie_id\n",
    "\n",
    "\n",
    "    #the two function calls below are used to populate user_to_ratings_full_transform, user_to_ratings_full, and user_to_target_index_full (both train and full versions). \n",
    "    #user_to_ratings_full_transform is scaled with the movie_id_to_average_rating (both train and full versions).\n",
    "\n",
    "    pre_svd(movie_id_to_average_rating_train, train_users.movies_in_order, train_users.user_to_ratings_full_transform, train_users.user_to_ratings_full, \n",
    "            train_users.user_to_target_index_full, train_users.user_to_movie_id_to_rating, train_users.user_to_target_movie_id)\n",
    "\n",
    "    pre_svd(movie_id_to_average_rating_full, all_movies_in_order, full_user_to_ratings_full_transform, full_user_to_ratings_full, full_user_to_target_index_full, \n",
    "                full_user_to_movie_id_to_rating, full_user_to_target_movie_id)\n",
    "\n",
    "\n",
    "    #In practice, there is a train and a test set, the train set is a selection of what the database has on record.\n",
    "    #The test data will usually be data that hasn't been seen before that can include any number of test users.\n",
    "    #When train_users.user_to_ratings_full_transform is used as the input of the svd function below, \n",
    "    #svd_out_train is used to produce predictions used to train the model\n",
    "    #When full_user_to_ratings_full_transform is used as the input of the svd function below,\n",
    "    #svd_out_full is used to produce predictions used to test the model\n",
    "\n",
    "    #LOOK: this is not valid with the current model of making best preidctions with few sample ratings for test users and many ratings for train users\n",
    "    #n = 20 is close to the highest performing constant for 100 min ratings for train and test users\n",
    "    #n = 10 is close to the highest performing constant for 50-75 min rating per train users and 5-10 min ratings per test user\n",
    "\n",
    "    #Note: different values of n per function call below were tested with 50-75 min rating per train users and 5-10 min ratings per test user\n",
    "    #this did not lead to performance benefits, it was best that both values of n were 10 for perfrormance\n",
    "\n",
    "    svd_out_train = svd_full(train_users.user_to_ratings_full_transform, 10, movie_id_to_average_rating_train)\n",
    "    svd_out_full = svd_full(full_user_to_ratings_full_transform, 10, movie_id_to_average_rating_full)\n",
    "\n",
    "    #here the smaller svd provides predictions used to train the model\n",
    "    for i in range(len(train_users.user_to_ratings_full_transform)):\n",
    "        train_users.feature_3.append(svd_out_train[i][train_users.user_to_target_index_full[i]])\n",
    "\n",
    "    #here the larger svd provides predictions used to test the model\n",
    "    for i in range(len(full_user_to_ratings_full_transform) - len(train_users.user_to_ratings_full_transform)):\n",
    "        test_users.feature_3.append(svd_out_full[i+len(train_users.user_to_ratings_full_transform)][full_user_to_target_index_full[i+len(train_users.user_to_ratings_full_transform)]])\n",
    "\n",
    "#populate train and test data (feature 3)\n",
    "load_feature_3()\n",
    "\n",
    "\n",
    "#this is just used to show how the features approximate the target rating\n",
    "print(\"Feature_1 to target comparison (train):\")\n",
    "print(train_users.feature_1[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_1 to target comparison (test):\")\n",
    "print(test_users.feature_1[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_2 to target comparison (train):\")\n",
    "print(train_users.feature_2[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_2 to target comparison (test):\")\n",
    "print(test_users.feature_2[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_3 to target comparison (train):\")\n",
    "print(train_users.feature_3[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_3 to target comparison (test):\")\n",
    "print(test_users.feature_3[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "\n",
    "#just for code clarity\n",
    "del user_to_data_train\n",
    "del user_to_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance scores: First feature: 0.14476050645065913 Second feature: 0.3467226147748838\n",
      "Feature Importance scores: First feature: 0.14781494177692336 Second feature: 0.3512569987263935\n",
      "Feature Importance scores: First feature: 0.14441300950567545 Second feature: 0.3429934046858544\n",
      "Feature Importance scores: First feature: 0.14659028128554638 Second feature: 0.33415348978835524\n",
      "Feature Importance scores: First feature: 0.1449643694982014 Second feature: 0.3416682893335311\n",
      "Feature Importance scores: First feature: 0.14552759237417295 Second feature: 0.3423325141159431\n",
      "Feature Importance scores: First feature: 0.1500010268688195 Second feature: 0.3332368321309996\n",
      "Feature Importance scores: First feature: 0.15103619062534662 Second feature: 0.34904569357244974\n",
      "Feature Importance scores: First feature: 0.15073065373295877 Second feature: 0.3419501811772582\n",
      "Feature Importance scores: First feature: 0.14511669178176817 Second feature: 0.33271462776050037\n",
      "Feature Importance scores: First feature: 0.14891777113573265 Second feature: 0.34470709120832344\n",
      "Feature Importance scores: First feature: 0.15294749726604182 Second feature: 0.34204926521585727\n",
      "Feature Importance scores: First feature: 0.1532372210374449 Second feature: 0.34761940330802654\n",
      "Feature Importance scores: First feature: 0.14583215818996215 Second feature: 0.34135352302708055\n",
      "Feature Importance scores: First feature: 0.14910307359398978 Second feature: 0.35084235259397895\n",
      "Feature Importance scores: First feature: 0.14832170102209888 Second feature: 0.34514493088109177\n",
      "Feature Importance scores: First feature: 0.14941951335276457 Second feature: 0.3456695086252276\n",
      "Feature Importance scores: First feature: 0.152311832701092 Second feature: 0.33939312614780964\n",
      "Feature Importance scores: First feature: 0.14781710098861175 Second feature: 0.3453513994385433\n",
      "Feature Importance scores: First feature: 0.14525650060310627 Second feature: 0.3388385044450019\n",
      "Feature Importance scores: First feature: 0.15352364575191485 Second feature: 0.334234068595089\n",
      "Feature Importance scores: First feature: 0.15189383737357848 Second feature: 0.34224330388570656\n",
      "Feature Importance scores: First feature: 0.14987997496027614 Second feature: 0.3389709485193043\n",
      "Feature Importance scores: First feature: 0.1513294179826618 Second feature: 0.33467137788241086\n",
      "Feature Importance scores: First feature: 0.1576281612523525 Second feature: 0.3420851970564181\n",
      "Feature Importance scores: First feature: 0.14797671627657988 Second feature: 0.3432884318984729\n",
      "Feature Importance scores: First feature: 0.15087925353665724 Second feature: 0.3449860500475737\n",
      "Feature Importance scores: First feature: 0.15122152461443966 Second feature: 0.3423026476387821\n",
      "Feature Importance scores: First feature: 0.14758618510444577 Second feature: 0.34355893936429777\n",
      "Feature Importance scores: First feature: 0.14956608717042927 Second feature: 0.34323903053547605\n",
      "Feature Importance scores: First feature: 0.15019875521203235 Second feature: 0.33612282632509993\n",
      "Feature Importance scores: First feature: 0.15182690881550776 Second feature: 0.34594028012461403\n",
      "Feature Importance scores: First feature: 0.1470679929470195 Second feature: 0.33923345972096924\n",
      "Feature Importance scores: First feature: 0.14632954642915041 Second feature: 0.34418782071622545\n",
      "Feature Importance scores: First feature: 0.15219607480927846 Second feature: 0.34929543966329735\n",
      "Feature Importance scores: First feature: 0.14716728405954801 Second feature: 0.3395892729285578\n",
      "Feature Importance scores: First feature: 0.1522383208699586 Second feature: 0.3486795447359014\n",
      "Feature Importance scores: First feature: 0.14692509074005128 Second feature: 0.33557301204870466\n",
      "Feature Importance scores: First feature: 0.14714802511393385 Second feature: 0.3477285167801445\n",
      "Feature Importance scores: First feature: 0.14733763211167933 Second feature: 0.34159225240522084\n",
      "Feature Importance scores: First feature: 0.1503449311766122 Second feature: 0.34799945567599966\n",
      "Feature Importance scores: First feature: 0.149519322675847 Second feature: 0.3413679320828934\n",
      "Feature Importance scores: First feature: 0.14733857605874673 Second feature: 0.3386436144957902\n",
      "Feature Importance scores: First feature: 0.14815834693952687 Second feature: 0.33359797328033014\n",
      "Feature Importance scores: First feature: 0.15046289811716693 Second feature: 0.33518701230486014\n",
      "Feature Importance scores: First feature: 0.15351913746689516 Second feature: 0.3452712968202113\n",
      "Feature Importance scores: First feature: 0.15243761489828742 Second feature: 0.33284554840726616\n",
      "Feature Importance scores: First feature: 0.14265920885375485 Second feature: 0.33838341847117975\n",
      "Feature Importance scores: First feature: 0.15034044496244853 Second feature: 0.3451501682039122\n",
      "Feature Importance scores: First feature: 0.1525932869941526 Second feature: 0.3409988329535061\n",
      "Feature Importance scores: First feature: 0.151217638687288 Second feature: 0.34625533945061365\n",
      "Feature Importance scores: First feature: 0.14845187549356514 Second feature: 0.33658253206061195\n",
      "Feature Importance scores: First feature: 0.14525399684475065 Second feature: 0.34173594787258715\n",
      "Feature Importance scores: First feature: 0.15108596316497147 Second feature: 0.3369624948887415\n",
      "Feature Importance scores: First feature: 0.15048066894639645 Second feature: 0.3418911684687841\n",
      "Feature Importance scores: First feature: 0.14722415657450055 Second feature: 0.33229046673482887\n",
      "Feature Importance scores: First feature: 0.14573445791521525 Second feature: 0.33617170271387825\n",
      "Feature Importance scores: First feature: 0.1442134320090297 Second feature: 0.3383901646823669\n",
      "Feature Importance scores: First feature: 0.14681262442804802 Second feature: 0.3424591863069658\n",
      "Feature Importance scores: First feature: 0.1471253980219249 Second feature: 0.33878905148647076\n",
      "Feature Importance scores: First feature: 0.15118755816666113 Second feature: 0.34132300383756137\n",
      "Feature Importance scores: First feature: 0.14762999316850056 Second feature: 0.3477638897408364\n",
      "Feature Importance scores: First feature: 0.14556691037200484 Second feature: 0.33431962287193784\n",
      "Feature Importance scores: First feature: 0.14382941868929386 Second feature: 0.33523720774205873\n",
      "Feature Importance scores: First feature: 0.15247842653742144 Second feature: 0.33969811717063747\n",
      "Feature Importance scores: First feature: 0.14825807078347647 Second feature: 0.34321177330623287\n",
      "Feature Importance scores: First feature: 0.15268166153820106 Second feature: 0.3357035068142385\n",
      "Feature Importance scores: First feature: 0.1543245424600515 Second feature: 0.3415216037882973\n",
      "Feature Importance scores: First feature: 0.1500693544952028 Second feature: 0.3394154115584517\n",
      "Feature Importance scores: First feature: 0.15063700910986028 Second feature: 0.34907647405814884\n",
      "Feature Importance scores: First feature: 0.14883308883027394 Second feature: 0.3429121364944222\n",
      "Feature Importance scores: First feature: 0.1499491749807492 Second feature: 0.342038817491901\n",
      "Feature Importance scores: First feature: 0.14841420787699636 Second feature: 0.3420308875225672\n",
      "Feature Importance scores: First feature: 0.14838202517298113 Second feature: 0.333874698760617\n",
      "Feature Importance scores: First feature: 0.14409764480909418 Second feature: 0.33564053026969587\n",
      "Feature Importance scores: First feature: 0.15719393681630472 Second feature: 0.349969162491804\n",
      "Feature Importance scores: First feature: 0.1529957465143195 Second feature: 0.34236836336585313\n",
      "Feature Importance scores: First feature: 0.14688528460300707 Second feature: 0.33256897395979085\n",
      "Feature Importance scores: First feature: 0.1485676536650805 Second feature: 0.3505263032288543\n",
      "Feature Importance scores: First feature: 0.1432082052537613 Second feature: 0.33373943841399656\n",
      "Feature Importance scores: First feature: 0.14365248892012078 Second feature: 0.34504713906071044\n",
      "Feature Importance scores: First feature: 0.14928284499495395 Second feature: 0.34423170944079273\n",
      "Feature Importance scores: First feature: 0.15000220831585104 Second feature: 0.3325571866608326\n",
      "Feature Importance scores: First feature: 0.15256864523043914 Second feature: 0.3445155314608205\n",
      "Feature Importance scores: First feature: 0.15396269218854142 Second feature: 0.3446869060828211\n",
      "Feature Importance scores: First feature: 0.14784105240140846 Second feature: 0.3400857418668686\n",
      "Feature Importance scores: First feature: 0.14618045940158295 Second feature: 0.33400739361634324\n",
      "Feature Importance scores: First feature: 0.14693488047202974 Second feature: 0.33968448438369175\n",
      "Feature Importance scores: First feature: 0.14668071506475794 Second feature: 0.3395925105560845\n",
      "Feature Importance scores: First feature: 0.1458293302723592 Second feature: 0.334841527617627\n",
      "Feature Importance scores: First feature: 0.15086634001945018 Second feature: 0.33990685286015704\n",
      "Feature Importance scores: First feature: 0.15025568875801776 Second feature: 0.33218550589131907\n",
      "Feature Importance scores: First feature: 0.14711947233283346 Second feature: 0.342468830688088\n",
      "Feature Importance scores: First feature: 0.14450715051198998 Second feature: 0.3456988606893737\n",
      "Feature Importance scores: First feature: 0.15126766779044795 Second feature: 0.3443896563579509\n",
      "Feature Importance scores: First feature: 0.14953271398278753 Second feature: 0.3372371976112201\n",
      "Feature Importance scores: First feature: 0.15505985479385082 Second feature: 0.3475251406265648\n",
      "Feature Importance scores: First feature: 0.15029818352407262 Second feature: 0.34091888090365796\n",
      "Feature Importance scores: First feature: 0.14873041535096682 Second feature: 0.33697671623180997\n",
      "Feature Importance scores: First feature: 0.15337960335356285 Second feature: 0.3487902357495267\n",
      "Average r2_score without rounding: 0.15453027266541675\n",
      "Average r2_score with rounded prediction to nearest .5 (note: the actual ratings a user makes must be divisable by .5): 0.13160695282014914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#the mlp model is not currently being used\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#feature scaling is not necessary because linear regression converges fast enough\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score\n",
    "#the alternative evaluation metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def test_parameters(nof_runs, layers, train_input_features, test_input_features):\n",
    "    \"\"\"Test_parameters for a number of runs and return performance results\"\"\"\n",
    "    train_inputs = [list(pair) for pair in train_input_features]\n",
    "    test_inputs = [list(pair) for pair in test_input_features]\n",
    "    return average_results(nof_runs, layers, train_inputs, test_inputs)\n",
    "    \n",
    "\n",
    "def average_results(nof_runs, layers, train_inputs, text_inputs):\n",
    "    \"\"\"Average the performance results for a number of models with identical inputs\"\"\"\n",
    "    no_rounding = 0\n",
    "    rounding = 0\n",
    "    for _ in range(nof_runs):\n",
    "        pair = train_and_test(layers, train_inputs, text_inputs)\n",
    "        no_rounding+=pair[0]\n",
    "        rounding+=pair[1]\n",
    "    return float(no_rounding/nof_runs), float(rounding/nof_runs)\n",
    "\n",
    "\n",
    "def train_and_test(layers, train_inputs, test_inputs):\n",
    "    \"\"\"Build, train, and test a model, then return accuracy scores\"\"\"\n",
    "\n",
    "    # nn model (worse performance):\n",
    "    # reg = MLPRegressor(hidden_layer_sizes = layers, solver = \"adam\",  max_iter = 1000)\n",
    "\n",
    "    # linear regression (better performance):\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    #train model\n",
    "    reg.fit(train_inputs, train_users.user_to_target_rating)\n",
    "\n",
    "    #print importance of the different input features to the model\n",
    "    results = permutation_importance(reg, train_inputs, train_users.user_to_target_rating)\n",
    "    importances = results[\"importances_mean\"]\n",
    "    print(\"Feature Importance scores:\", \"First feature:\", importances[0],\"Second feature:\", importances[1])\n",
    "\n",
    "    #make predictions for test inputs\n",
    "    predictions = reg.predict(test_inputs)\n",
    "\n",
    "    #test with and without roundings...\n",
    "    #note: the actual ratings a user makes must be divisable by .5 \n",
    "    rounded_predictions = []\n",
    "    for item in predictions:\n",
    "        rounded_predictions.append(float(round(item*2)/2.0))\n",
    "\n",
    "    #evaluation metric 1:\n",
    "    return(r2_score(test_users.user_to_target_rating, predictions), \n",
    "        r2_score(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "    #evaluation metric 2:\n",
    "    # return(mean_squared_error(test_users.user_to_target_rating, predictions), \n",
    "    #         mean_squared_error(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "\n",
    "\n",
    "# the current test is the average accuracy scores (currently r2_score) for 100 models trained on the same inputs\n",
    "# the hidden layers are (10,10,10) but the linear model is the current model being used which does not user layers\n",
    "# and the highest scoring inputs features (feature_1 and feature_3) are used here\n",
    "\n",
    "avg_scores = test_parameters(100, (10,10,10), \n",
    "    zip(train_users.feature_1, train_users.feature_3),\n",
    "      zip(test_users.feature_2, test_users.feature_3))\n",
    "\n",
    "\n",
    "print(\"Average r2_score without rounding:\",avg_scores[0])\n",
    "print(\"Average r2_score with rounded prediction to nearest .5 (note: the actual ratings a user makes must be divisable by .5):\",avg_scores[1])\n",
    "\n",
    "\n",
    "\n",
    "# misc... \n",
    "# results:\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 20 for svd_full\n",
    "# Average r2_score without rounding:  \n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  \n",
    "\n",
    "# BEST:\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 10 for svd_full\n",
    "# Average r2_score without rounding:  0.15453027266541675\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.13160695282014914\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 5 for svd_full\n",
    "# Average r2_score without rounding:  0.1531792173890736\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.13107484923731846\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = 15 for svd_full\n",
    "# Average r2_score without rounding:  0.14856750114822856\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.13160695282014914\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = (20,10) for svd_full\n",
    "# Average r2_score without rounding:  0.14704697205805803\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.12415750266051795\n",
    "#Note: two different n values leads to worse results...\n",
    "\n",
    "# linear regression, train users with 50-75 ratings, test users with 5-10 ratings, using feature_1 and feature_3, n = (15,10) for svd_full\n",
    "# Average r2_score without rounding:  0.1497370871224573\n",
    "# Average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.12841433132316396\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
