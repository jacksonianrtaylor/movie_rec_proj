{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\the-movies-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "#his cell downloads the data needed for this jupyter notebook from kaggle and stores in the-movies-dataset folder\n",
    "#if the files are already in that folder than this cell does nothing and requires no credentials\n",
    "\n",
    "#Data Soruce Information:\n",
    "#https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?select=movies_metadata.csv\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId    id rating               title  \\\n",
      "6566765      1  1246    5.0        Rocky Balboa   \n",
      "6880303      1  2959    4.0      License to Wed   \n",
      "2083077      1  2762    4.5  Young and Innocent   \n",
      "1492304      1  1968    4.0       Fools Rush In   \n",
      "2638962      1   147    4.5       The 400 Blows   \n",
      "\n",
      "                                                                                                genres  \\\n",
      "6566765                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "6880303                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "2083077                                     [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name': 'Crime'}]   \n",
      "1492304  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "2638962                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                production_companies  \\\n",
      "6566765                                                                                                  [{'name': 'Columbia Pictures', 'id': 5}, {'name': 'Revolution Studios', 'id': 497}, {'name': 'Rogue Marble', 'id': 696}, {'name': 'Metro-Goldwyn-Mayer (MGM)', 'id': 8411}]   \n",
      "6880303  [{'name': 'Village Roadshow Pictures', 'id': 79}, {'name': 'Robert Simonds Productions', 'id': 3929}, {'name': 'Warner Bros.', 'id': 6194}, {'name': 'Phoenix Pictures', 'id': 11317}, {'name': 'Underground', 'id': 49326}, {'name': 'Proposal Productions', 'id': 49327}]   \n",
      "2083077                                                                                                                                                                                                                [{'name': 'Gaumont British Picture Corporation', 'id': 4978}]   \n",
      "1492304                                                                                                                                                                                                                                     [{'name': 'Columbia Pictures', 'id': 5}]   \n",
      "2638962                                                                                                                                 [{'name': 'Les Films du Carrosse', 'id': 53}, {'name': 'Sédif Productions', 'id': 10897}, {'name': 'The Criterion Collection', 'id': 10932}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
      "6566765  [{'id': 276, 'name': 'philadelphia'}, {'id': 396, 'name': 'transporter'}, {'id': 1721, 'name': 'fight'}, {'id': 2038, 'name': \"love of one's life\"}, {'id': 2416, 'name': 'publicity'}, {'id': 2792, 'name': 'boxer'}, {'id': 2968, 'name': 'grave'}, {'id': 3393, 'name': 'tombstone'}, {'id': 3586, 'name': 'tv station'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5167, 'name': 'restaurant owner'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5380, 'name': 'virtual fight'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 10163, 'name': 'cancer'}, {'id': 155464, 'name': 'over-the-hill fighter'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                             [{'id': 1605, 'name': 'new love'}, {'id': 2856, 'name': 'ten commandments'}, {'id': 3582, 'name': 'bride'}, {'id': 3583, 'name': 'bridegroom'}, {'id': 6038, 'name': 'marriage'}, {'id': 6192, 'name': 'relation'}, {'id': 6281, 'name': 'partnership'}, {'id': 6704, 'name': 'civil registry office'}, {'id': 10093, 'name': 'priest'}, {'id': 13027, 'name': 'wedding'}, {'id': 14765, 'name': 'church'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'id': 769, 'name': 'falsely accused'}, {'id': 1655, 'name': 'country house'}, {'id': 9826, 'name': 'murder'}, {'id': 9937, 'name': 'suspense'}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'id': 828, 'name': 'waitress'}, {'id': 1463, 'name': 'culture clash'}, {'id': 9799, 'name': 'romantic comedy'}, {'id': 13149, 'name': 'pregnancy'}]   \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                      [{'id': 6930, 'name': 'fondling'}, {'id': 10183, 'name': 'independent film'}, {'id': 155518, 'name': 'nouvelle vague'}, {'id': 170268, 'name': 'skipping school'}, {'id': 170272, 'name': 'mise en scene'}, {'id': 170273, 'name': 'fingerprinting'}, {'id': 170279, 'name': '\\xa0mugshot'}, {'id': 170286, 'name': 'strict teacher'}, {'id': 170293, 'name': 'montmartre paris'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        cast  \\\n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'cast_id': 24, 'character': 'Rocky Balboa', 'credit_id': '52fe42e9c3a36847f802c61b', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 25, 'character': 'Paulie', 'credit_id': '52fe42e9c3a36847f802c61f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 1, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 26, 'character': 'Rocky Jr.', 'credit_id': '52fe42e9c3a36847f802c623', 'gender': 2, 'id': 16501, 'name': 'Milo Ventimiglia', 'order': 2, 'profile_path': '/maJeS6bA6ku21rSRceISQtwHL2h.jpg'}, {'cast_id': 27, 'character': 'Marie', 'credit_id': '52fe42e9c3a36847f802c627', 'gender': 1, 'id': 16502, 'name': 'Geraldine Hughes', 'order': 3, 'profile_path': '/bTXux3EJq25Fh2ixbet6MjdG3Fb.jpg'}, {'cast_id': 28, 'character': 'Steps', 'credit_id': '52fe42e9c3a36847f802c62b', 'gender': 2, 'id': 16503, 'name': 'James Francis Kelly III', 'order': 4, 'profile_path': '/iZyTQ2UlwNXrqLqPeNHbofFXubP.jpg'}, {'cast_id': 29, 'character': 'Duke', 'credit_id': '52fe42e9c3a36847f802c62f', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 30, 'character': 'L.C.', 'credit_id': '52fe42e9c3a36847f802c633', 'gender': 2, 'id': 16505, 'name': 'A. J. Benza', 'order': 6, 'profile_path': '/5hVinC6C1ZyD7c8EmZFTiEaF7vH.jpg'}, {'cast_id': 31, 'character': 'Adrian', 'credit_id': '52fe42e9c3a36847f802c637', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 7, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 32, 'character': 'Martin', 'credit_id': '52fe42e9c3a36847f802c63b', 'gender': 2, 'id': 16506, 'name': 'Henry G. Sanders', 'order': 8, 'profile_path': '/2SU75g2CAIzGWbgfIlNvKZQhYTZ.jpg'}, {'cast_id': 33, 'character': \"Mason 'The Line' Dixon\", 'credit_id': '52fe42e9c3a36847f802c63f', 'gender': 2, 'id': 16507, 'name': 'Antonio Tarver', 'order': 9, 'profile_path': '/kJEljjHwBvrjoxqcSVntXlejgl1.jpg'}, {'cast_id': 34, 'character': 'Spider Rico', 'credit_id': '52fe42e9c3a36847f802c643', 'gender': 2, 'id': 16508, 'name': 'Pedro Lovell', 'order': 10, 'profile_path': None}, {'cast_id': 35, 'character': 'Isabel', 'credit_id': '52fe42e9c3a36847f802c647', 'gender': 1, 'id': 16509, 'name': 'Ana Gerena', 'order': 11, 'profile_path': None}, {'cast_id': 36, 'character': 'Angie', 'credit_id': '52fe42e9c3a36847f802c64b', 'gender': 1, 'id': 16510, 'name': 'Angela Boyd', 'order': 12, 'profile_path': None}, {'cast_id': 37, 'character': 'Bar Thug', 'credit_id': '52fe42e9c3a36847f802c64f', 'gender': 0, 'id': 16511, 'name': 'Louis Giansante', 'order': 13, 'profile_path': None}, {'cast_id': 38, 'character': \"Lucky's Bartender\", 'credit_id': '52fe42e9c3a36847f802c653', 'gender': 0, 'id': 16512, 'name': 'Maureen Schilling', 'order': 14, 'profile_path': None}, {'cast_id': 40, 'character': 'X-Cell', 'credit_id': '5761db05c3a3682f20000302', 'gender': 2, 'id': 98298, 'name': 'Lahmard J. Tate', 'order': 15, 'profile_path': '/4WcFReePSxyGQJWV5wXGNfY0Y7o.jpg'}]   \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'cast_id': 18, 'character': 'Reverend Frank', 'credit_id': '52fe4376c3a36847f8056039', 'gender': 2, 'id': 2157, 'name': 'Robin Williams', 'order': 0, 'profile_path': '/sojtJyIV3lkUeThD7A2oHNm8183.jpg'}, {'cast_id': 19, 'character': 'Sadie Jones', 'credit_id': '52fe4376c3a36847f805603d', 'gender': 1, 'id': 16855, 'name': 'Mandy Moore', 'order': 1, 'profile_path': '/15sDtRpe301tZWrRYV31wjMuFpx.jpg'}, {'cast_id': 20, 'character': 'Ben Murphy', 'credit_id': '52fe4376c3a36847f8056041', 'gender': 2, 'id': 17697, 'name': 'John Krasinski', 'order': 2, 'profile_path': '/nOWwdZURikW22qo6OUSGFCTukgc.jpg'}, {'cast_id': 21, 'character': 'Carlisle', 'credit_id': '52fe4376c3a36847f8056045', 'gender': 2, 'id': 29020, 'name': 'Eric Christian Olsen', 'order': 3, 'profile_path': '/clbouet8o9IJlUd8WILD0lzHAtG.jpg'}, {'cast_id': 22, 'character': 'Lindsey Jones', 'credit_id': '52fe4376c3a36847f8056049', 'gender': 1, 'id': 15286, 'name': 'Christine Taylor', 'order': 4, 'profile_path': '/99OssnGmgGjduXFA7syxjNqt9tQ.jpg'}, {'cast_id': 23, 'character': 'Choir Boy', 'credit_id': '52fe4376c3a36847f805604d', 'gender': 2, 'id': 216, 'name': 'Josh Flitter', 'order': 5, 'profile_path': '/6RCA8tDWBxIVk9N3IqUjJEAzYGv.jpg'}, {'cast_id': 24, 'character': 'Joel', 'credit_id': '52fe4376c3a36847f8056051', 'gender': 2, 'id': 11827, 'name': 'DeRay Davis', 'order': 6, 'profile_path': '/w2JYPRLwXhNCpxpJc2v4UQYyMv8.jpg'}, {'cast_id': 25, 'character': 'Mr. Jones', 'credit_id': '52fe4376c3a36847f8056055', 'gender': 2, 'id': 21368, 'name': 'Peter Strauss', 'order': 7, 'profile_path': '/ufx1trct43k7UcT4DpoIMPZXi5A.jpg'}, {'cast_id': 26, 'character': 'Grandma Jones', 'credit_id': '52fe4376c3a36847f8056059', 'gender': 1, 'id': 6465, 'name': 'Grace Zabriskie', 'order': 8, 'profile_path': '/ibBabuSM1UyPYFFo0wBXhGbqElk.jpg'}, {'cast_id': 27, 'character': 'Mrs. Jones', 'credit_id': '52fe4376c3a36847f805605d', 'gender': 1, 'id': 29021, 'name': 'Roxanne Hart', 'order': 9, 'profile_path': '/yWGMW6HdhUGT2oIcQ4jmnkw7ZAM.jpg'}, {'cast_id': 28, 'character': 'Shelly', 'credit_id': '5586ee469251417f6f0059c8', 'gender': 1, 'id': 125167, 'name': 'Mindy Kaling', 'order': 10, 'profile_path': '/Agpd4tJyZ95hk74RifjnfnJpn9U.jpg'}, {'cast_id': 30, 'character': 'Expectant Father', 'credit_id': '56c3467cc3a36847c5001f66', 'gender': 2, 'id': 1368801, 'name': 'David Quinlan', 'order': 11, 'profile_path': '/2m75rrBhvOTtdUS9jlKW8GOHCBV.jpg'}, {'cast_id': 31, 'character': 'Judith', 'credit_id': '58e26093c3a36872f600dcf2', 'gender': 1, 'id': 113867, 'name': 'Angela Kinsey', 'order': 12, 'profile_path': '/omLdRLdwMLliVeVIualEnWVhm1a.jpg'}]   \n",
      "2083077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'cast_id': 18, 'character': 'Erica Burgoyne', 'credit_id': '52fe436bc3a36847f8052cd5', 'gender': 1, 'id': 27939, 'name': 'Nova Pilbeam', 'order': 0, 'profile_path': '/l6oHJaRYrVxsvoTSmMS5wIXaei5.jpg'}, {'cast_id': 19, 'character': 'Robert Tisdall', 'credit_id': '52fe436bc3a36847f8052cd9', 'gender': 0, 'id': 27940, 'name': 'Derrick De Marney', 'order': 1, 'profile_path': '/7VRZ7K0EZ50haOlbVr7DHZ5550O.jpg'}, {'cast_id': 20, 'character': 'Col. Burgoyne', 'credit_id': '52fe436bc3a36847f8052cdd', 'gender': 2, 'id': 27929, 'name': 'Percy Marmont', 'order': 2, 'profile_path': '/p3DIyvlxx6B0SVIxcDaPUPlEV0U.jpg'}, {'cast_id': 21, 'character': 'Old Will', 'credit_id': '52fe436bc3a36847f8052ce1', 'gender': 2, 'id': 27941, 'name': 'Edward Rigby', 'order': 3, 'profile_path': '/B7GJ0jPtODqZVgVtZHPtvZl2tO.jpg'}, {'cast_id': 22, 'character': 'Ericas Tante Margaret', 'credit_id': '52fe436bc3a36847f8052ce5', 'gender': 1, 'id': 14304, 'name': 'Mary Clare', 'order': 4, 'profile_path': '/lAdEwCGiSUj9CCMPB4L9X4oujLe.jpg'}, {'cast_id': 23, 'character': 'Det. Insp. Kent', 'credit_id': '52fe436bc3a36847f8052ce9', 'gender': 2, 'id': 7383, 'name': 'John Longden', 'order': 5, 'profile_path': '/rsCoUEx2ThNIz12fBR6vPncCICk.jpg'}, {'cast_id': 24, 'character': 'Guy', 'credit_id': '52fe436bc3a36847f8052ced', 'gender': 2, 'id': 27942, 'name': 'George Curzon', 'order': 6, 'profile_path': None}, {'cast_id': 25, 'character': 'Ericas Onkel Basil', 'credit_id': '52fe436bc3a36847f8052cf1', 'gender': 2, 'id': 14303, 'name': 'Basil Radford', 'order': 7, 'profile_path': '/9STo7Tgdutplo78ZtyeINGWkXUk.jpg'}, {'cast_id': 26, 'character': 'Christine Clay', 'credit_id': '52fe436bc3a36847f8052cf5', 'gender': 1, 'id': 27943, 'name': 'Pamela Carme', 'order': 8, 'profile_path': None}, {'cast_id': 27, 'character': 'Detective Sergeant Miller', 'credit_id': '52fe436bc3a36847f8052cf9', 'gender': 2, 'id': 27944, 'name': 'George Merritt', 'order': 9, 'profile_path': None}, {'cast_id': 28, 'character': 'Henry Briggs', 'credit_id': '52fe436bc3a36847f8052cfd', 'gender': 2, 'id': 27945, 'name': 'J.H. Roberts', 'order': 10, 'profile_path': None}, {'cast_id': 29, 'character': \"Truckfahrer bei Tom's Hat\", 'credit_id': '52fe436bc3a36847f8052d01', 'gender': 2, 'id': 27946, 'name': 'Jerry Verno', 'order': 11, 'profile_path': None}, {'cast_id': 30, 'character': 'Police Sergeant Ruddock', 'credit_id': '52fe436bc3a36847f8052d05', 'gender': 2, 'id': 27947, 'name': 'H.F. Maltby', 'order': 12, 'profile_path': None}, {'cast_id': 31, 'character': 'Police Constable', 'credit_id': '52fe436bc3a36847f8052d09', 'gender': 2, 'id': 27948, 'name': 'John Miller', 'order': 13, 'profile_path': None}]   \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'cast_id': 2, 'character': 'Alex Whitman', 'credit_id': '52fe4327c3a36847f803e629', 'gender': 2, 'id': 14408, 'name': 'Matthew Perry', 'order': 0, 'profile_path': '/oSKEEDXDNnwWdQ68qfDVD6Q7Pxp.jpg'}, {'cast_id': 3, 'character': 'Isabel Fuentes', 'credit_id': '52fe4327c3a36847f803e62d', 'gender': 1, 'id': 3136, 'name': 'Salma Hayek', 'order': 1, 'profile_path': '/u5mg73xKVqm8oT93HoMmsgQHyoK.jpg'}, {'cast_id': 4, 'character': 'Jeff', 'credit_id': '52fe4327c3a36847f803e631', 'gender': 2, 'id': 4602, 'name': 'Jon Tenney', 'order': 2, 'profile_path': '/fiG1bW6DX1szsRDPIYjfIKPQ0kV.jpg'}, {'cast_id': 5, 'character': 'Lanie', 'credit_id': '52fe4327c3a36847f803e635', 'gender': 1, 'id': 6751, 'name': 'Siobhan Fallon', 'order': 3, 'profile_path': '/wVFa8GiY0xdOLFsvGygy9RMtcBc.jpg'}, {'cast_id': 16, 'character': 'Great Grandma', 'credit_id': '52fe4327c3a36847f803e675', 'gender': 1, 'id': 20360, 'name': 'Angelina Torres', 'order': 4, 'profile_path': None}, {'cast_id': 17, 'character': 'Richard Whitman', 'credit_id': '52fe4327c3a36847f803e679', 'gender': 2, 'id': 20361, 'name': 'John Bennett Perry', 'order': 5, 'profile_path': '/bzFhwuXsdZiOHRtBgz4XVELIFYO.jpg'}, {'cast_id': 18, 'character': 'Nan Whitman', 'credit_id': '52fe4327c3a36847f803e67d', 'gender': 1, 'id': 20362, 'name': 'Jill Clayburgh', 'order': 6, 'profile_path': '/twrfhIvbqHuJ7nXVpehvU6nyi6R.jpg'}, {'cast_id': 19, 'character': 'Cathy Stewart', 'credit_id': '52fe4327c3a36847f803e681', 'gender': 1, 'id': 20363, 'name': 'Suzanne Snyder', 'order': 7, 'profile_path': '/90FrTcjJudpeIYUjUzlO6XAmvnt.jpg'}, {'cast_id': 20, 'character': 'Amalia', 'credit_id': '52fe4327c3a36847f803e685', 'gender': 0, 'id': 13029, 'name': 'Anne Betancourt', 'order': 8, 'profile_path': '/6UU5P4DzjJTSBFztIu1nALT2tk0.jpg'}, {'cast_id': 21, 'character': 'Juan Fuentes', 'credit_id': '52fe4327c3a36847f803e689', 'gender': 2, 'id': 4511, 'name': 'Mark Adair-Rios', 'order': 9, 'profile_path': '/rX4d1e5jlF5P73qynjjUzJslB0c.jpg'}, {'cast_id': 22, 'character': 'Judd Marshall', 'credit_id': '52fe4327c3a36847f803e68d', 'gender': 2, 'id': 4171, 'name': 'Stanley DeSantis', 'order': 10, 'profile_path': '/4cHxkhTd7oklyNkdva9WJp0FLrX.jpg'}, {'cast_id': 23, 'character': 'Antonio Fuentes', 'credit_id': '52fe4327c3a36847f803e691', 'gender': 0, 'id': 4665, 'name': 'Josh Cruze', 'order': 11, 'profile_path': '/v3QrQzH0uGV9pd1dNR5Ue6a74qO.jpg'}, {'cast_id': 24, 'character': 'Petra', 'credit_id': '52fe4327c3a36847f803e695', 'gender': 0, 'id': 4666, 'name': 'Angela Lanza', 'order': 12, 'profile_path': '/zmf6TMWMVCdnuUfpgdnioaICk1L.jpg'}, {'cast_id': 25, 'character': 'Phil', 'credit_id': '52fe4327c3a36847f803e699', 'gender': 2, 'id': 4445, 'name': 'Chris Bauer', 'order': 13, 'profile_path': '/3KYVMaGkWTEDQ0T9lsu85pVbP4T.jpg'}, {'cast_id': 26, 'character': 'Chuy', 'credit_id': '577e438f925141440c000d63', 'gender': 0, 'id': 115874, 'name': 'Carlos Gómez', 'order': 14, 'profile_path': '/nBxwoMv1zrhNXyEjYXbcdmAdmF0.jpg'}]   \n",
      "2638962  [{'cast_id': 6, 'character': 'Antoine Doinel', 'credit_id': '52fe421ec3a36847f8005661', 'gender': 2, 'id': 1653, 'name': 'Jean-Pierre Léaud', 'order': 0, 'profile_path': '/dzkPODapVe4CSubEqI9ytTCqnZ7.jpg'}, {'cast_id': 7, 'character': 'Gilberte Doinel', 'credit_id': '52fe421ec3a36847f8005665', 'gender': 1, 'id': 1654, 'name': 'Claire Maurier', 'order': 1, 'profile_path': '/cP1n7zMsMKr77xJeR3CncomxEZ0.jpg'}, {'cast_id': 8, 'character': 'Julien Doinel', 'credit_id': '52fe421ec3a36847f8005669', 'gender': 0, 'id': 1655, 'name': 'Albert Rémy', 'order': 2, 'profile_path': '/6b8eyIXAV6oA5eX6ltc3hF7ZB3d.jpg'}, {'cast_id': 10, 'character': 'Mr. Bigey', 'credit_id': '52fe421ec3a36847f8005673', 'gender': 2, 'id': 1658, 'name': 'Georges Flamant', 'order': 3, 'profile_path': '/lQwmtPsFWME63x5M7IRF6g8bLrR.jpg'}, {'cast_id': 11, 'character': 'René', 'credit_id': '52fe421ec3a36847f8005677', 'gender': 0, 'id': 1659, 'name': 'Patrick Auffay', 'order': 4, 'profile_path': None}, {'cast_id': 12, 'character': 'Director of the school', 'credit_id': '52fe421ec3a36847f800567b', 'gender': 0, 'id': 1660, 'name': 'Robert Beauvais', 'order': 5, 'profile_path': None}, {'cast_id': 13, 'character': 'Mme Bigey', 'credit_id': '52fe421ec3a36847f800567f', 'gender': 0, 'id': 1661, 'name': 'Yvonne Claudie', 'order': 6, 'profile_path': None}, {'cast_id': 14, 'character': 'English Teacher', 'credit_id': '52fe421ec3a36847f8005683', 'gender': 0, 'id': 1662, 'name': 'Pierre Repp', 'order': 7, 'profile_path': '/1AUhiNGBAR0C6AU9iK1IXBs3QTz.jpg'}, {'cast_id': 17, 'character': 'French Teacher', 'credit_id': '52fe421ec3a36847f8005693', 'gender': 0, 'id': 1656, 'name': 'Guy Decomble', 'order': 8, 'profile_path': '/34iexAuqI1asyFounbSXSCFphen.jpg'}, {'cast_id': 20, 'character': 'Betrand Mauricet', 'credit_id': '52fe421ec3a36847f8005697', 'gender': 0, 'id': 1077237, 'name': 'Daniel Couturier', 'order': 9, 'profile_path': None}, {'cast_id': 21, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569b', 'gender': 0, 'id': 1077238, 'name': 'François Nocher', 'order': 10, 'profile_path': None}, {'cast_id': 22, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569f', 'gender': 2, 'id': 150939, 'name': 'Richard Kanayan', 'order': 11, 'profile_path': '/vCMDk3ifj2vJKZYCISXT3K6DYXF.jpg'}, {'cast_id': 23, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a3', 'gender': 0, 'id': 1077239, 'name': 'Renaud Fontanarosa', 'order': 12, 'profile_path': None}, {'cast_id': 24, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a7', 'gender': 0, 'id': 1077240, 'name': 'Michel Girard', 'order': 13, 'profile_path': None}, {'cast_id': 25, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056ab', 'gender': 0, 'id': 71997, 'name': 'Serge Moati', 'order': 14, 'profile_path': '/wccRQKHrX61sH4WlOtM1KBP4qaq.jpg'}, {'cast_id': 26, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056af', 'gender': 0, 'id': 1077241, 'name': 'Bernard Abbou', 'order': 15, 'profile_path': None}, {'cast_id': 27, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b3', 'gender': 0, 'id': 1077242, 'name': 'Jean-François Bergouignan', 'order': 16, 'profile_path': None}, {'cast_id': 28, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b7', 'gender': 0, 'id': 1077243, 'name': 'Michel Lesignor', 'order': 17, 'profile_path': None}, {'cast_id': 31, 'character': 'Man in Street', 'credit_id': '5457f0a1c3a3683993000156', 'gender': 2, 'id': 24299, 'name': 'Jean-Claude Brialy', 'order': 18, 'profile_path': '/g3kkYcAvq90tALMErxmdAIcIXsE.jpg'}, {'cast_id': 32, 'character': 'Woman with Dog', 'credit_id': '5457f0bec3a36839a0000144', 'gender': 1, 'id': 14812, 'name': 'Jeanne Moreau', 'order': 19, 'profile_path': '/uHJnVwCzehEoz0mIlwN7xkymql8.jpg'}, {'cast_id': 33, 'character': 'Man in Funfair', 'credit_id': '5457f0d3c3a368399300015b', 'gender': 2, 'id': 34613, 'name': 'Philippe de Broca', 'order': 20, 'profile_path': '/yrvmXE2SJBX659r2Y7eWwlmwfYd.jpg'}, {'cast_id': 34, 'character': 'Man in Funfair', 'credit_id': '5457f0e5c3a368399d00014c', 'gender': 0, 'id': 1650, 'name': 'François Truffaut', 'order': 21, 'profile_path': '/apCCV99N3FqB5NsEPqOzetlkprL.jpg'}]   \n",
      "\n",
      "                                                                               tagline  \\\n",
      "6566765                                                  It ain't over 'til it's over.   \n",
      "6880303                                   First came love... then came Reverend Frank.   \n",
      "2083077                                                          A Brilliant Melodrama   \n",
      "1492304  What if finding the love of your life meant changing the life that you loved?   \n",
      "2638962                                            Angel faces hell-bent for violence.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        overview  \n",
      "6566765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When he loses a highly publicized virtual boxing match to ex-champ Rocky Balboa, reigning heavyweight titleholder, Mason Dixon retaliates by challenging Rocky to a nationally televised, 10-round exhibition bout. To the surprise of his son and friends, Rocky agrees to come out of retirement and face an opponent who's faster, stronger and thirty years his junior.  \n",
      "6880303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Newly engaged, Ben and Sadie can't wait to start their life together and live happily ever after. However Sadie's family church's Reverend Frank won't bless their union until they pass his patented, \"foolproof\" marriage prep course consisting of outrageous classes, outlandish homework assignments and some outright invasion of privacy.  \n",
      "2083077  Derrick De Marney finds himself in a 39 Steps situation when he is wrongly accused of murder. While a fugitive from the law, De Marney is helped by heroine Nova Pilbeam, who three years earlier had played the adolescent kidnap victim in Hitchcock's The Man Who Knew Too Much. The obligatory \"fish out of water\" scene, in which the principals are briefly slowed down by a banal everyday event, occurs during a child's birthday party. The actual villain, whose identity is never in doubt (Hitchcock made thrillers, not mysteries) is played by George Curzon, who suffers from a twitching eye. Curzon's revelation during an elaborate nightclub sequence is a Hitchcockian tour de force, the sort of virtuoso sequence taken for granted in these days of flexible cameras and computer enhancement, but which in 1937 took a great deal of time, patience and talent to pull off. Released in the US as The Girl Was Young, Young and Innocent was based on a novel by Josephine Tey.  \n",
      "1492304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alex Whitman (Matthew Perry) is a designer from New York City who is sent to Las Vegas to supervise the construction of a nightclub that his firm has been hired to build. Alex is a straight-laced WASP-ish type who, while enjoying a night on the town, meets Isabel Fuentes (Salma Hayek), a free-spirited Mexican-American photographer. Alex and Isabel are overtaken by lust at first sight and end up sp  \n",
      "2638962                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For young Parisian boy Antoine Doinel, life is one difficult situation after another. Surrounded by inconsiderate adults, including his neglectful parents, Antoine spends his days with his best friend, Rene, trying to plan for a better life. When one of their schemes goes awry, Antoine ends up in trouble with the law, leading to even more conflicts with unsympathetic authority figures.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#seed for consistent results across runtimes\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "#This cell is for combining certain data from the necessary csv files into a single dataframe (complete)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "movies_full = pd.read_csv('./the-movies-dataset/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={\"tagline\": \"string\", \"id\":\"string\", 'genres':\"string\", \"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\", \"production_companies\" :\"string\"})\n",
    "movies_full = movies_full.dropna()\n",
    "movies_full = movies_full.reset_index()\n",
    "\n",
    "\n",
    "#filter rows of empty data from movies_full on the columns: \"genres\", \"production_companies\"\n",
    "drop_indices = []\n",
    "for i in range(len(movies_full)):\n",
    "    len_1 = len(movies_full.iloc[i].loc[\"genres\"])                   \n",
    "    if(movies_full.iloc[i].loc[\"genres\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "        continue\n",
    "    len_2 = len(movies_full.iloc[i].loc[\"production_companies\"])\n",
    "    if(movies_full.iloc[i].loc[\"production_companies\"][len_2 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)    \n",
    "        continue   \n",
    "\n",
    "movies_full = movies_full.drop(labels=drop_indices, axis = 0)\n",
    "movies_full = movies_full.reset_index(names = \"index_1\")\n",
    "\n",
    "\n",
    "ratings = pd.read_csv('./the-movies-dataset/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"), dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})\n",
    "ratings = ratings.rename(columns={\"movieId\": \"id\"})\n",
    "ratings.dropna()\n",
    "ratings = ratings.reset_index(names = \"index_2\")\n",
    "\n",
    "\n",
    "keywords = pd.read_csv('./the-movies-dataset/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})\n",
    "keywords.dropna()\n",
    "keywords = keywords.reset_index()\n",
    "\n",
    "#filter rows of empty data from keyword on the keywords column\n",
    "drop_indices = []\n",
    "for i in range(len(keywords)):\n",
    "    len_1 = len(keywords.iloc[i].loc[\"keywords\"])                   \n",
    "    if(keywords.iloc[i].loc[\"keywords\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "\n",
    "keywords = keywords.drop(labels=drop_indices, axis = 0)\n",
    "keywords = keywords.reset_index(names = \"index_3\")\n",
    "\n",
    "\n",
    "credits = pd.read_csv(\"./the-movies-dataset/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})\n",
    "credits.dropna()\n",
    "credits = credits.reset_index()\n",
    "\n",
    "#filter rows of empty data from credits on the cast column \n",
    "drop_indices = []\n",
    "for i in range(len(credits)):\n",
    "    len_1 = len(credits.iloc[i].loc[\"cast\"])                   \n",
    "    if(credits.iloc[i].loc[\"cast\"][len_1 -2:] == \"[]\"):\n",
    "        drop_indices.append(i)\n",
    "\n",
    "credits = credits.drop(labels=drop_indices, axis = 0)\n",
    "credits = credits.reset_index(names = \"index_4\")\n",
    "\n",
    "\n",
    "#default merge is inner: this only keeps movies that have the id existing in both dataframes...\n",
    "complete =  pd.merge(movies_full, ratings, on =\"id\")\n",
    "complete =  pd.merge(complete,keywords, on =\"id\")\n",
    "complete  = pd.merge(complete,credits, on =\"id\")\n",
    "\n",
    "\n",
    "complete = complete.sort_values(by = 'userId')\n",
    "\n",
    "\n",
    "#use only certain types of columns\n",
    "complete  = complete.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "#for testing\n",
    "print(complete.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 260788\n",
      "gaps [6, 8, 1, 4, 20]\n",
      "Total number of users: 17360\n",
      "Number of users chosen: 5260\n",
      "Average number of ratings for the number of users chosen: 181.55029473283895\n",
      "seconds taken:  1364.9479970932007\n",
      "minutes taken:  22.74913328488668\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# seed for consistent results across runtime\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "\n",
    "def condition(array):\n",
    "    \"\"\"\"\n",
    "    originally used to filter out the rows of data with empty entries for certain columns\n",
    "    a method simlair to this is used in the previous cell above to reduce the number of checks\n",
    "    \"\"\"\n",
    "    length = len(array[4])\n",
    "    if(array[4][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[5])\n",
    "    if(array[5][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[6])\n",
    "    if(array[6][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[7])\n",
    "    if(array[7][length-2:] == \"[]\"):\n",
    "        return False   \n",
    "    #this is this unecessary with the dropNa function in the previous cell:\n",
    "    # length = len(array[8])\n",
    "    # if(array[8][length-4:]==\"<NA>\"):\n",
    "    #     return False\n",
    "    # length = len(array[9])\n",
    "    # if(array[9][length-4:]==\"<NA>\"):\n",
    "    #     return False \n",
    "    return True\n",
    "\n",
    "\n",
    "def populate_names(item):\n",
    "    \"\"\"used to extract names from the syntax of certain data entries\"\"\"\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    cnt = 0\n",
    "    for item in jsons:\n",
    "        if(cnt == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        cnt += 1\n",
    "    return names\n",
    "\n",
    "\n",
    "def provide_data(array):\n",
    "    \"\"\"extract data from row of complete_array\"\"\"\n",
    "    movie_data = []\n",
    "    movie_data.append(int(array[0]))\n",
    "    movie_data.append(int(array[1]))\n",
    "    movie_data.append(float(array[2]))\n",
    "    movie_data.append(array[3])  \n",
    "\n",
    "    movie_data.append(populate_names(array[4]))\n",
    "    movie_data.append(populate_names(array[5]))\n",
    "    movie_data.append(populate_names(array[6]))\n",
    "    movie_data.append(populate_names(array[7]))\n",
    "\n",
    "    movie_data.append(str(array[8]))\n",
    "    movie_data.append(str(array[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "#LOOK: \n",
    "#https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "#iterating over pandas objects is slow!!!\n",
    "#should check for other datastructures below\n",
    "\n",
    "\n",
    "#LOOK:\n",
    "#there is an issue with this!!!\n",
    "#complete.loc[complete['userId'] == user_id] is too slow since it observes the entire dataframe\n",
    "#should try to make use of the fact that rows are in user order\n",
    "#there can be an initial list that is the copy of the dataframe...\n",
    "#another idea...\n",
    "#need to populate gaps and list_of_user_ids...\n",
    "\n",
    "\n",
    "\n",
    "list_of_user_ids = list(complete[\"userId\"].unique())\n",
    "complete_list = complete.values.tolist()\n",
    "\n",
    "print(\"number of users:\", len(list_of_user_ids))\n",
    "\n",
    "#the complete list of user rows without ratings of the same movie more than once\n",
    "complete_list_no_dups = []\n",
    "#distinquish the users the row belongs to \n",
    "last_id = -1\n",
    "#the set of movies that a user has rated\n",
    "#used to prevent later ratings of a movie that the user has already rated\n",
    "movie_set = set()\n",
    "#how many rows a single user takes up for each user in the order of their occurance\n",
    "gaps = []\n",
    "#added to gaps when all of a users rows have been counted\n",
    "gap_len = 0\n",
    "#prevent adding gap_len to gaps until a real user has been iterated over\n",
    "first_it = True\n",
    "\n",
    "#populate above variables while omitting movies that already have a rating...\n",
    "#in respect to each user\n",
    "for row in complete_list:\n",
    "    if last_id != row[0]:\n",
    "        movie_set= set()\n",
    "        complete_list_no_dups.append(row)\n",
    "        movie_set.add(row[1])\n",
    "        if not first_it:    \n",
    "            gaps.append(gap_len)\n",
    "        gap_len = 1\n",
    "\n",
    "        first_it = False\n",
    "    else:\n",
    "        if row[1] not in movie_set:\n",
    "            complete_list_no_dups.append(row)\n",
    "            gap_len+=1\n",
    "            movie_set.add(row[1])\n",
    "    last_id = row[0]\n",
    "\n",
    "\n",
    "#add the last gap_len\n",
    "gaps.append(gap_len)\n",
    "\n",
    "#LOOK: should there be trials with train users with a high number of ratings\n",
    "#and test users with a low number of ratings???\n",
    "\n",
    "\n",
    "#min_number_of_users = 100 is used for the extended training and testing \n",
    "#but users that have a minimum number of ratings of 100 are rare...\n",
    "#Another senario is that any number of ratings can be used for test and train users\n",
    "#this was tested and the average numbef or rating for a given user was around 30\n",
    "min_number_of_users = 100\n",
    "index = 0\n",
    "complete_list_index = 0\n",
    "\n",
    "#removes users that dont fit the bounds for the acceptable number of users\n",
    "for _ in range(len(gaps)):\n",
    "    if gaps[index] < min_number_of_users:\n",
    "        temp = gaps[index]\n",
    "        del gaps[index]\n",
    "        del list_of_user_ids[index]\n",
    "        del complete_list_no_dups[complete_list_index:complete_list_index+temp]\n",
    "    else:\n",
    "        complete_list_index+=gaps[index]\n",
    "        index+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this is a list for all users to rows of transformed data for each movie they rated\n",
    "user_to_data = []\n",
    "\n",
    "#this is the total number of users in the whole dataset\n",
    "#total number of users for min number of ratings 100: (17378)???\n",
    "#lOOK: What is the total number of users in the dataset and with at least 100 ratings\n",
    "total_nof_users = len(list_of_user_ids)\n",
    "print(\"Total number of users:\", total_nof_users)\n",
    "\n",
    "\n",
    "#this is the number of desired users out of the total_nof_users:\n",
    "#note: this number is not exact to the number of users because it is applied in a random operation...\n",
    "#note: extra 250 is used to account for error with a target of 5000 users: 5250\n",
    "nof_users_aproximation =  5250\n",
    "\n",
    "#index of the current movie row for the current users\n",
    "index  = 0\n",
    "\n",
    "#this is collected for insight\n",
    "avg = 0.0\n",
    "cnt = 0.0\n",
    "\n",
    "\n",
    "#LOOK: alternate method:\n",
    "#1. randomly choose 5000 unqiue indices from the indices below the length of total_nof_users and make a list of them\n",
    "#2. iterate through the list of 5000 unqiue indices\n",
    "#3. when an indice is reached need to move index to the corerpsodnign movie row\n",
    "#this seems more complicated thanth method below!!!\n",
    "\n",
    "\n",
    "#populate user_to_data from complete_array\n",
    "for i in range(0, total_nof_users):\n",
    "    #generate a random float to determine a pass for the user\n",
    "    if (random.random()<float(nof_users_aproximation/total_nof_users)):\n",
    "        user_to_data.append([])\n",
    "        last_index = len(user_to_data) -1\n",
    "        for j in range(index, len(complete_list_no_dups)):\n",
    "            if complete_list_no_dups[j][0] == list_of_user_ids[i]:\n",
    "                #orginally: the condition function checked if the movie row had missing values for certain columns and...\n",
    "                #omitted the movie if it had missing values   \n",
    "                #a more efficient method is used instead in the second cell  \n",
    "                # if(condition(complete_array[j])):\n",
    "                    #transform data...\n",
    "                transformed = provide_data(complete_list_no_dups[j])\n",
    "                user_to_data[last_index].append(transformed)    \n",
    "            else:\n",
    "                avg += len(user_to_data[last_index])\n",
    "                cnt+=1\n",
    "                index = j\n",
    "                break           \n",
    "    else:\n",
    "        index += gaps[i]\n",
    "\n",
    "\n",
    "\n",
    "#Go through user_to_data and re-index the users in list order since certain users were omitted\n",
    "#this is for simplicity and readability \n",
    "for i in range(len(user_to_data)):\n",
    "    for j in range(len(user_to_data[i])):\n",
    "        user_to_data[i][j][0] = i\n",
    "\n",
    "\n",
    "#How many users are in the final user_to_data \n",
    "print(\"Number of users chosen:\", len(user_to_data))\n",
    "\n",
    "#average number of ratings per users\n",
    "#note: omits the very last user but this makes little difference\n",
    "print(\"Average number of ratings for the number of users chosen:\", float(avg/cnt))\n",
    "\n",
    "\n",
    "print(\"Minutes taken: \", float((time.time()-start_time)/60))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MISC below: \n",
    "\n",
    "#time to complete Total number of users with 100 min user rating limit: ~50 minutes\n",
    "#number of users with more than 100 ratings: 17378\n",
    "#average number of ratings: 181.84876560971398\n",
    "#is this higher than the other method\n",
    "\n",
    "#average number of ratings:\n",
    "#with 1000 users: 185.972\n",
    "#with 5250 users: 184.63586233124167\n",
    "\n",
    "#the average number of ratings of the complete list of users shuod be around 30: ~6 minutes\n",
    "#30.25708986940731 average rating with (12941 out of 260788) users chosen\n",
    "\n",
    "#the next block can be removing all movies that have already been previously rated\n",
    "#problem: if the number of ratings dips below 2 then there are issues later\n",
    "#solution: need to do this process before filtering min number of users\n",
    "\n",
    "# Number of users chosen: 5260\n",
    "# Average number of ratings for the number of users chosen: 181.55029473283895\n",
    "# seconds taken:  1364.9479970932007\n",
    "# minutes taken:  22.74913328488668\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in a constructed_data/constructed_data.csv file so that cells below can run without running this cell and above\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, 'constructed_data')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    for i in range(len(user_to_data)):\n",
    "        writer.writerows(user_to_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a starting point if the data is already saved to the constructed_data/constructed_data.csv\n",
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructed_data/constructed_data.csv\", 'r', encoding=\"utf-8\") as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seed for consistent results across runtime\n",
    "#used with every random function except for the last cell where a certain number of models are tested and accumulated with identiacal test and train data\n",
    "seed_int = 2\n",
    "random.seed(seed_int)\n",
    "\n",
    "#user to data rows \n",
    "user_to_data = []\n",
    "user_to_data_train = []\n",
    "user_to_data_test = []\n",
    "user_id = -1\n",
    "\n",
    "#note: works when row[0] is also an index\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        user_id = row[0]\n",
    "        user_to_data.append([row])\n",
    "    else:\n",
    "        user_to_data[int(row[0])].append(row)\n",
    "\n",
    "\n",
    "#these both can be increased for consistency as long as there is enough data\n",
    "#with the current configuration there are 4204 users\n",
    "#this can be increased by increasing the desired_nof_users_before_filter parameter above\n",
    "for i in range(5000):\n",
    "    index = random.randint(0, len(user_to_data)-1)\n",
    "    user_to_data_train.append(user_to_data[index])\n",
    "    del user_to_data[index]\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    index = random.randint(0, len(user_to_data_train)-1)\n",
    "    user_to_data_test.append(user_to_data_train[index])\n",
    "    del user_to_data_train[index]\n",
    "\n",
    "\n",
    "del user_to_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_1 to target comparison (train):\n",
      "[3.5492957746478875, 3.436, 3.201388888888889, 3.0930232558139537, 3.547169811320755]\n",
      "[4.0, 4.0, 4.0, 4.0, 4.0]\n",
      "Feature_1 to target comparison (test):\n",
      "[3.442553191489362, 3.8625, 4.030769230769231, 3.3138686131386863, 3.172043010752688]\n",
      "[4.0, 4.5, 4.0, 4.5, 3.0]\n",
      "Feature_2 to target comparison (train):\n",
      "[3.3913145457695006, 3.421093924060176, 3.0992801105014403, 3.170779617769549, 3.5361874203425403]\n",
      "[4.0, 4.0, 4.0, 4.0, 4.0]\n",
      "Feature_2 to target comparison (test):\n",
      "[3.4130044784167977, 3.8678220640284144, 4.040675013795052, 3.3714347353723984, 3.2305045403735138]\n",
      "[4.0, 4.5, 4.0, 4.5, 3.0]\n",
      "Feature_3 to target comparison (train):\n",
      "[3.586664028637569, 3.464455663106878, 3.8962783724112273, 3.9887608040685083, 3.476283698917307]\n",
      "[4.0, 4.0, 4.0, 4.0, 4.0]\n",
      "Feature_3 to target comparison (test):\n",
      "[3.794273965015983, 3.81797383375422, 3.1125607784767197, 3.8430984065841782, 2.734028543430622]\n",
      "[4.0, 4.5, 4.0, 4.5, 3.0]\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "import json\n",
    "from ordered_set import OrderedSet\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#the linalg is used from numpy instea of scipy\n",
    "import numpy as np\n",
    "#the version from numpy is used instead\n",
    "from scipy import linalg\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.linalg import sqrtm\n",
    "import math\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "\n",
    "class user_type_vars():\n",
    "    def __init__(self):\n",
    "        #for each user of the user type, a dictionary of movie_id to the movies rating for each movie the user watched\n",
    "        self.user_to_movie_id_to_rating = [] \n",
    "\n",
    "        #for each user, a random choice of movie_id from all the movies the user watched to represent the target movie\n",
    "        self.user_to_target_movie_id = [] \n",
    "\n",
    "        #for each user, this is the index of the users target movie in the order of movies_in_order\n",
    "        #(train_users only)\n",
    "        self.user_to_target_index_full = [] \n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set \n",
    "        #missing ratings and target movie ratings are set to that movies average rating\n",
    "        #(train_users only)\n",
    "        self.user_to_ratings_full = [] \n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set\n",
    "        #the movies mean rating is subtracted from each rating\n",
    "        #missing ratings and target movie ratings are set to zero\n",
    "        #(train_users only)\n",
    "        self.user_to_ratings_full_transform = []\n",
    "\n",
    "        #for every movie watched by the user_type, a list of ratings\n",
    "        self.movie_id_to_ratings = dict()\n",
    "\n",
    "        #this is a set of every unique target movie for the user_type\n",
    "        self.target_movies = set()\n",
    "\n",
    "        #all the movies in order of the movies ratings for each user of the user type\n",
    "        self.movies_in_order = OrderedSet()\n",
    "\n",
    "        #model input features x\n",
    "        self.feature_1 = []\n",
    "        self.feature_2 = []\n",
    "        self.feature_3 = []\n",
    "\n",
    "        #model output feature y\n",
    "        self.user_to_target_rating  = [] \n",
    "\n",
    "\n",
    "#for most of the variables above a train and test version is used\n",
    "train_users = user_type_vars()\n",
    "test_users = user_type_vars()\n",
    "\n",
    "\n",
    "#This is the users average rating not including the chosen target movie\n",
    "#this is for all train users in order followed by the test users in order\n",
    "#(this not being used currently)\n",
    "user_to_average_rating = []\n",
    "\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def load_feature_1_and_2(target_movies, movies_in_order, user_to_data, movie_id_to_ratings, user_to_movie_id_to_rating, user_to_target_movie_id, user_to_target_rating, feature_1, feature_2):\n",
    "   \n",
    "    #these are used to calculate the overall train rating\n",
    "    #this is used to fill in rating for movies that are only target movies (they dont have ratings)\n",
    "    overall_rating_sum = 0\n",
    "    overall_rating_count = 0\n",
    "\n",
    "    for i in range(len(user_to_data)):\n",
    "        movie_id_to_words = dict()\n",
    "        movie_id_to_rating = dict()\n",
    "        cnt = 0\n",
    "        total =0\n",
    "        rand_int = random.randint(0, len(user_to_data[i])-1)\n",
    "        for movie_data in user_to_data[i]:\n",
    "            if cnt == rand_int:    \n",
    "                target_movies.add(movie_data[1])\n",
    "                user_to_target_movie_id.append(movie_data[1])\n",
    "            else:\n",
    "                overall_rating_sum += float(movie_data[2])\n",
    "                overall_rating_count += 1\n",
    "                total += float(movie_data[2])\n",
    "\n",
    "                #this only runs when the movie is not the target movie because\n",
    "                #the target movies are thought to be the movies whose rating is to be predicted...\n",
    "                #not ratings that are already on record\n",
    "                if movie_data[1] in movie_id_to_ratings.keys():\n",
    "                    movie_id_to_ratings[movie_data[1]].append(float(movie_data[2]))\n",
    "                else:\n",
    "                    movie_id_to_ratings[movie_data[1]] = [float(movie_data[2])]\n",
    "\n",
    "            movie_string = \"\"\n",
    "\n",
    "            #use this to apply all the text data and combine in to a single list of words (repeats allowed):\n",
    "            # for index in range (3,len(movie_data)):\n",
    "            #     if(index!= len(movie_data)-1):\n",
    "            #         movie_string+= movie_data[index]+\" \"\n",
    "            #     else:\n",
    "            #         movie_string+= movie_data[index]\n",
    "\n",
    "\n",
    "            #all of the text columns and a few combinations of certain text columns were tested but they were not helpful in...\n",
    "            #increasing model perfromance (see below)\n",
    "\n",
    "\n",
    "            #Use this truncated code to only include the genre column strings:\n",
    "            movie_string = movie_data[4]\n",
    "\n",
    "            #lematization and conversion to lists\n",
    "            cleaned = remove_stopwords(movie_string)\n",
    "            cleaned = [wnl.lemmatize(word) for word in cleaned.split(\" \")]\n",
    "            cleaned = [word[:-1] for word in cleaned if word.endswith(\".\")] + [word for word in cleaned if not word.endswith(\".\")]\n",
    "\n",
    "            movie_id_to_words[movie_data[1]] = cleaned\n",
    "            movie_id_to_rating[movie_data[1]] = float(movie_data[2])\n",
    "            movies_in_order.add(movie_data[1])\n",
    "            cnt+=1\n",
    "\n",
    "        user_to_movie_id_to_rating.append(movie_id_to_rating)\n",
    "        #when a user has only a single rating the division by zero occurs\n",
    "        #this is a reason why every user must have at least 2 ratings\n",
    "        user_to_average_rating.append(float(total/(cnt-1)))\n",
    "\n",
    "        #the current users list of words from all the movies they rated\n",
    "        users_words_in_order = OrderedSet()\n",
    "        for movie_id in movie_id_to_words.keys():\n",
    "            for word in movie_id_to_words[movie_id]:\n",
    "                users_words_in_order.add(word)\n",
    "\n",
    "\n",
    "        word_counts = [] #list of word counts for the users_words_in_order for each movie (excluding target)\n",
    "        target_word_counts = [] #word counts for the users_words_in_order for the target movie\n",
    "\n",
    "        #these are the scaled versions of variables directly above\n",
    "        #these are only relevant with user averages scalings opposed to movie average scaling...\n",
    "        #note: scaling also happens automatically below\n",
    "        word_counts_transformed = []\n",
    "        target_word_counts_transformed = []\n",
    "\n",
    "        #word count sums for each word in users_words_in_order for each user\n",
    "        sums = dict()\n",
    "\n",
    "        #for each movie the user watched record the wordcount for each word in users_words_in_order\n",
    "        for movie_id in movie_id_to_words.keys():\n",
    "            if movie_id != user_to_target_movie_id[-1]:\n",
    "                temp_dict = Counter(movie_id_to_words[movie_id])\n",
    "                temp_list = []\n",
    "                # sum = 0\n",
    "                for word in users_words_in_order:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])\n",
    "                        # sum+=temp_dict[word]\n",
    "                        if word in sums.keys():\n",
    "                            sums[word] += temp_dict[word] \n",
    "                        else:\n",
    "                            sums[word] = temp_dict[word] \n",
    "                    else:\n",
    "                        temp_list.append(0) \n",
    "                        if word not in sums.keys():\n",
    "                            sums[word] = 0  \n",
    "\n",
    "                word_counts.append(temp_list)  \n",
    "\n",
    "                # append to word_counts_transformed:\n",
    "                # avg = float(sum/len(users_words_in_order))\n",
    "                # word_counts_transformed.append([x - avg for x in temp_list])\n",
    "            else:\n",
    "\n",
    "                temp_dict = Counter(movie_id_to_words[movie_id])\n",
    "                temp_list = []\n",
    "                # sum = 0\n",
    "                for word in users_words_in_order:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])\n",
    "                        # sum+=temp_dict[word]\n",
    "                        if word in sums.keys():\n",
    "                            sums[word] += temp_dict[word] \n",
    "                        else:\n",
    "                            sums[word] = temp_dict[word]             \n",
    "                    else:\n",
    "                        temp_list.append(0) \n",
    "                        if word not in sums.keys():\n",
    "                            sums[word] = 0 \n",
    "\n",
    "                target_word_counts = temp_list\n",
    "\n",
    "                # set target_word_counts_transformed:\n",
    "                # avg = float(sum/len(users_words_in_order))\n",
    "                # target_word_counts_transformed = [x - avg for x in temp_list]\n",
    "        \n",
    "\n",
    "        complete_word_counts = word_counts.copy()\n",
    "        complete_word_counts.append(target_word_counts)\n",
    "        transformed_word_counts = TfidfTransformer().fit_transform(complete_word_counts).toarray()\n",
    "\n",
    "\n",
    "        #populate ratings with the exception of the target rating \n",
    "        #also record the users target movie rating \n",
    "\n",
    "\n",
    "        #need to test if any movie id is rated twice!!!\n",
    "        somecount = 0\n",
    "\n",
    "        ratings = []\n",
    "        for movie_id in movie_id_to_rating.keys():\n",
    "            if movie_id != user_to_target_movie_id[-1]:\n",
    "                ratings.append(movie_id_to_rating[movie_id])\n",
    "            else:\n",
    "                #this signifies the ratings to be predicted by the model\n",
    "                user_to_target_rating.append(movie_id_to_rating[movie_id])\n",
    "                somecount+1\n",
    "        \n",
    "        #need to test if any movie id is rated twice!!!\n",
    "        if(somecount>1):\n",
    "            print(\"duplicate movie id\")\n",
    "\n",
    "        \n",
    "\n",
    "        #potential functions of predict:\n",
    "        #return the average ratings from movies that are a like the target movie with cosine similairity\n",
    "        #unweighted average of all of the users movies\n",
    "        #weighted average of all the users movies (weights are based on cossine similarity)\n",
    "        def predict():\n",
    "            item_1 = 0 \n",
    "            item_2 = 0\n",
    "\n",
    "            # option 1: \n",
    "            # cosine_sim = linear_kernel(X = transformed_word_counts[0:-1],Y = [transformed_word_counts[-1]])\n",
    "            #or\n",
    "            #cosine_sim = cosine_similarity(X = transformed_word_counts[0:-1],Y = [transformed_word_counts[-1]])\n",
    "            # cosine_sim = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "            # combined = zip(cosine_sim, ratings)\n",
    "            # combined = sorted(combined, key=lambda x: x[0], reverse=True)\n",
    "            # avg = 0\n",
    "            # nof = 10.0\n",
    "            # for i in range(int(nof)):\n",
    "            #     avg += combined[i][1]\n",
    "            # item_2 =  float(avg/nof)\n",
    "\n",
    "            #option 2:\n",
    "            #note: item 1 is a higher performing feature than any of the other methods in the function\n",
    "            sum = 0\n",
    "            for i in range(len(ratings)):\n",
    "                sum += ratings[i]\n",
    "\n",
    "            \n",
    "            #there is potential for this to be zero when a user has only a single rating\n",
    "            #this effectively means that every user must have at least 2 ratings\n",
    "            item_1 = float(sum/len(ratings))\n",
    "\n",
    "            #option 3:\n",
    "            #when the svd function is used:\n",
    "            # cosine_sim = cosine_similarity(X = transformed_word_counts[0:-1],Y = [transformed_word_counts[-1]])\n",
    "\n",
    "            #when the svd function is not used:\n",
    "            cosine_sim = linear_kernel(X = transformed_word_counts[0:-1],Y = [transformed_word_counts[-1]])\n",
    "            cosine_sim = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            item_2 = item_1\n",
    "            for i in range(len(ratings)):\n",
    "                numerator += float(cosine_sim[i]*ratings[i])\n",
    "                denominator += cosine_sim[i]\n",
    "            \n",
    "            if denominator != 0:\n",
    "                item_2 = float(numerator/denominator)\n",
    "        \n",
    "            return (item_1, item_2)\n",
    "        \n",
    "        \n",
    "        items = predict()\n",
    "\n",
    "        feature_1.append(items[0])\n",
    "        feature_2.append(items[1])\n",
    "            \n",
    "        \n",
    "    return float(overall_rating_sum/overall_rating_count)\n",
    "\n",
    "\n",
    "overall_average_train = load_feature_1_and_2(train_users.target_movies, train_users.movies_in_order, user_to_data_train, train_users.movie_id_to_ratings, train_users.user_to_movie_id_to_rating, \n",
    "                                                         train_users.user_to_target_movie_id, train_users.user_to_target_rating, train_users.feature_1, train_users.feature_2)\n",
    "\n",
    "\n",
    "load_feature_1_and_2(test_users.target_movies, test_users.movies_in_order, user_to_data_test, test_users.movie_id_to_ratings, test_users.user_to_movie_id_to_rating, \n",
    "               test_users.user_to_target_movie_id,\n",
    "               test_users.user_to_target_rating, test_users.feature_1, test_users.feature_2)\n",
    "\n",
    "\n",
    "def pre_svd(movie_id_to_average_rating, movies_in_order, user_to_ratings_full_transform, user_to_ratings_full, user_to_target_index_full, \n",
    "               user_to_movie_id_to_rating, user_to_target_movie_id):\n",
    "    for i in range(len(user_to_movie_id_to_rating)):\n",
    "        ratings = []\n",
    "        transformed_ratings = []\n",
    "        index = 0\n",
    "\n",
    "\n",
    "        #what if there is no movie_id == user_to_target_movie_id[i]\n",
    "        #this can happen when a test users target movie is not in the train_users.movies_in_order...\n",
    "\n",
    "        #solution:\n",
    "\n",
    "        #this could be run once with only train_movies\n",
    "        #and then used to populate the train svd\n",
    "        #and then extract the prediction to train the model\n",
    "\n",
    "\n",
    "        #then again with all movies train_movies + test_movies\n",
    "        #then used to populate the full svd\n",
    "        #and then extract the prediction to test model\n",
    "\n",
    "\n",
    "        #note: movie_id_to_average_rating_train shouold onyl be used for the train run of this function\n",
    "        #for the test version of the this movie_id_to_average_rating_full should be used\n",
    "\n",
    "        for movie_id in movies_in_order:\n",
    "            if movie_id == user_to_target_movie_id[i]:\n",
    "                user_to_target_index_full.append(index)\n",
    "                ratings.append(movie_id_to_average_rating[movie_id])\n",
    "                #note: per item averages are being subtracted here instead of per user averages\n",
    "                transformed_ratings.append(movie_id_to_average_rating[movie_id] - movie_id_to_average_rating[movie_id]) \n",
    "\n",
    "            #note: It should not matter that user_to_movie_id_to_rating includes movie id equal to user_to_target_movie_id[i] since the above condition will flag before this condition\n",
    "            elif movie_id in user_to_movie_id_to_rating[i].keys():\n",
    "                ratings.append(user_to_movie_id_to_rating[i][movie_id])\n",
    "                #note: per item averages are being subtracted here instead of per user averages\n",
    "                transformed_ratings.append(user_to_movie_id_to_rating[i][movie_id] - movie_id_to_average_rating[movie_id])\n",
    "            else:\n",
    "                ratings.append(movie_id_to_average_rating[movie_id])\n",
    "                #note: per item averages are being subtracted here instead of per user averages\n",
    "                transformed_ratings.append(movie_id_to_average_rating[movie_id] - movie_id_to_average_rating[movie_id])\n",
    "            index +=1\n",
    "        user_to_ratings_full.append(ratings)\n",
    "        user_to_ratings_full_transform.append(transformed_ratings)\n",
    "\n",
    "\n",
    "#note: before passing to this function the data is normalized about the average movie ratings (not average user ratings)\n",
    "#each user train and test users have a single rating that needs to be trained against in the train case\n",
    "#and predicted in the test case\n",
    "\n",
    "#the svd can be applied to the combined data of the train and test sets\n",
    "#both movies that the user didn't watch and movies that should be guesses are...\n",
    "#transformed to have a value of zero before svd\n",
    "\n",
    "#the movie columns are taken from the train dataset...\n",
    "#senario: suppose a test user has a rating of a movie not part of the train set and it is not the target movie (ignore it)\n",
    "#senario: suppose a test user has a rating of a movie not part of the train set and it is the target movie (guess the rating instead of using svd)\n",
    "\n",
    "#...Once the UsV is created...\n",
    "#take the rating from the new UsV for the user row and movie column for the target movie\n",
    "#other option: cossine similairty on the U ignoring other test users\n",
    "\n",
    "\n",
    "def svd_full(user_to_ratings_full_transform, n, movie_id_to_average_rating):\n",
    "    #is this the source the random variation???\n",
    "    U, s, V = np.linalg.svd(user_to_ratings_full_transform, full_matrices=False)\n",
    "    \n",
    "    #simplify ratings to n features\n",
    "    s=np.diag(s)\n",
    "    s=s[0:n,0:n]\n",
    "    U=U[:,0:n]\n",
    "    V=V[0:n,:]\n",
    "\n",
    "    #reconstrcut to a new array\n",
    "    Us = np.dot(U,s)\n",
    "    UsV = np.dot(Us,V)\n",
    "    \n",
    "\n",
    "    #the keys of movie_id_to_ratings is in the same order of movies_in_order and therefore so is movie_id_to_average_rating_train\n",
    "    x = np.tile(list(movie_id_to_average_rating.values()), (UsV.shape[0],1))\n",
    "\n",
    "    #this tranforms the UsV row by row into the original rating scale (1-5)\n",
    "    UsV = UsV + x\n",
    "\n",
    "    #be consistent with data structures...\n",
    "    return list(UsV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Unlike the other feature loading functions it only makes sense to run this once since...\n",
    "#there is significantly difference processes for train and test data\n",
    "def load_feature_3():\n",
    "\n",
    "    movie_id_to_average_rating_train = dict()\n",
    "    movie_id_to_average_rating_full = dict()\n",
    "\n",
    "    #is all_movies_in_order still in order???\n",
    "    all_movies_in_order = train_users.movies_in_order|test_users.movies_in_order\n",
    "\n",
    "\n",
    "    #this is used to populate movie_id_to_average_rating_train and movie_id_to_average_rating_full...\n",
    "    #without skipping the movies that are target movies and not in (movies not in test_users.movie_id_to_ratings or train_users.movie_id_to_ratings)\n",
    "    for movie in all_movies_in_order:\n",
    "        temp = 0\n",
    "        if(movie in train_users.movie_id_to_ratings and movie in test_users.movie_id_to_ratings):\n",
    "            for rating in train_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_train[movie] = float(temp/len(train_users.movie_id_to_ratings[movie])) \n",
    "\n",
    "            for rating in test_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_full[movie] = float(temp/(len(train_users.movie_id_to_ratings[movie])+len(test_users.movie_id_to_ratings[movie])))  \n",
    "\n",
    "        elif(movie in train_users.movie_id_to_ratings):\n",
    "            for rating in train_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_train[movie] = float(temp/len(train_users.movie_id_to_ratings[movie]))\n",
    "            movie_id_to_average_rating_full[movie] = movie_id_to_average_rating_train[movie]\n",
    "\n",
    "        elif(movie in test_users.movie_id_to_ratings):\n",
    "            #is the movie a target movie in the train set that isn't in train_users.movies_id_to_ratings???         \n",
    "            if(movie in train_users.target_movies):\n",
    "                movie_id_to_average_rating_train[movie] = overall_average_train\n",
    "\n",
    "            for rating in test_users.movie_id_to_ratings[movie]:\n",
    "                temp+=rating\n",
    "            movie_id_to_average_rating_full[movie] = float(temp/len(test_users.movie_id_to_ratings[movie]))\n",
    "        else:\n",
    "            #is the movie a target movie in the train set that isn't in train_users.movie_id_to_ratings???\n",
    "            #is the movie a target movie in the test set that isn't in test_users.movie_id_to_ratings???\n",
    "            if(movie in train_users.target_movies):\n",
    "                movie_id_to_average_rating_train[movie] = overall_average_train\n",
    "                movie_id_to_average_rating_full[movie] = overall_average_train\n",
    "            else:\n",
    "                movie_id_to_average_rating_full[movie] = overall_average_train\n",
    "   \n",
    "\n",
    "    #for all users in train and then test order\n",
    "    full_user_to_ratings_full_transform = []\n",
    "    full_user_to_ratings_full = []\n",
    "    full_user_to_target_index_full = []\n",
    "\n",
    "\n",
    "    #this makes a comprehensive list of the train data followed by the test users data\n",
    "    full_user_to_movie_id_to_rating  = train_users.user_to_movie_id_to_rating + test_users.user_to_movie_id_to_rating\n",
    "    full_user_to_target_movie_id = train_users.user_to_target_movie_id + test_users.user_to_target_movie_id\n",
    "\n",
    "\n",
    "    #This is used to scale the ratings and store in train_users.user_to_ratings_full_transform and full_user_to_ratings_full_transform\n",
    "    #This will transform the target movie ratings and unrated movies to zero\n",
    "\n",
    "    #run once with only train data to train model\n",
    "    #run again with train and test data to evaluate model...\n",
    "\n",
    "    pre_svd(movie_id_to_average_rating_train, train_users.movies_in_order, train_users.user_to_ratings_full_transform, train_users.user_to_ratings_full, train_users.user_to_target_index_full, \n",
    "                train_users.user_to_movie_id_to_rating, train_users.user_to_target_movie_id)\n",
    "\n",
    "    pre_svd(movie_id_to_average_rating_full, all_movies_in_order, full_user_to_ratings_full_transform, full_user_to_ratings_full, full_user_to_target_index_full, \n",
    "                full_user_to_movie_id_to_rating, full_user_to_target_movie_id)\n",
    "\n",
    "\n",
    "    #In practice, there is a train and a test set, the train set is what the database has on record\n",
    "    #the test data will usually be data that hasn't been seen before that can include any number of test users\n",
    "\n",
    "    #When train_users.user_to_ratings_full_transform is used as the input of the svd function, \n",
    "    #svd_out_train is used to produce predictions used to train the model\n",
    "\n",
    "    #When full_user_to_ratings_full_transform is used as the input of the svd function,\n",
    "    #svd_out_full is used to produce predictions used to test the model\n",
    "    \n",
    "\n",
    "    #n = 20 proved to be close to the highest performing constant for the above configuration\n",
    "    svd_out_train = svd_full(train_users.user_to_ratings_full_transform, 20, movie_id_to_average_rating_train)\n",
    "    svd_out_full = svd_full(full_user_to_ratings_full_transform, 20, movie_id_to_average_rating_full)\n",
    "\n",
    "    #here the smaller svd provides predictions used to train the mlp model\n",
    "    for i in range(len(train_users.user_to_ratings_full_transform)):\n",
    "        train_users.feature_3.append(svd_out_train[i][train_users.user_to_target_index_full[i]])\n",
    "\n",
    "    #here the larger svd provides predictions used to test the mlp model\n",
    "    for i in range(len(full_user_to_ratings_full_transform) - len(train_users.user_to_ratings_full_transform)):\n",
    "        test_users.feature_3.append(svd_out_full[i+len(train_users.user_to_ratings_full_transform)][full_user_to_target_index_full[i+len(train_users.user_to_ratings_full_transform)]])\n",
    "\n",
    "load_feature_3()\n",
    "\n",
    "\n",
    "#this is just used to see how the features aproximate the\n",
    "print(\"Feature_1 to target comparison (train):\")\n",
    "print(train_users.feature_1[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_1 to target comparison (test):\")\n",
    "print(test_users.feature_1[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_2 to target comparison (train):\")\n",
    "print(train_users.feature_2[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_2 to target comparison (test):\")\n",
    "print(test_users.feature_2[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_3 to target comparison (train):\")\n",
    "print(train_users.feature_3[0:5])\n",
    "print(train_users.user_to_target_rating[0:5])\n",
    "\n",
    "print(\"Feature_3 to target comparison (test):\")\n",
    "print(test_users.feature_3[0:5])\n",
    "print(test_users.user_to_target_rating[0:5])\n",
    "\n",
    "\n",
    "#this might not be worth the deletion!!!\n",
    "del user_to_data_train\n",
    "del user_to_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.27801114]\n",
      "Feature Importances:  [0.28174239]\n",
      "Feature Importances:  [0.28963231]\n",
      "Feature Importances:  [0.28858317]\n",
      "Feature Importances:  [0.27693054]\n",
      "Feature Importances:  [0.2743256]\n",
      "Feature Importances:  [0.28069541]\n",
      "Feature Importances:  [0.27421776]\n",
      "Feature Importances:  [0.28900726]\n",
      "Feature Importances:  [0.2925632]\n",
      "Feature Importances:  [0.27277945]\n",
      "Feature Importances:  [0.2807576]\n",
      "Feature Importances:  [0.28400971]\n",
      "Feature Importances:  [0.28442598]\n",
      "Feature Importances:  [0.2842645]\n",
      "Feature Importances:  [0.29246741]\n",
      "Feature Importances:  [0.28656351]\n",
      "Feature Importances:  [0.29703024]\n",
      "Feature Importances:  [0.27748278]\n",
      "Feature Importances:  [0.2832791]\n",
      "Feature Importances:  [0.28734202]\n",
      "Feature Importances:  [0.2753373]\n",
      "Feature Importances:  [0.28668609]\n",
      "Feature Importances:  [0.27931031]\n",
      "Feature Importances:  [0.27887718]\n",
      "Feature Importances:  [0.2812503]\n",
      "Feature Importances:  [0.2824563]\n",
      "Feature Importances:  [0.27727884]\n",
      "Feature Importances:  [0.28647372]\n",
      "Feature Importances:  [0.27917298]\n",
      "Feature Importances:  [0.27683737]\n",
      "Feature Importances:  [0.27839123]\n",
      "Feature Importances:  [0.28689651]\n",
      "Feature Importances:  [0.28684331]\n",
      "Feature Importances:  [0.28648162]\n",
      "Feature Importances:  [0.28629592]\n",
      "Feature Importances:  [0.28672328]\n",
      "Feature Importances:  [0.28234685]\n",
      "Feature Importances:  [0.27901843]\n",
      "Feature Importances:  [0.28468378]\n",
      "Feature Importances:  [0.28400042]\n",
      "Feature Importances:  [0.27844165]\n",
      "Feature Importances:  [0.28357793]\n",
      "Feature Importances:  [0.2760822]\n",
      "Feature Importances:  [0.28313932]\n",
      "Feature Importances:  [0.27629307]\n",
      "Feature Importances:  [0.28626775]\n",
      "Feature Importances:  [0.28898135]\n",
      "Feature Importances:  [0.28303574]\n",
      "Feature Importances:  [0.27744177]\n",
      "Feature Importances:  [0.27584407]\n",
      "Feature Importances:  [0.28445444]\n",
      "Feature Importances:  [0.28309811]\n",
      "Feature Importances:  [0.28529358]\n",
      "Feature Importances:  [0.28736031]\n",
      "Feature Importances:  [0.28164578]\n",
      "Feature Importances:  [0.28335474]\n",
      "Feature Importances:  [0.28174396]\n",
      "Feature Importances:  [0.28165823]\n",
      "Feature Importances:  [0.28319239]\n",
      "Feature Importances:  [0.28256702]\n",
      "Feature Importances:  [0.27796966]\n",
      "Feature Importances:  [0.29067778]\n",
      "Feature Importances:  [0.27839266]\n",
      "Feature Importances:  [0.28453062]\n",
      "Feature Importances:  [0.27939602]\n",
      "Feature Importances:  [0.29038127]\n",
      "Feature Importances:  [0.27485821]\n",
      "Feature Importances:  [0.28749343]\n",
      "Feature Importances:  [0.28295091]\n",
      "Feature Importances:  [0.28126126]\n",
      "Feature Importances:  [0.28256365]\n",
      "Feature Importances:  [0.2874336]\n",
      "Feature Importances:  [0.27946229]\n",
      "Feature Importances:  [0.27977873]\n",
      "Feature Importances:  [0.27490117]\n",
      "Feature Importances:  [0.28464477]\n",
      "Feature Importances:  [0.28427096]\n",
      "Feature Importances:  [0.27617326]\n",
      "Feature Importances:  [0.28473932]\n",
      "Feature Importances:  [0.28152442]\n",
      "Feature Importances:  [0.27483988]\n",
      "Feature Importances:  [0.285641]\n",
      "Feature Importances:  [0.28557978]\n",
      "Feature Importances:  [0.28500358]\n",
      "Feature Importances:  [0.28127189]\n",
      "Feature Importances:  [0.28144002]\n",
      "Feature Importances:  [0.2819311]\n",
      "Feature Importances:  [0.27418376]\n",
      "Feature Importances:  [0.28160464]\n",
      "Feature Importances:  [0.27473716]\n",
      "Feature Importances:  [0.28249694]\n",
      "Feature Importances:  [0.27814416]\n",
      "Feature Importances:  [0.27847881]\n",
      "Feature Importances:  [0.28269507]\n",
      "Feature Importances:  [0.27418467]\n",
      "Feature Importances:  [0.28673886]\n",
      "Feature Importances:  [0.28309917]\n",
      "Feature Importances:  [0.27744931]\n",
      "Feature Importances:  [0.29157452]\n",
      "average r2_score without rounding:  0.16069330580025995\n",
      "average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5):  0.1414093528438838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#average the performance results for a number of models with identical inputs\n",
    "def test_parameters(nof_runs, layers, train_input_features, test_input_features):\n",
    "    train_inputs = [list(pair) for pair in train_input_features]\n",
    "    test_inputs = [list(pair) for pair in test_input_features]\n",
    "    return average_results(nof_runs, layers, train_inputs, test_inputs)\n",
    "    \n",
    "\n",
    "def average_results(nof_runs, layers, train_inputs, text_inputs):\n",
    "    no_rounding = 0\n",
    "    rounding = 0\n",
    "    for _ in range(nof_runs):\n",
    "        #best performance analysis is analysis_1\n",
    "        pair = analysis_1(layers, train_inputs, text_inputs)\n",
    "        no_rounding+=pair[0]\n",
    "        rounding+=pair[1]\n",
    "    return float(no_rounding/nof_runs), float(rounding/nof_runs)\n",
    "\n",
    "\n",
    "#no scaling (best performance):\n",
    "def analysis_1(layers, train_inputs, test_inputs):\n",
    "    # build and train model\n",
    "    # nn model (worse performance)\n",
    "    # reg = MLPRegressor(hidden_layer_sizes = layers, solver = \"adam\",  max_iter = 1000)\n",
    "    # linear regression (better performance)\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(train_inputs, train_users.user_to_target_rating)\n",
    "\n",
    "    #show importance of different inputs features to the model\n",
    "    results = permutation_importance(reg, train_inputs, train_users.user_to_target_rating)\n",
    "    print(\"Feature Importances: \", results[\"importances_mean\"])\n",
    "\n",
    "    #make predictions\n",
    "    predictions = reg.predict(test_inputs)\n",
    "\n",
    "    #test with and without roundings...\n",
    "    #in a sense this is logical sense becasue the actual ratings a user makes must be divisable by .5 \n",
    "    rounded_predictions = []\n",
    "    for item in predictions:\n",
    "        rounded_predictions.append(float(round(item*2)/2.0))\n",
    "\n",
    "    #evaluation metric 1:\n",
    "    return(r2_score(test_users.user_to_target_rating, predictions), \n",
    "        r2_score(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "    #evaluation metric 2:\n",
    "    # return(mean_squared_error(test_users.user_to_target_rating, predictions), \n",
    "    #         mean_squared_error(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "#scale inputs and targets:\n",
    "def analysis_2(layers, train_inputs, test_inputs):\n",
    "    #scale input features\n",
    "    train_inputs_scaled = StandardScaler().fit_transform(train_inputs)\n",
    "\n",
    "    #scale target values\n",
    "    target_scalar = StandardScaler()\n",
    "    true_rating_train_scaled = target_scalar.fit_transform(np.reshape(train_users.user_to_target_rating, (-1, 1)))\n",
    "    true_rating_train_scaled = np.reshape(true_rating_train_scaled, len(true_rating_train_scaled))\n",
    "\n",
    "    #build and train model\n",
    "    reg = MLPRegressor(hidden_layer_sizes = layers, solver = \"adam\",  max_iter = 1000)\n",
    "    reg.fit(train_inputs_scaled, true_rating_train_scaled)\n",
    "\n",
    "    #show importance of different inputs features...\n",
    "    results = permutation_importance(reg, train_inputs_scaled,true_rating_train_scaled)\n",
    "    print(results[\"importances_mean\"])\n",
    "\n",
    "    #scale inputs features\n",
    "    test_inputs_scaled = StandardScaler().fit_transform(test_inputs)\n",
    "\n",
    "    #predict the scaled verison of ouptuts\n",
    "    scaled_predictions = reg.predict(test_inputs_scaled)\n",
    "\n",
    "    #get actual predictions from scaled predictions...\n",
    "    predictions = target_scalar.inverse_transform(scaled_predictions.reshape(-1, 1))\n",
    "    predictions = list(predictions.reshape(len(predictions)))\n",
    "\n",
    "    #test with and without roundings...\n",
    "    #in a sense this is logical sense becasue the actual ratings a user makes must be divisable by .5 \n",
    "    rounded_predictions = []\n",
    "    for item in predictions:\n",
    "        rounded_predictions.append(float(round(item*2)/2.0))\n",
    "\n",
    "    #evaluation metric 1:\n",
    "    return(r2_score(test_users.user_to_target_rating, predictions), \n",
    "        r2_score(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "    #evaluation metric 2:\n",
    "    # return(mean_squared_error(test_users.user_to_target_rating, predictions), \n",
    "    #         mean_squared_error(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "#only scale inputs:\n",
    "def analysis_3(layers, train_inputs, test_inputs):\n",
    "    #scale input features\n",
    "    train_inputs_scaled = StandardScaler().fit_transform(train_inputs)\n",
    "\n",
    "    #build and train model\n",
    "    reg = MLPRegressor(hidden_layer_sizes = layers, solver = \"adam\",  max_iter = 1000)\n",
    "    reg.fit(train_inputs_scaled, train_users.user_to_target_rating)\n",
    "\n",
    "    #show importance of different inputs features...\n",
    "    results = permutation_importance(reg, train_inputs_scaled, train_users.user_to_target_rating)\n",
    "    print(results[\"importances_mean\"])\n",
    "\n",
    "    #scale inputs features\n",
    "    test_inputs_scaled = StandardScaler().fit_transform(test_inputs)\n",
    "\n",
    "    #predict the scaled verison of ouptuts\n",
    "    predictions = reg.predict(test_inputs_scaled)\n",
    "\n",
    "    #test with and without roundings...\n",
    "    #in a sense this is logical sense becasue the actual ratings a user makes must be divisable by .5 \n",
    "    rounded_predictions = []\n",
    "    for item in predictions:\n",
    "        rounded_predictions.append(float(round(item*2)/2.0))\n",
    "\n",
    "    #evaluation metric 1:\n",
    "    return(r2_score(test_users.user_to_target_rating, predictions), \n",
    "        r2_score(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "    #evaluation metric 2:\n",
    "    # return(mean_squared_error(test_users.user_to_target_rating, predictions), \n",
    "    #         mean_squared_error(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "\n",
    "\n",
    "#the current test is the average of the r2 scores for 100 different models trained on the same input\n",
    "#the hidden layers are (10,10,10) and the best combination of inputs features(feature_2 and feature_3) are used\n",
    "\n",
    "\n",
    "\n",
    "avg_scores = test_parameters(100, (10,10,10), \n",
    "    zip(train_users.feature_2),\n",
    "      zip(test_users.feature_2))\n",
    "\n",
    "\n",
    "print(\"average r2_score without rounding: \",avg_scores[0])\n",
    "print(\"average r2_score with rounded prediction to nearest .5 (note: actual users ratings must be divisibl by .5): \",avg_scores[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#don't remove this until readme explains results (they are iuumportant result to the conclusion):\n",
    "\n",
    "#with linear regression:\n",
    "#with cossine similarity:\n",
    "\n",
    "#feature_2 and feature_3:\n",
    "#(0.3749823647027071, 0.348993902575555)\n",
    "#(0.3749823647027071, 0.348993902575555)\n",
    "\n",
    "#feature_1 and feature_3: \n",
    "#(0.37665923268552526, 0.35436777366278627)\n",
    "#(0.37665923268552526, 0.35436777366278627)\n",
    "\n",
    "\n",
    "#with linear regression:\n",
    "#with linear_kernel:\n",
    "\n",
    "#feature_2 and feature_3:\n",
    "#(0.3749823647027071, 0.348993902575555)...\n",
    "\n",
    "#feature_1 and feature_3: \n",
    "#(0.37665923268552526, 0.35436777366278627)...\n",
    "#(0.3692252282147528, 0.35771948109887597)\n",
    "\n",
    "\n",
    "\n",
    "#with nn model:\n",
    "#feature_2 and feature_3:\n",
    "#(0.368986238493678, 0.34709385529828507)\n",
    "#feature_1 and feature_3: \n",
    "#(0.3692192733203262, 0.34905915672447185)\n",
    "\n",
    "\n",
    "#feature 1 and 3:\n",
    "#average r2_score without rounding:  0.4393485303942193\n",
    "\n",
    "#feature 2 and 3:\n",
    "#average r2_score without rounding:  0.43574994324307864\n",
    "\n",
    "#feature 1:\n",
    "#average r2_score without rounding:  0.17208657031405555\n",
    "\n",
    "#feature 2:\n",
    "#average r2_score without rounding: 0.16069330580025995"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
