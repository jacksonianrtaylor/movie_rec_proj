{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId    id rating               title  \\\n",
      "8830418      1  2959    4.0      License to Wed   \n",
      "1690638      1  1968    4.0       Fools Rush In   \n",
      "2343877      1  2762    4.5  Young and Innocent   \n",
      "2943547      1   147    4.5       The 400 Blows   \n",
      "8434697      1  1246    5.0        Rocky Balboa   \n",
      "\n",
      "                                                                                                genres  \\\n",
      "8830418                                                                 [{'id': 35, 'name': 'Comedy'}]   \n",
      "1690638  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name': 'Comedy'}, {'id': 10749, 'name': 'Romance'}]   \n",
      "2343877                                     [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name': 'Crime'}]   \n",
      "2943547                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "8434697                                                                  [{'id': 18, 'name': 'Drama'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                production_companies  \\\n",
      "8830418  [{'name': 'Village Roadshow Pictures', 'id': 79}, {'name': 'Robert Simonds Productions', 'id': 3929}, {'name': 'Warner Bros.', 'id': 6194}, {'name': 'Phoenix Pictures', 'id': 11317}, {'name': 'Underground', 'id': 49326}, {'name': 'Proposal Productions', 'id': 49327}]   \n",
      "1690638                                                                                                                                                                                                                                     [{'name': 'Columbia Pictures', 'id': 5}]   \n",
      "2343877                                                                                                                                                                                                                [{'name': 'Gaumont British Picture Corporation', 'id': 4978}]   \n",
      "2943547                                                                                                                                 [{'name': 'Les Films du Carrosse', 'id': 53}, {'name': 'SÃ©dif Productions', 'id': 10897}, {'name': 'The Criterion Collection', 'id': 10932}]   \n",
      "8434697                                                                                                  [{'name': 'Columbia Pictures', 'id': 5}, {'name': 'Revolution Studios', 'id': 497}, {'name': 'Rogue Marble', 'id': 696}, {'name': 'Metro-Goldwyn-Mayer (MGM)', 'id': 8411}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
      "8830418                                                                                                                                                                                                                                                                                                                                             [{'id': 1605, 'name': 'new love'}, {'id': 2856, 'name': 'ten commandments'}, {'id': 3582, 'name': 'bride'}, {'id': 3583, 'name': 'bridegroom'}, {'id': 6038, 'name': 'marriage'}, {'id': 6192, 'name': 'relation'}, {'id': 6281, 'name': 'partnership'}, {'id': 6704, 'name': 'civil registry office'}, {'id': 10093, 'name': 'priest'}, {'id': 13027, 'name': 'wedding'}, {'id': 14765, 'name': 'church'}]   \n",
      "1690638                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'id': 828, 'name': 'waitress'}, {'id': 1463, 'name': 'culture clash'}, {'id': 9799, 'name': 'romantic comedy'}, {'id': 13149, 'name': 'pregnancy'}]   \n",
      "2343877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'id': 769, 'name': 'falsely accused'}, {'id': 1655, 'name': 'country house'}, {'id': 9826, 'name': 'murder'}, {'id': 9937, 'name': 'suspense'}]   \n",
      "2943547                                                                                                                                                                                                                                                                                                                                                                      [{'id': 6930, 'name': 'fondling'}, {'id': 10183, 'name': 'independent film'}, {'id': 155518, 'name': 'nouvelle vague'}, {'id': 170268, 'name': 'skipping school'}, {'id': 170272, 'name': 'mise en scene'}, {'id': 170273, 'name': 'fingerprinting'}, {'id': 170279, 'name': '\\xa0mugshot'}, {'id': 170286, 'name': 'strict teacher'}, {'id': 170293, 'name': 'montmartre paris'}]   \n",
      "8434697  [{'id': 276, 'name': 'philadelphia'}, {'id': 396, 'name': 'transporter'}, {'id': 1721, 'name': 'fight'}, {'id': 2038, 'name': \"love of one's life\"}, {'id': 2416, 'name': 'publicity'}, {'id': 2792, 'name': 'boxer'}, {'id': 2968, 'name': 'grave'}, {'id': 3393, 'name': 'tombstone'}, {'id': 3586, 'name': 'tv station'}, {'id': 4487, 'name': 'boxing match'}, {'id': 4610, 'name': 'comeback'}, {'id': 4613, 'name': 'training'}, {'id': 5167, 'name': 'restaurant owner'}, {'id': 5378, 'name': 'world champion'}, {'id': 5379, 'name': 'challenger'}, {'id': 5380, 'name': 'virtual fight'}, {'id': 6066, 'name': 'defeat'}, {'id': 6067, 'name': 'victory'}, {'id': 10163, 'name': 'cancer'}, {'id': 155464, 'name': 'over-the-hill fighter'}]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        cast  \\\n",
      "8830418                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'cast_id': 18, 'character': 'Reverend Frank', 'credit_id': '52fe4376c3a36847f8056039', 'gender': 2, 'id': 2157, 'name': 'Robin Williams', 'order': 0, 'profile_path': '/sojtJyIV3lkUeThD7A2oHNm8183.jpg'}, {'cast_id': 19, 'character': 'Sadie Jones', 'credit_id': '52fe4376c3a36847f805603d', 'gender': 1, 'id': 16855, 'name': 'Mandy Moore', 'order': 1, 'profile_path': '/15sDtRpe301tZWrRYV31wjMuFpx.jpg'}, {'cast_id': 20, 'character': 'Ben Murphy', 'credit_id': '52fe4376c3a36847f8056041', 'gender': 2, 'id': 17697, 'name': 'John Krasinski', 'order': 2, 'profile_path': '/nOWwdZURikW22qo6OUSGFCTukgc.jpg'}, {'cast_id': 21, 'character': 'Carlisle', 'credit_id': '52fe4376c3a36847f8056045', 'gender': 2, 'id': 29020, 'name': 'Eric Christian Olsen', 'order': 3, 'profile_path': '/clbouet8o9IJlUd8WILD0lzHAtG.jpg'}, {'cast_id': 22, 'character': 'Lindsey Jones', 'credit_id': '52fe4376c3a36847f8056049', 'gender': 1, 'id': 15286, 'name': 'Christine Taylor', 'order': 4, 'profile_path': '/99OssnGmgGjduXFA7syxjNqt9tQ.jpg'}, {'cast_id': 23, 'character': 'Choir Boy', 'credit_id': '52fe4376c3a36847f805604d', 'gender': 2, 'id': 216, 'name': 'Josh Flitter', 'order': 5, 'profile_path': '/6RCA8tDWBxIVk9N3IqUjJEAzYGv.jpg'}, {'cast_id': 24, 'character': 'Joel', 'credit_id': '52fe4376c3a36847f8056051', 'gender': 2, 'id': 11827, 'name': 'DeRay Davis', 'order': 6, 'profile_path': '/w2JYPRLwXhNCpxpJc2v4UQYyMv8.jpg'}, {'cast_id': 25, 'character': 'Mr. Jones', 'credit_id': '52fe4376c3a36847f8056055', 'gender': 2, 'id': 21368, 'name': 'Peter Strauss', 'order': 7, 'profile_path': '/ufx1trct43k7UcT4DpoIMPZXi5A.jpg'}, {'cast_id': 26, 'character': 'Grandma Jones', 'credit_id': '52fe4376c3a36847f8056059', 'gender': 1, 'id': 6465, 'name': 'Grace Zabriskie', 'order': 8, 'profile_path': '/ibBabuSM1UyPYFFo0wBXhGbqElk.jpg'}, {'cast_id': 27, 'character': 'Mrs. Jones', 'credit_id': '52fe4376c3a36847f805605d', 'gender': 1, 'id': 29021, 'name': 'Roxanne Hart', 'order': 9, 'profile_path': '/yWGMW6HdhUGT2oIcQ4jmnkw7ZAM.jpg'}, {'cast_id': 28, 'character': 'Shelly', 'credit_id': '5586ee469251417f6f0059c8', 'gender': 1, 'id': 125167, 'name': 'Mindy Kaling', 'order': 10, 'profile_path': '/Agpd4tJyZ95hk74RifjnfnJpn9U.jpg'}, {'cast_id': 30, 'character': 'Expectant Father', 'credit_id': '56c3467cc3a36847c5001f66', 'gender': 2, 'id': 1368801, 'name': 'David Quinlan', 'order': 11, 'profile_path': '/2m75rrBhvOTtdUS9jlKW8GOHCBV.jpg'}, {'cast_id': 31, 'character': 'Judith', 'credit_id': '58e26093c3a36872f600dcf2', 'gender': 1, 'id': 113867, 'name': 'Angela Kinsey', 'order': 12, 'profile_path': '/omLdRLdwMLliVeVIualEnWVhm1a.jpg'}]   \n",
      "1690638                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'cast_id': 2, 'character': 'Alex Whitman', 'credit_id': '52fe4327c3a36847f803e629', 'gender': 2, 'id': 14408, 'name': 'Matthew Perry', 'order': 0, 'profile_path': '/oSKEEDXDNnwWdQ68qfDVD6Q7Pxp.jpg'}, {'cast_id': 3, 'character': 'Isabel Fuentes', 'credit_id': '52fe4327c3a36847f803e62d', 'gender': 1, 'id': 3136, 'name': 'Salma Hayek', 'order': 1, 'profile_path': '/u5mg73xKVqm8oT93HoMmsgQHyoK.jpg'}, {'cast_id': 4, 'character': 'Jeff', 'credit_id': '52fe4327c3a36847f803e631', 'gender': 2, 'id': 4602, 'name': 'Jon Tenney', 'order': 2, 'profile_path': '/fiG1bW6DX1szsRDPIYjfIKPQ0kV.jpg'}, {'cast_id': 5, 'character': 'Lanie', 'credit_id': '52fe4327c3a36847f803e635', 'gender': 1, 'id': 6751, 'name': 'Siobhan Fallon', 'order': 3, 'profile_path': '/wVFa8GiY0xdOLFsvGygy9RMtcBc.jpg'}, {'cast_id': 16, 'character': 'Great Grandma', 'credit_id': '52fe4327c3a36847f803e675', 'gender': 1, 'id': 20360, 'name': 'Angelina Torres', 'order': 4, 'profile_path': None}, {'cast_id': 17, 'character': 'Richard Whitman', 'credit_id': '52fe4327c3a36847f803e679', 'gender': 2, 'id': 20361, 'name': 'John Bennett Perry', 'order': 5, 'profile_path': '/bzFhwuXsdZiOHRtBgz4XVELIFYO.jpg'}, {'cast_id': 18, 'character': 'Nan Whitman', 'credit_id': '52fe4327c3a36847f803e67d', 'gender': 1, 'id': 20362, 'name': 'Jill Clayburgh', 'order': 6, 'profile_path': '/twrfhIvbqHuJ7nXVpehvU6nyi6R.jpg'}, {'cast_id': 19, 'character': 'Cathy Stewart', 'credit_id': '52fe4327c3a36847f803e681', 'gender': 1, 'id': 20363, 'name': 'Suzanne Snyder', 'order': 7, 'profile_path': '/90FrTcjJudpeIYUjUzlO6XAmvnt.jpg'}, {'cast_id': 20, 'character': 'Amalia', 'credit_id': '52fe4327c3a36847f803e685', 'gender': 0, 'id': 13029, 'name': 'Anne Betancourt', 'order': 8, 'profile_path': '/6UU5P4DzjJTSBFztIu1nALT2tk0.jpg'}, {'cast_id': 21, 'character': 'Juan Fuentes', 'credit_id': '52fe4327c3a36847f803e689', 'gender': 2, 'id': 4511, 'name': 'Mark Adair-Rios', 'order': 9, 'profile_path': '/rX4d1e5jlF5P73qynjjUzJslB0c.jpg'}, {'cast_id': 22, 'character': 'Judd Marshall', 'credit_id': '52fe4327c3a36847f803e68d', 'gender': 2, 'id': 4171, 'name': 'Stanley DeSantis', 'order': 10, 'profile_path': '/4cHxkhTd7oklyNkdva9WJp0FLrX.jpg'}, {'cast_id': 23, 'character': 'Antonio Fuentes', 'credit_id': '52fe4327c3a36847f803e691', 'gender': 0, 'id': 4665, 'name': 'Josh Cruze', 'order': 11, 'profile_path': '/v3QrQzH0uGV9pd1dNR5Ue6a74qO.jpg'}, {'cast_id': 24, 'character': 'Petra', 'credit_id': '52fe4327c3a36847f803e695', 'gender': 0, 'id': 4666, 'name': 'Angela Lanza', 'order': 12, 'profile_path': '/zmf6TMWMVCdnuUfpgdnioaICk1L.jpg'}, {'cast_id': 25, 'character': 'Phil', 'credit_id': '52fe4327c3a36847f803e699', 'gender': 2, 'id': 4445, 'name': 'Chris Bauer', 'order': 13, 'profile_path': '/3KYVMaGkWTEDQ0T9lsu85pVbP4T.jpg'}, {'cast_id': 26, 'character': 'Chuy', 'credit_id': '577e438f925141440c000d63', 'gender': 0, 'id': 115874, 'name': 'Carlos GÃ³mez', 'order': 14, 'profile_path': '/nBxwoMv1zrhNXyEjYXbcdmAdmF0.jpg'}]   \n",
      "2343877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'cast_id': 18, 'character': 'Erica Burgoyne', 'credit_id': '52fe436bc3a36847f8052cd5', 'gender': 1, 'id': 27939, 'name': 'Nova Pilbeam', 'order': 0, 'profile_path': '/l6oHJaRYrVxsvoTSmMS5wIXaei5.jpg'}, {'cast_id': 19, 'character': 'Robert Tisdall', 'credit_id': '52fe436bc3a36847f8052cd9', 'gender': 0, 'id': 27940, 'name': 'Derrick De Marney', 'order': 1, 'profile_path': '/7VRZ7K0EZ50haOlbVr7DHZ5550O.jpg'}, {'cast_id': 20, 'character': 'Col. Burgoyne', 'credit_id': '52fe436bc3a36847f8052cdd', 'gender': 2, 'id': 27929, 'name': 'Percy Marmont', 'order': 2, 'profile_path': '/p3DIyvlxx6B0SVIxcDaPUPlEV0U.jpg'}, {'cast_id': 21, 'character': 'Old Will', 'credit_id': '52fe436bc3a36847f8052ce1', 'gender': 2, 'id': 27941, 'name': 'Edward Rigby', 'order': 3, 'profile_path': '/B7GJ0jPtODqZVgVtZHPtvZl2tO.jpg'}, {'cast_id': 22, 'character': 'Ericas Tante Margaret', 'credit_id': '52fe436bc3a36847f8052ce5', 'gender': 1, 'id': 14304, 'name': 'Mary Clare', 'order': 4, 'profile_path': '/lAdEwCGiSUj9CCMPB4L9X4oujLe.jpg'}, {'cast_id': 23, 'character': 'Det. Insp. Kent', 'credit_id': '52fe436bc3a36847f8052ce9', 'gender': 2, 'id': 7383, 'name': 'John Longden', 'order': 5, 'profile_path': '/rsCoUEx2ThNIz12fBR6vPncCICk.jpg'}, {'cast_id': 24, 'character': 'Guy', 'credit_id': '52fe436bc3a36847f8052ced', 'gender': 2, 'id': 27942, 'name': 'George Curzon', 'order': 6, 'profile_path': None}, {'cast_id': 25, 'character': 'Ericas Onkel Basil', 'credit_id': '52fe436bc3a36847f8052cf1', 'gender': 2, 'id': 14303, 'name': 'Basil Radford', 'order': 7, 'profile_path': '/9STo7Tgdutplo78ZtyeINGWkXUk.jpg'}, {'cast_id': 26, 'character': 'Christine Clay', 'credit_id': '52fe436bc3a36847f8052cf5', 'gender': 1, 'id': 27943, 'name': 'Pamela Carme', 'order': 8, 'profile_path': None}, {'cast_id': 27, 'character': 'Detective Sergeant Miller', 'credit_id': '52fe436bc3a36847f8052cf9', 'gender': 2, 'id': 27944, 'name': 'George Merritt', 'order': 9, 'profile_path': None}, {'cast_id': 28, 'character': 'Henry Briggs', 'credit_id': '52fe436bc3a36847f8052cfd', 'gender': 2, 'id': 27945, 'name': 'J.H. Roberts', 'order': 10, 'profile_path': None}, {'cast_id': 29, 'character': \"Truckfahrer bei Tom's Hat\", 'credit_id': '52fe436bc3a36847f8052d01', 'gender': 2, 'id': 27946, 'name': 'Jerry Verno', 'order': 11, 'profile_path': None}, {'cast_id': 30, 'character': 'Police Sergeant Ruddock', 'credit_id': '52fe436bc3a36847f8052d05', 'gender': 2, 'id': 27947, 'name': 'H.F. Maltby', 'order': 12, 'profile_path': None}, {'cast_id': 31, 'character': 'Police Constable', 'credit_id': '52fe436bc3a36847f8052d09', 'gender': 2, 'id': 27948, 'name': 'John Miller', 'order': 13, 'profile_path': None}]   \n",
      "2943547  [{'cast_id': 6, 'character': 'Antoine Doinel', 'credit_id': '52fe421ec3a36847f8005661', 'gender': 2, 'id': 1653, 'name': 'Jean-Pierre LÃ©aud', 'order': 0, 'profile_path': '/dzkPODapVe4CSubEqI9ytTCqnZ7.jpg'}, {'cast_id': 7, 'character': 'Gilberte Doinel', 'credit_id': '52fe421ec3a36847f8005665', 'gender': 1, 'id': 1654, 'name': 'Claire Maurier', 'order': 1, 'profile_path': '/cP1n7zMsMKr77xJeR3CncomxEZ0.jpg'}, {'cast_id': 8, 'character': 'Julien Doinel', 'credit_id': '52fe421ec3a36847f8005669', 'gender': 0, 'id': 1655, 'name': 'Albert RÃ©my', 'order': 2, 'profile_path': '/6b8eyIXAV6oA5eX6ltc3hF7ZB3d.jpg'}, {'cast_id': 10, 'character': 'Mr. Bigey', 'credit_id': '52fe421ec3a36847f8005673', 'gender': 2, 'id': 1658, 'name': 'Georges Flamant', 'order': 3, 'profile_path': '/lQwmtPsFWME63x5M7IRF6g8bLrR.jpg'}, {'cast_id': 11, 'character': 'RenÃ©', 'credit_id': '52fe421ec3a36847f8005677', 'gender': 0, 'id': 1659, 'name': 'Patrick Auffay', 'order': 4, 'profile_path': None}, {'cast_id': 12, 'character': 'Director of the school', 'credit_id': '52fe421ec3a36847f800567b', 'gender': 0, 'id': 1660, 'name': 'Robert Beauvais', 'order': 5, 'profile_path': None}, {'cast_id': 13, 'character': 'Mme Bigey', 'credit_id': '52fe421ec3a36847f800567f', 'gender': 0, 'id': 1661, 'name': 'Yvonne Claudie', 'order': 6, 'profile_path': None}, {'cast_id': 14, 'character': 'English Teacher', 'credit_id': '52fe421ec3a36847f8005683', 'gender': 0, 'id': 1662, 'name': 'Pierre Repp', 'order': 7, 'profile_path': '/1AUhiNGBAR0C6AU9iK1IXBs3QTz.jpg'}, {'cast_id': 17, 'character': 'French Teacher', 'credit_id': '52fe421ec3a36847f8005693', 'gender': 0, 'id': 1656, 'name': 'Guy Decomble', 'order': 8, 'profile_path': '/34iexAuqI1asyFounbSXSCFphen.jpg'}, {'cast_id': 20, 'character': 'Betrand Mauricet', 'credit_id': '52fe421ec3a36847f8005697', 'gender': 0, 'id': 1077237, 'name': 'Daniel Couturier', 'order': 9, 'profile_path': None}, {'cast_id': 21, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569b', 'gender': 0, 'id': 1077238, 'name': 'FranÃ§ois Nocher', 'order': 10, 'profile_path': None}, {'cast_id': 22, 'character': 'Child', 'credit_id': '52fe421ec3a36847f800569f', 'gender': 2, 'id': 150939, 'name': 'Richard Kanayan', 'order': 11, 'profile_path': '/vCMDk3ifj2vJKZYCISXT3K6DYXF.jpg'}, {'cast_id': 23, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a3', 'gender': 0, 'id': 1077239, 'name': 'Renaud Fontanarosa', 'order': 12, 'profile_path': None}, {'cast_id': 24, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056a7', 'gender': 0, 'id': 1077240, 'name': 'Michel Girard', 'order': 13, 'profile_path': None}, {'cast_id': 25, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056ab', 'gender': 0, 'id': 71997, 'name': 'Serge Moati', 'order': 14, 'profile_path': '/wccRQKHrX61sH4WlOtM1KBP4qaq.jpg'}, {'cast_id': 26, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056af', 'gender': 0, 'id': 1077241, 'name': 'Bernard Abbou', 'order': 15, 'profile_path': None}, {'cast_id': 27, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b3', 'gender': 0, 'id': 1077242, 'name': 'Jean-FranÃ§ois Bergouignan', 'order': 16, 'profile_path': None}, {'cast_id': 28, 'character': 'Child', 'credit_id': '52fe421ec3a36847f80056b7', 'gender': 0, 'id': 1077243, 'name': 'Michel Lesignor', 'order': 17, 'profile_path': None}, {'cast_id': 31, 'character': 'Man in Street', 'credit_id': '5457f0a1c3a3683993000156', 'gender': 2, 'id': 24299, 'name': 'Jean-Claude Brialy', 'order': 18, 'profile_path': '/g3kkYcAvq90tALMErxmdAIcIXsE.jpg'}, {'cast_id': 32, 'character': 'Woman with Dog', 'credit_id': '5457f0bec3a36839a0000144', 'gender': 1, 'id': 14812, 'name': 'Jeanne Moreau', 'order': 19, 'profile_path': '/uHJnVwCzehEoz0mIlwN7xkymql8.jpg'}, {'cast_id': 33, 'character': 'Man in Funfair', 'credit_id': '5457f0d3c3a368399300015b', 'gender': 2, 'id': 34613, 'name': 'Philippe de Broca', 'order': 20, 'profile_path': '/yrvmXE2SJBX659r2Y7eWwlmwfYd.jpg'}, {'cast_id': 34, 'character': 'Man in Funfair', 'credit_id': '5457f0e5c3a368399d00014c', 'gender': 0, 'id': 1650, 'name': 'FranÃ§ois Truffaut', 'order': 21, 'profile_path': '/apCCV99N3FqB5NsEPqOzetlkprL.jpg'}]   \n",
      "8434697                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'cast_id': 24, 'character': 'Rocky Balboa', 'credit_id': '52fe42e9c3a36847f802c61b', 'gender': 2, 'id': 16483, 'name': 'Sylvester Stallone', 'order': 0, 'profile_path': '/gnmwOa46C2TP35N7ARSzboTdx2u.jpg'}, {'cast_id': 25, 'character': 'Paulie', 'credit_id': '52fe42e9c3a36847f802c61f', 'gender': 2, 'id': 4521, 'name': 'Burt Young', 'order': 1, 'profile_path': '/rbSsSkQ72FoGcvwIHUxQWJ92I3W.jpg'}, {'cast_id': 26, 'character': 'Rocky Jr.', 'credit_id': '52fe42e9c3a36847f802c623', 'gender': 2, 'id': 16501, 'name': 'Milo Ventimiglia', 'order': 2, 'profile_path': '/maJeS6bA6ku21rSRceISQtwHL2h.jpg'}, {'cast_id': 27, 'character': 'Marie', 'credit_id': '52fe42e9c3a36847f802c627', 'gender': 1, 'id': 16502, 'name': 'Geraldine Hughes', 'order': 3, 'profile_path': '/bTXux3EJq25Fh2ixbet6MjdG3Fb.jpg'}, {'cast_id': 28, 'character': 'Steps', 'credit_id': '52fe42e9c3a36847f802c62b', 'gender': 2, 'id': 16503, 'name': 'James Francis Kelly III', 'order': 4, 'profile_path': '/iZyTQ2UlwNXrqLqPeNHbofFXubP.jpg'}, {'cast_id': 29, 'character': 'Duke', 'credit_id': '52fe42e9c3a36847f802c62f', 'gender': 2, 'id': 16504, 'name': 'Tony Burton', 'order': 5, 'profile_path': '/ue54hK217thXeQMzN4qUYXLImLd.jpg'}, {'cast_id': 30, 'character': 'L.C.', 'credit_id': '52fe42e9c3a36847f802c633', 'gender': 2, 'id': 16505, 'name': 'A. J. Benza', 'order': 6, 'profile_path': '/5hVinC6C1ZyD7c8EmZFTiEaF7vH.jpg'}, {'cast_id': 31, 'character': 'Adrian', 'credit_id': '52fe42e9c3a36847f802c637', 'gender': 1, 'id': 3094, 'name': 'Talia Shire', 'order': 7, 'profile_path': '/liNfrVB3eZFBOjcUGltISCucews.jpg'}, {'cast_id': 32, 'character': 'Martin', 'credit_id': '52fe42e9c3a36847f802c63b', 'gender': 2, 'id': 16506, 'name': 'Henry G. Sanders', 'order': 8, 'profile_path': '/2SU75g2CAIzGWbgfIlNvKZQhYTZ.jpg'}, {'cast_id': 33, 'character': \"Mason 'The Line' Dixon\", 'credit_id': '52fe42e9c3a36847f802c63f', 'gender': 2, 'id': 16507, 'name': 'Antonio Tarver', 'order': 9, 'profile_path': '/kJEljjHwBvrjoxqcSVntXlejgl1.jpg'}, {'cast_id': 34, 'character': 'Spider Rico', 'credit_id': '52fe42e9c3a36847f802c643', 'gender': 2, 'id': 16508, 'name': 'Pedro Lovell', 'order': 10, 'profile_path': None}, {'cast_id': 35, 'character': 'Isabel', 'credit_id': '52fe42e9c3a36847f802c647', 'gender': 1, 'id': 16509, 'name': 'Ana Gerena', 'order': 11, 'profile_path': None}, {'cast_id': 36, 'character': 'Angie', 'credit_id': '52fe42e9c3a36847f802c64b', 'gender': 1, 'id': 16510, 'name': 'Angela Boyd', 'order': 12, 'profile_path': None}, {'cast_id': 37, 'character': 'Bar Thug', 'credit_id': '52fe42e9c3a36847f802c64f', 'gender': 0, 'id': 16511, 'name': 'Louis Giansante', 'order': 13, 'profile_path': None}, {'cast_id': 38, 'character': \"Lucky's Bartender\", 'credit_id': '52fe42e9c3a36847f802c653', 'gender': 0, 'id': 16512, 'name': 'Maureen Schilling', 'order': 14, 'profile_path': None}, {'cast_id': 40, 'character': 'X-Cell', 'credit_id': '5761db05c3a3682f20000302', 'gender': 2, 'id': 98298, 'name': 'Lahmard J. Tate', 'order': 15, 'profile_path': '/4WcFReePSxyGQJWV5wXGNfY0Y7o.jpg'}]   \n",
      "\n",
      "                                                                               tagline  \\\n",
      "8830418                                   First came love... then came Reverend Frank.   \n",
      "1690638  What if finding the love of your life meant changing the life that you loved?   \n",
      "2343877                                                          A Brilliant Melodrama   \n",
      "2943547                                            Angel faces hell-bent for violence.   \n",
      "8434697                                                  It ain't over 'til it's over.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        overview  \n",
      "8830418                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Newly engaged, Ben and Sadie can't wait to start their life together and live happily ever after. However Sadie's family church's Reverend Frank won't bless their union until they pass his patented, \"foolproof\" marriage prep course consisting of outrageous classes, outlandish homework assignments and some outright invasion of privacy.  \n",
      "1690638                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alex Whitman (Matthew Perry) is a designer from New York City who is sent to Las Vegas to supervise the construction of a nightclub that his firm has been hired to build. Alex is a straight-laced WASP-ish type who, while enjoying a night on the town, meets Isabel Fuentes (Salma Hayek), a free-spirited Mexican-American photographer. Alex and Isabel are overtaken by lust at first sight and end up sp  \n",
      "2343877  Derrick De Marney finds himself in a 39 Steps situation when he is wrongly accused of murder. While a fugitive from the law, De Marney is helped by heroine Nova Pilbeam, who three years earlier had played the adolescent kidnap victim in Hitchcock's The Man Who Knew Too Much. The obligatory \"fish out of water\" scene, in which the principals are briefly slowed down by a banal everyday event, occurs during a child's birthday party. The actual villain, whose identity is never in doubt (Hitchcock made thrillers, not mysteries) is played by George Curzon, who suffers from a twitching eye. Curzon's revelation during an elaborate nightclub sequence is a Hitchcockian tour de force, the sort of virtuoso sequence taken for granted in these days of flexible cameras and computer enhancement, but which in 1937 took a great deal of time, patience and talent to pull off. Released in the US as The Girl Was Young, Young and Innocent was based on a novel by Josephine Tey.  \n",
      "2943547                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For young Parisian boy Antoine Doinel, life is one difficult situation after another. Surrounded by inconsiderate adults, including his neglectful parents, Antoine spends his days with his best friend, Rene, trying to plan for a better life. When one of their schemes goes awry, Antoine ends up in trouble with the law, leading to even more conflicts with unsympathetic authority figures.  \n",
      "8434697                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When he loses a highly publicized virtual boxing match to ex-champ Rocky Balboa, reigning heavyweight titleholder, Mason Dixon retaliates by challenging Rocky to a nationally televised, 10-round exhibition bout. To the surprise of his son and friends, Rocky agrees to come out of retirement and face an opponent who's faster, stronger and thirty years his junior.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#seed for consistent results across runtime\n",
    "# seed_int = 3\n",
    "# random.seed(seed_int)\n",
    "\n",
    "#This code is for combining certain data from the necessary csv files into a single dataframe (complete)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "movies_full = pd.read_csv('newdata/movies_metadata.csv',usecols=(\"genres\",\"id\" ,\"title\",\"tagline\", \"overview\",\"production_companies\"),\n",
    "                          dtype={\"tagline\": \"string\", \"id\":\"string\", 'genres':\"string\", \"title\": \"string\", \"tagline\": \"string\",\"overview\":\"string\", \"production_companies\" :\"string\"})\n",
    "ratings = pd.read_csv('newdata/ratings.csv', usecols = (\"userId\", \"movieId\", \"rating\"), dtype={\"userId\": \"string\",\"movieId\": \"string\",\"rating\": \"string\"})\n",
    "ratings = ratings.rename(columns={\"movieId\": \"id\"})\n",
    "\n",
    "keywords = pd.read_csv('newdata/keywords.csv', usecols = (\"id\", \"keywords\"), dtype={\"id\": \"string\",\"keywords\":\"string\"})\n",
    "credits = pd.read_csv(\"newdata/credits.csv\", usecols = (\"cast\", \"id\"), dtype={\"cast\": \"string\", \"id\": \"string\"})\n",
    "\n",
    "complete =  pd.merge(movies_full, ratings, on =\"id\")\n",
    "complete =  pd.merge(complete,keywords, on =\"id\")\n",
    "complete  = pd.merge(complete,credits, on =\"id\")\n",
    "\n",
    "\n",
    "#new:\n",
    "#userIds are in order\n",
    "# every_id = list(unique(list(complete[\"userId\"])))\n",
    "#userIds are out of order\n",
    "# sample_ids  = random.sample(every_id, 1000)\n",
    "# completeNew = pd.DataFrame()\n",
    "#This is a very expensive task...\n",
    "#it is possile to choose a subset of users from here instead of\n",
    "#ibcluing  the entire set of users\n",
    "# for user in sample_ids:\n",
    "#     completeNew = pd.concat([completeNew, complete.loc[complete[\"userId\"] == user]])\n",
    "\n",
    "#new:\n",
    "# complete = complete.sample(frac=1, random_state = seed_int, axis =0)\n",
    "#this is not the desired behavior\n",
    "#the users ids need to show up in a true random order\n",
    "# complete = complete.groupby(by = \"userId\", sort = False, group_keys = True).apply(lambda x: x)\n",
    "#this is omitted since the values should not be sorted by userId just grouped by userId\n",
    "\n",
    "complete = complete.sort_values(by = 'userId')\n",
    "\n",
    "complete  = complete.dropna()\n",
    "\n",
    "complete  = complete.loc[:,['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\" ]]\n",
    "\n",
    "\n",
    "print(complete.head())\n",
    "\n",
    "# f = open(\"test_dicts.txt\", \"w\", encoding=\"utf-8\")\n",
    "# f.write(str(list(complete[\"tagline\"])))\n",
    "# f.write(str(list(complete[\"overview\"])))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575\n",
      "29.902903104184993\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "\n",
    "#seed for consistent results across runtime\n",
    "# seed_int = 3\n",
    "# random.seed(seed_int)\n",
    "\n",
    "#used to filter out the rows of data with empty entries\n",
    "def condition(array):\n",
    "    length = len(array[4])\n",
    "    if(array[4][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[5])\n",
    "    if(array[5][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[6])\n",
    "    if(array[6][length-2:] == \"[]\"):\n",
    "        return False\n",
    "    length = len(array[7])\n",
    "    if(array[7][length-2:] == \"[]\"):\n",
    "        return False   \n",
    "    #this is probably not needed due to the dropNa function used above...\n",
    "    # length = len(array[8])\n",
    "    # if(array[8][length-4:]==\"<NA>\"):\n",
    "    #     return False\n",
    "    # length = len(array[9])\n",
    "    # if(array[9][length-4:]==\"<NA>\"):\n",
    "    #     return False \n",
    "    return True\n",
    "\n",
    "\n",
    "#used to extract names\n",
    "def populate_names(item):\n",
    "    string  = item[1:-1]\n",
    "    jsons = string.split(\"}, \")   \n",
    "    names = \"\"\n",
    "    cnt = 0\n",
    "    for item in jsons:\n",
    "        if(cnt == len(jsons)-1):\n",
    "            temp_dict = ast.literal_eval(item)\n",
    "            names+=str(temp_dict[\"name\"])\n",
    "        else:\n",
    "            temp_dict = ast.literal_eval(item+\"}\")\n",
    "            names+=str(str(temp_dict[\"name\"])+\" \")\n",
    "        cnt += 1\n",
    "    return names\n",
    "\n",
    "#extract data from row of complete_array\n",
    "def provide_data(array):\n",
    "    movie_data = []\n",
    "    movie_data.append(int(array[0]))\n",
    "    movie_data.append(int(array[1]))\n",
    "    movie_data.append(float(array[2]))\n",
    "    movie_data.append(array[3])  \n",
    "\n",
    "    movie_data.append(populate_names(array[4]))\n",
    "    movie_data.append(populate_names(array[5]))\n",
    "    movie_data.append(populate_names(array[6]))\n",
    "    movie_data.append(populate_names(array[7]))\n",
    "\n",
    "    movie_data.append(str(array[8]))\n",
    "    movie_data.append(str(array[9]))\n",
    "    return movie_data\n",
    "    \n",
    "\n",
    "\n",
    "#new method\n",
    "list_of_user_ids = list(complete[\"userId\"].unique())\n",
    "\n",
    "counts = complete['userId'].value_counts()\n",
    "gaps = []\n",
    "for id in list_of_user_ids:\n",
    "    gaps.append(counts[id])\n",
    "\n",
    "complete_array = complete.to_numpy()\n",
    "\n",
    "#old method...\n",
    "# gaps = []\n",
    "# size = 0\n",
    "# list_of_user_ids = []\n",
    "# last_id  = -1\n",
    "# past_first_it = False\n",
    "\n",
    "\n",
    "# for row in complete_array:\n",
    "#     if(row[0]!= last_id):\n",
    "#         list_of_user_ids.append(row[0])\n",
    "#         last_id = row[0]\n",
    "#         if(past_first_it ==True):\n",
    "#             gaps.append(size)\n",
    "#             size =0 \n",
    "#     size+=1\n",
    "#     past_first_it = True\n",
    "\n",
    "# #there is always a gap for the last iteration\n",
    "# gaps.append(size)\n",
    "\n",
    "\n",
    "\n",
    "index  = 0\n",
    "\n",
    "user_to_data = []\n",
    "#this is the total number of users in the whole dataset\n",
    "total_nof_users = len(list_of_user_ids)\n",
    "#this is the number of desired users before filtering\n",
    "#note: set back to 40000\n",
    "desired_nof_users_before_filter = 40000\n",
    "\n",
    "avg = 0\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "#instead of using this random pass generaion \n",
    "#the users can be picked randomly before hand and replace list_of_user_ids[i]\n",
    "#will index still work???\n",
    "\n",
    "#populate user_to_data from complete_array\n",
    "for i in range(0, total_nof_users):\n",
    "    #generate a random float to determine a pass for the user\n",
    "    if (random.random()<float(desired_nof_users_before_filter/total_nof_users)):\n",
    "        #user_to_data[list_of_user_ids[i]] = []\n",
    "        user_to_data.append([])\n",
    "        last_index = len(user_to_data) -1\n",
    "        for j in range(index, len(complete_array)):\n",
    "            if complete_array[j][0] == list_of_user_ids[i]:\n",
    "                #condition is checked for complete_array[j]\n",
    "                if(condition(complete_array[j])):\n",
    "                    #this is where data is tranformed\n",
    "                    transformed = provide_data(complete_array[j])\n",
    "                    #is copy needed here???\n",
    "                    user_to_data[last_index].append(transformed)\n",
    "\n",
    "                #last iteration\n",
    "                if (j==len(complete_array)-1):\n",
    "                    if (len(user_to_data[last_index])<50 or len(user_to_data[last_index])>75):\n",
    "                        del user_to_data[last_index]       \n",
    "            else:\n",
    "                avg += len(user_to_data[last_index])\n",
    "                cnt+=1\n",
    "                #this condition can be tweaked for better accuracy\n",
    "                #len(user_to_data[list_of_user_ids[i]])<50 or len(user_to_data[list_of_user_ids[i]])>75\n",
    "                if (len(user_to_data[last_index])<50 or len(user_to_data[last_index])>75):\n",
    "                    del user_to_data[last_index]  \n",
    "                #note: changed from (index = j+1)\n",
    "                index = j\n",
    "                break\n",
    "        #note, problem: provide data is run in right order\n",
    "        #but a user can be deleted and then the order can be messed up    \n",
    "    else:\n",
    "        #every iteration, index starts at first data point of the next user\n",
    "        index += gaps[i]\n",
    "\n",
    "\n",
    "#runtime test, go through user_to_data and re-index the users in list order\n",
    "for i in range(len(user_to_data)):\n",
    "    for j in range(len(user_to_data[i])):\n",
    "        user_to_data[i][j][0] = i\n",
    "\n",
    "\n",
    "\n",
    "#needs to be sure that there are enough users after the condiiton\n",
    "print(len(user_to_data))\n",
    "\n",
    "#average number of ratings per users\n",
    "print(float(avg/cnt))\n",
    "\n",
    "#18 minutes for 2599 users\n",
    "\n",
    "#test with dictionaries:\n",
    "# 71\n",
    "#runtime: 30.679282868525895\n",
    "\n",
    "#test without dictionaries:\n",
    "# 63\n",
    "#runtime: 30.422131147540984\n",
    "\n",
    "#18 minutes for 2611 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in a file so that cells below can run without running this cell and above\n",
    "\n",
    "#question: would renaming the user ids as indexes in their order be helpful???\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(\"constructedData/constructedData.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['userId','id','rating',\"title\", \"genres\",\"production_companies\",\"keywords\", \"cast\", \"tagline\", \"overview\"])\n",
    "    for i in range(len(user_to_data)):\n",
    "        writer.writerows(user_to_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a starting point if the data is already saved to the constructedData.csv file\n",
    "import csv\n",
    "\n",
    "data_list =[]\n",
    "\n",
    "with open(\"constructedData/constructedData.csv\", 'r', encoding=\"utf-8\") as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    data_list = list(csv_reader)\n",
    "\n",
    "data_list = data_list[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#try removing unecessay copying...\n",
    "\n",
    "#seed for consistent results across runtime\n",
    "# seed_int = 1\n",
    "# random.seed(seed_int)\n",
    "\n",
    "#user to data rows \n",
    "user_to_data = []\n",
    "user_to_data_train = []\n",
    "user_to_data_test = []\n",
    "user_id = -1\n",
    "\n",
    "#note: works when row[0] is also an index\n",
    "for row in data_list:\n",
    "    if (row[0]!=user_id):\n",
    "        user_id = row[0]\n",
    "        user_to_data.append([row])\n",
    "    else:\n",
    "        user_to_data[int(row[0])].append(row)\n",
    "\n",
    "\n",
    "#this can be tweaked...\n",
    "for i in range(500):\n",
    "    index = random.randint(0, len(user_to_data)-1)\n",
    "    user_to_data_train.append(user_to_data[index])\n",
    "    del user_to_data[index]\n",
    "\n",
    "\n",
    "#for test data to be used later...\n",
    "for i in range(100):\n",
    "    index = random.randint(0, len(user_to_data_train)-1)\n",
    "    user_to_data_test.append(user_to_data_train[index])\n",
    "    del user_to_data_train[index]\n",
    "\n",
    "\n",
    "del user_to_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "import json\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "\n",
    "\n",
    "#seed for consistent results across runtime\n",
    "# seed_int = 1\n",
    "# random.seed(seed_int)\n",
    "\n",
    "\n",
    "#check if there are variables that can be removed!!!\n",
    "class user_type_vars():\n",
    "    def __init__(self):\n",
    "        #user to movie_id to a list of all the words in that movie (copies allowed)\n",
    "        self.user_to_movie_id_to_corpus = [] \n",
    "\n",
    "        #user to movie_id to its rating\n",
    "        self.user_to_movie_id_to_rating = [] \n",
    "\n",
    "        #for each user, includes a random choice from all the movies the user watched to be the target\n",
    "        self.user_to_target_movie_id = [] \n",
    "\n",
    "        #for each user, the index is the placement of the target movie in the entire set of train movies inorder\n",
    "        self.user_to_target_index_full = [] \n",
    "\n",
    "        #for each user, a set of all the words in all the movies the user watched \n",
    "        self.user_to_words_in_order  = [] \n",
    "\n",
    "        #for each user, the word counts for movies that they watched\n",
    "        self.user_to_word_counts  = [] \n",
    "        self.user_to_word_counts_transformed = []\n",
    "\n",
    "        #The word counts of the target movie for each user\n",
    "        self.user_to_target_word_counts  = [] \n",
    "        self.user_to_target_word_counts_transformed = []\n",
    "\n",
    "        #for each user, includes all the ratings of movies the user has rated with a -1 marked as the target rating\n",
    "        self.user_to_ratings  = []\n",
    "\n",
    "        #for each user, includes ratings for all the movies in the entire train set (missing ratings are filled in)\n",
    "        self.user_to_ratings_full = [] \n",
    "        self.user_to_ratings_full_transform = []\n",
    "\n",
    "        #model features x\n",
    "        self.feature_1 = []\n",
    "        self.feature_2 = []\n",
    "        self.feature_3 = []\n",
    "\n",
    "        #output feature y\n",
    "        self.user_to_target_rating  = [] \n",
    "\n",
    "\n",
    "#need to think about the order these variables are used to improve memory perf...\n",
    "#goal: minimize the window between when a variable was populated and used\n",
    "\n",
    "\n",
    "#user_to_movie_id_to_corpus:\n",
    "#1,2, 3, 4\n",
    "\n",
    "#user_to_movie_id_to_rating:\n",
    "#1, 3, after 5, 6\n",
    "\n",
    "#user_to_target_movie_id:\n",
    "#1, 3, 4, after 5, 6\n",
    "\n",
    "#user_to_target_index_full:\n",
    "#6,7\n",
    "\n",
    "#user_to_words_in_order:\n",
    "#2,4\n",
    "#this seems optimal\n",
    "\n",
    "#user_to_word_counts:\n",
    "#4,5,\n",
    "\n",
    "#user_to_word_counts_transformed:\n",
    "#4,5,\n",
    "\n",
    "#user_to_target_word_counts:\n",
    "#4,5\n",
    "\n",
    "#user_to_target_word_counts_transformed:\n",
    "#4,5\n",
    "\n",
    "#user_to_ratings: (the combination of 4 and 5 streamline this this)\n",
    "#3,5\n",
    "\n",
    "#user_to_ratings_full:\n",
    "#6,7\n",
    "\n",
    "#user_to_ratings_full_transform:\n",
    "#6,7\n",
    "\n",
    "#needed until the end:\n",
    "#self.features...\n",
    "#self.user_to_target_rating\n",
    "\n",
    "\n",
    "#goal: minimize the window between when a vraible was populated and used\n",
    "#or remove intermediate variables \n",
    "\n",
    "\n",
    "# first observation:\n",
    "# these variables are populated and used in sucession\n",
    "# user_to_word_counts:\n",
    "# user_to_word_counts_transformed:\n",
    "# user_to_target_word_counts:\n",
    "# user_to_target_word_counts_transformed:\n",
    "\n",
    "# the sole purpose of 4 and 5 is to created a cossine similairty list\n",
    "# so populate 4 and 5 can be combined\n",
    "\n",
    "\n",
    "#idea:\n",
    "#exchange places of 2 and 3\n",
    "\n",
    "\n",
    "#idea:\n",
    "#after the switch is populate 3 even necessary ???\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "train_users = user_type_vars()\n",
    "test_users = user_type_vars()\n",
    "\n",
    "\n",
    "\n",
    "#no changes needed for these vars below...\n",
    "movie_id_to_ratings_total = dict() #all ratings for each movie\n",
    "movies_in_order = OrderedSet() #all movies in order\n",
    "movie_id_to_average_rating_train = dict() #average movie rating amoung all users for each movie\n",
    "user_to_average_rating = []\n",
    "overall_sum_train = 0 #used to compute the overall_average\n",
    "overall_counts_train = 0 #used to compute the overall_average\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def populate_1(user_to_data, user_to_movie_id_to_corpus, user_to_movie_id_to_rating,\n",
    "            movie_id_to_ratings, overall_sum, overall_counts, user_to_target_movie_id):\n",
    "    for i in range(len(user_to_data)):\n",
    "        movie_id_to_words_temp = dict()\n",
    "        movie_id_to_rating_temp = dict()\n",
    "        cnt = 0\n",
    "        total =0\n",
    "        rand_int = random.randint(0, len(user_to_data[i])-1)\n",
    "        for movie_data in user_to_data[i]:\n",
    "            if cnt == rand_int:    \n",
    "                user_to_target_movie_id.append(movie_data[1])\n",
    "            else:\n",
    "                overall_sum += float(movie_data[2])\n",
    "                overall_counts += 1\n",
    "                total += float(movie_data[2])\n",
    "            \n",
    "            if movie_data[1] in movie_id_to_ratings.keys():\n",
    "                movie_id_to_ratings[movie_data[1]].append(float(movie_data[2]))\n",
    "            else:\n",
    "                movie_id_to_ratings[movie_data[1]] = [float(movie_data[2])]\n",
    "\n",
    "            movie_string = \"\"\n",
    "            #avoid the first three data points (user id, movieid, and rating)\n",
    "            #use only the text data\n",
    "            for index in range (3,len(movie_data)):\n",
    "                if(index!= len(movie_data)-1):\n",
    "                    movie_string+= movie_data[index]+\" \"\n",
    "                else:\n",
    "                    movie_string+= movie_data[index]\n",
    "\n",
    "            #need to try with and without lematization...\n",
    "            cleaned = remove_stopwords(movie_string)\n",
    "            cleaned = [wnl.lemmatize(word) for word in cleaned.split(\" \")]\n",
    "            cleaned = [word[:-1] for word in cleaned if word.endswith(\".\")] + [word for word in cleaned if not word.endswith(\".\")]\n",
    "            #is copy really needed with this scope ???\n",
    "            movie_id_to_words_temp[movie_data[1]] = cleaned\n",
    "            movie_id_to_rating_temp[movie_data[1]] = float(movie_data[2])\n",
    "            movies_in_order.add(movie_data[1])\n",
    "            cnt+=1\n",
    "        user_to_average_rating.append(float(total/(cnt-1)))\n",
    "        #is copy really needed with this scope ???\n",
    "        user_to_movie_id_to_corpus.append(movie_id_to_words_temp)\n",
    "        #is copy really needed with this scope ???\n",
    "        user_to_movie_id_to_rating.append(movie_id_to_rating_temp)\n",
    "    return overall_sum, overall_counts\n",
    "\n",
    "\n",
    "overall_sum_train, overall_counts_train = populate_1(user_to_data_train, train_users.user_to_movie_id_to_corpus, \n",
    "                                                   train_users.user_to_movie_id_to_rating,movie_id_to_ratings_total,\n",
    "                                                   overall_sum_train, overall_counts_train, train_users.user_to_target_movie_id)\n",
    "\n",
    "#this is used when there are no usable ratings for a movie\n",
    "overall_average_train = float(overall_sum_train/overall_counts_train)\n",
    "\n",
    "populate_1(user_to_data_test, test_users.user_to_movie_id_to_corpus, test_users.user_to_movie_id_to_rating,\n",
    "            dict(), 0, 0, test_users.user_to_target_movie_id)\n",
    "\n",
    "\n",
    "#movie_id_to_average_rating_train is used by both the test and train set\n",
    "for movie in movie_id_to_ratings_total.keys():\n",
    "    temp = 0\n",
    "    for rating in movie_id_to_ratings_total[movie]:\n",
    "        temp +=rating\n",
    "    movie_id_to_average_rating_train[movie] = float(temp/len(movie_id_to_ratings_total[movie]))\n",
    "\n",
    "\n",
    "#used to see what the text data looks like...\n",
    "\n",
    "# not applicable with dict to list change...\n",
    "# file = open(\"test_dicts_1.txt\", 'w', encoding=\"utf-8\")\n",
    "# file.write(json.dumps(user_to_movie_id_to_corpus_train))\n",
    "# file.close()\n",
    "\n",
    "# file = open(\"test_dicts_2.txt\", 'w', encoding=\"utf-8\")\n",
    "# file.write(json.dumps(user_to_movie_id_to_corpus_test))\n",
    "# file.close()\n",
    "\n",
    "del user_to_data_train\n",
    "del user_to_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from ordered_set import OrderedSet\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#what if populate 1 2 3 and 4 were combined???\n",
    "\n",
    "\n",
    "def populate_2(user_to_movie_id_to_corpus, user_to_words_in_order):\n",
    "    for i in range(len(user_to_movie_id_to_corpus)):\n",
    "        user_to_words_in_order.append(OrderedSet())\n",
    "        for movie_id in user_to_movie_id_to_corpus[i].keys():\n",
    "            for word in user_to_movie_id_to_corpus[i][movie_id]:\n",
    "                user_to_words_in_order[i].add(word)\n",
    "\n",
    "populate_2(train_users.user_to_movie_id_to_corpus,  train_users.user_to_words_in_order)\n",
    "populate_2(test_users.user_to_movie_id_to_corpus,  test_users.user_to_words_in_order)\n",
    "\n",
    "\n",
    "\n",
    "def populate_3(user_to_movie_id_to_corpus, user_to_target_movie_id, user_to_movie_id_to_rating,\n",
    "    user_to_target_rating, user_to_ratings):\n",
    "    for i in range(len(user_to_movie_id_to_corpus)):\n",
    "        temp = []\n",
    "        cnt = 0\n",
    "        for movie_id in user_to_movie_id_to_corpus[i].keys():\n",
    "            if movie_id != user_to_target_movie_id[i]:\n",
    "                temp.append(user_to_movie_id_to_rating[i][movie_id])\n",
    "            else:\n",
    "                #this signifies the ratings to be predicted by the model\n",
    "                user_to_target_rating.append(user_to_movie_id_to_rating[i][movie_id])\n",
    "                temp.append(-1)\n",
    "            cnt+=1\n",
    "        #is copy needed with this scope???\n",
    "        user_to_ratings.append(temp)\n",
    "\n",
    "\n",
    "populate_3(train_users.user_to_movie_id_to_corpus, train_users.user_to_target_movie_id, train_users.user_to_movie_id_to_rating,\n",
    "            train_users.user_to_target_rating, train_users.user_to_ratings)\n",
    "populate_3(test_users.user_to_movie_id_to_corpus, test_users.user_to_target_movie_id, test_users.user_to_movie_id_to_rating,\n",
    "            test_users.user_to_target_rating, test_users.user_to_ratings)\n",
    "\n",
    "\n",
    "#note: user to word counts needs to omit movies with no rating\n",
    "\n",
    "def populate_4(user_to_word_counts_transformed, user_to_target_word_counts_transformed,\n",
    "                user_to_movie_id_to_corpus, user_to_word_counts,\n",
    "                user_to_target_movie_id, user_to_words_in_order, user_to_target_word_counts):\n",
    "    for i in range(len(user_to_movie_id_to_corpus)):\n",
    "        user_to_word_counts.append([])\n",
    "        user_to_word_counts_transformed.append([])\n",
    "        for movie_id in user_to_movie_id_to_corpus[i].keys():\n",
    "            if movie_id != user_to_target_movie_id[i]:\n",
    "                #idea: instead of using words in order use a set of words that are local to the user\n",
    "                #this cuts time iterating over words_in_order\n",
    "                #and cuts space by having templist be shorter\n",
    "                #note: it also adds a bit of space by needing a list of words for each user\n",
    "                temp_dict = Counter(user_to_movie_id_to_corpus[i][movie_id])\n",
    "                temp_list = []\n",
    "                avg = 0\n",
    "                for word in user_to_words_in_order[i]:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])\n",
    "                        avg+=temp_dict[word]\n",
    "                    else:\n",
    "                        temp_list.append(0)\n",
    "                avg = float(avg/len(user_to_words_in_order[i]))\n",
    "                #is copy needed with this scope???\n",
    "                user_to_word_counts[i].append(temp_list)\n",
    "                user_to_word_counts_transformed[i].append([x - avg for x in temp_list])\n",
    "            else:\n",
    "\n",
    "                temp_dict = Counter(user_to_movie_id_to_corpus[i][movie_id])\n",
    "                temp_list = []\n",
    "                avg = 0\n",
    "                for word in user_to_words_in_order[i]:\n",
    "                    if word in temp_dict.keys():\n",
    "                        temp_list.append(temp_dict[word])\n",
    "                        avg+=temp_dict[word]\n",
    "                    else:\n",
    "                        temp_list.append(0)\n",
    "                avg = float(avg/len(user_to_words_in_order[i]))\n",
    "                #is copy needed with this scope???\n",
    "                user_to_target_word_counts.append(temp_list)\n",
    "                user_to_target_word_counts_transformed.append([x - avg for x in temp_list])\n",
    "\n",
    "\n",
    "populate_4(train_users.user_to_word_counts_transformed, train_users.user_to_target_word_counts_transformed,\n",
    "           train_users.user_to_movie_id_to_corpus, train_users.user_to_word_counts, train_users.user_to_target_movie_id,\n",
    "       train_users.user_to_words_in_order, train_users.user_to_target_word_counts)\n",
    "\n",
    "populate_4(test_users.user_to_word_counts_transformed, test_users.user_to_target_word_counts_transformed,\n",
    "           test_users.user_to_movie_id_to_corpus, test_users.user_to_word_counts, \n",
    "       test_users.user_to_target_movie_id, test_users.user_to_words_in_order, test_users.user_to_target_word_counts)\n",
    "\n",
    "#try omitting deletions...\n",
    "del train_users.user_to_words_in_order\n",
    "del train_users.user_to_movie_id_to_corpus\n",
    "del test_users.user_to_words_in_order\n",
    "del test_users.user_to_movie_id_to_corpus\n",
    "\n",
    "\n",
    "\n",
    "#now for each user, use the user_to_index_full and find the most similair users by omitting that index across the\n",
    "#sim_matrix\n",
    "\n",
    "\n",
    "\n",
    "#collaboritive filtering idea\n",
    "#data structures:\n",
    "#need a user to movies to ratings dictionary (done) (only needed for train data)\n",
    "#need a ordered set of all movies (done) (only needed for train data)\n",
    "\n",
    "#need to transform it into a user to list of all movies with user ratings or otherwise filled in ratings with sutiable average\n",
    "#(the list needs to be in a consistent order across users)\n",
    "#to fill in the averages we need a movie to average rating dictionary\n",
    "#(note: if no other user has rated the movie then fill it in with the overall movie average)\n",
    "#standardize the data row wise (why not columnwise???)\n",
    "#filter the users that have rated the movie to predict\n",
    "#then use cossine similairity on this set to find the most similair user the the chosen user\n",
    "#ignore the movie rating to predict with the cossine similarity function\n",
    "\n",
    "#Note: this is an expensive task and the number of users may have to be truncated before running\n",
    "\n",
    "\n",
    "\n",
    "#ideas: \n",
    "#idea1: \n",
    "#collaborative filtering:\n",
    "#https://towardsdatascience.com/predict-movie-ratings-with-user-based-collaborative-filtering-392304b988af\n",
    "#https://www.geeksforgeeks.org/user-based-collaborative-filtering/#\n",
    "#https://www.youtube.com/watch?v=3ecNC-So0r4&ab_channel=CodeHeroku\n",
    "#idea2: \n",
    "#note: the model can be scored based on how close a predition is to a threshold of .5 \n",
    "\n",
    "#idea 3:\n",
    "#there may be a replacement for cossine similarity:\n",
    "#perhaps it is not properly matching similair people and similair movies \n",
    "#maybe there is a replacement function\n",
    "\n",
    "#idea 4: \n",
    "#there should be more train and test users\n",
    "\n",
    "#idea 5: (basic model)\n",
    "#https://www.kaggle.com/code/muhammadayman/recommendation-system-using-cosine-similarity#Data-Cleaning\n",
    "\n",
    "\n",
    "\n",
    "#10 minutes for 2500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def predict(user, user_to_word_counts_transformed, user_to_target_word_counts_transformed,\n",
    "            user_to_target_word_counts, user_to_word_counts, user_to_ratings):\n",
    "    #before this operation, for each movie the average word count needs to be computed\n",
    "    #and the transformed list of word counts subtracs the mean\n",
    "    #note: in the next line you can siwtch beteen transformed and not to see if there are any boosts to perfromance\n",
    "\n",
    "    cosine_sim = cosine_similarity(X = user_to_word_counts_transformed[user] ,Y = [user_to_target_word_counts_transformed[user]])\n",
    "    \n",
    "    #not sure if reshape is needed???\n",
    "    #should test with and without reshape\n",
    "    cosine_sim = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "\n",
    "    ratings = [user_to_ratings[user][x] for x in range(len(user_to_ratings[user])) if user_to_ratings[user][x] != -1]\n",
    "\n",
    "\n",
    "    #use the movie thats are most similair to the movie in question \n",
    "\n",
    "    #option 1: \n",
    "    # combined = zip(cosine_sim, ratings)\n",
    "    # combined = sorted(combined, key=lambda x: x[0], reverse=False)\n",
    "    # avg = 0\n",
    "    # nof = 10.0\n",
    "    # for i in range(int(nof)):\n",
    "    #     avg += combined[i][1]\n",
    "    # return float(avg/nof)\n",
    "\n",
    "    #option 2:\n",
    "    # avg = 0\n",
    "    # for i in range(len(ratings)):\n",
    "    #     avg += ratings[i]\n",
    "    # return float(avg/len(ratings))\n",
    "\n",
    "    #option 3: \n",
    "    combined = zip(cosine_sim, ratings)\n",
    "    combined = sorted(combined, key=lambda x: x[0], reverse=True)\n",
    "    avg = 0\n",
    "    nof = 10.0\n",
    "    for i in range(int(nof)):\n",
    "        avg += combined[i][1]\n",
    "    return float(avg/nof)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def populate_5(user_to_word_counts_transformed, user_to_target_word_counts_transformed,\n",
    "               user_to_movie_id_to_rating, feature_1,\n",
    "                user_to_target_word_counts, user_to_word_counts,\n",
    "                user_to_ratings):\n",
    "    for i in range(len(user_to_movie_id_to_rating)):\n",
    "        feature_1.append(predict(i, user_to_word_counts_transformed, user_to_target_word_counts_transformed,\n",
    "                                  user_to_target_word_counts, user_to_word_counts, user_to_ratings))\n",
    "\n",
    "\n",
    "\n",
    "populate_5(train_users.user_to_word_counts_transformed, train_users.user_to_target_word_counts_transformed,\n",
    "           train_users.user_to_movie_id_to_rating, train_users.feature_1,\n",
    "                train_users.user_to_target_word_counts, train_users.user_to_word_counts,\n",
    "                train_users.user_to_ratings)\n",
    "\n",
    "populate_5(test_users.user_to_word_counts_transformed, test_users.user_to_target_word_counts_transformed,\n",
    "           test_users.user_to_movie_id_to_rating, test_users.feature_1,\n",
    "                test_users.user_to_target_word_counts, test_users.user_to_word_counts,\n",
    "                test_users.user_to_ratings)\n",
    "\n",
    "del train_users.user_to_word_counts\n",
    "del test_users.user_to_word_counts\n",
    "del train_users.user_to_word_counts_transformed\n",
    "del test_users.user_to_word_counts_transformed\n",
    "del train_users.user_to_target_word_counts\n",
    "del test_users.user_to_target_word_counts\n",
    "del train_users.user_to_target_word_counts_transformed\n",
    "del test_users.user_to_target_word_counts_transformed\n",
    "del train_users.user_to_ratings\n",
    "del test_users.user_to_ratings\n",
    "\n",
    "\n",
    "#note: for some reason feature 2 out performs feature 3 as a feature...\n",
    "\n",
    "#populates feature_2_train\n",
    "for i in range(len(train_users.user_to_movie_id_to_rating)): \n",
    "    if(len(movie_id_to_ratings_total[train_users.user_to_target_movie_id[i]])==1):\n",
    "        #this means that there is no other rating besides the first train rating\n",
    "        train_users.feature_2.append(overall_average_train)\n",
    "    else:\n",
    "        #omit the rating the user in question made\n",
    "        train_users.feature_2.append(float(((movie_id_to_average_rating_train[train_users.user_to_target_movie_id[i]]\n",
    "                        *len(movie_id_to_ratings_total[train_users.user_to_target_movie_id[i]]))\n",
    "                        -train_users.user_to_movie_id_to_rating[i][train_users.user_to_target_movie_id[i]])\n",
    "                        /(len(movie_id_to_ratings_total[train_users.user_to_target_movie_id[i]])-1)))\n",
    "\n",
    "\n",
    "#populates feature_2_test\n",
    "for i in range(len(test_users.user_to_movie_id_to_rating)):\n",
    "    if(test_users.user_to_target_movie_id[i] not in movie_id_to_ratings_total.keys()):\n",
    "        #if the movie is not in the train set make a guess\n",
    "        test_users.feature_2.append(overall_average_train)\n",
    "    else:\n",
    "        #only use the train data\n",
    "        test_users.feature_2.append(movie_id_to_average_rating_train[test_users.user_to_target_movie_id[i]])\n",
    "\n",
    "\n",
    "\n",
    "def populate_6(user_to_ratings_full_transform, user_to_ratings_full, user_to_target_index_full, \n",
    "               user_to_movie_id_to_rating, user_to_target_movie_id):\n",
    "    for i in range(len(user_to_movie_id_to_rating)):\n",
    "        ratings = []\n",
    "        index = 0\n",
    "        for movie_id in movies_in_order:\n",
    "            #note: when this happens should rating be omitted???\n",
    "            #it is omitted in another way later\n",
    "            #why can it not be omitted now???\n",
    "            if movie_id == user_to_target_movie_id[i]:\n",
    "                user_to_target_index_full.append(index)\n",
    "            if movie_id in user_to_movie_id_to_rating[i].keys():\n",
    "                ratings.append(user_to_movie_id_to_rating[i][movie_id])\n",
    "            elif movie_id in movie_id_to_average_rating_train.keys():\n",
    "                #note: does not consider test ratings\n",
    "                ratings.append(movie_id_to_average_rating_train[movie_id])\n",
    "            else:   \n",
    "                #note: does not consider test ratings\n",
    "                ratings.append(overall_average_train)\n",
    "            index +=1\n",
    "        #is copy needed, considering the scope of ratings???\n",
    "        #this behavior can be replace with append if they where lists\n",
    "        user_to_ratings_full.append(ratings)\n",
    "        user_to_ratings_full_transform.append([x - user_to_average_rating[i] for x in ratings])\n",
    "\n",
    "\n",
    "populate_6(train_users.user_to_ratings_full_transform, train_users.user_to_ratings_full, train_users.user_to_target_index_full, train_users.user_to_movie_id_to_rating, train_users.user_to_target_movie_id)\n",
    "populate_6(test_users.user_to_ratings_full_transform, test_users.user_to_ratings_full, test_users.user_to_target_index_full, test_users.user_to_movie_id_to_rating, test_users.user_to_target_movie_id)\n",
    "\n",
    "\n",
    "del train_users.user_to_movie_id_to_rating\n",
    "del test_users.user_to_movie_id_to_rating\n",
    "del train_users.user_to_target_movie_id\n",
    "del test_users.user_to_target_movie_id\n",
    "\n",
    "#why is feature 3 outperformed by feature 2 ???\n",
    "\n",
    "def populate_7(user_to_ratings_full_transform, user_to_ratings_full, user_to_target_index_full, feature_3):\n",
    "    for i in range(len(user_to_ratings_full)):\n",
    "        list_of_list_of_ratings = []\n",
    "        sample_ratings = []\n",
    "        for j in range(len(train_users.user_to_ratings_full)):\n",
    "            if i != j:\n",
    "                #note sure if this method is faster than full copy and deletion...\n",
    "                #because there is a check that needs to be done for each item...\n",
    "                sample_ratings.append(train_users.user_to_ratings_full[j][user_to_target_index_full[i]])\n",
    "                ratings = [train_users.user_to_ratings_full_transform[j][x] \n",
    "                          for x \n",
    "                          in range(len(train_users.user_to_ratings_full_transform[j])) \n",
    "                          if x != user_to_target_index_full[i]]\n",
    "                list_of_list_of_ratings.append(ratings)\n",
    "\n",
    "        #note sure if this method is faster than full copy and deletion...\n",
    "        #because there is a check that needs to be done for each item...\n",
    "        user_ratings = [user_to_ratings_full_transform[i][x] \n",
    "                    for x \n",
    "                    in range(len(user_to_ratings_full_transform[i])) \n",
    "                    if x != user_to_target_index_full[i]]\n",
    "\n",
    "\n",
    "        sim  = cosine_similarity(X = list_of_list_of_ratings, Y = [user_ratings])\n",
    "        sim = np.reshape(sim,  (len(sim)))\n",
    "\n",
    "        combined = zip(sim, sample_ratings)\n",
    "        #note: orginally, reverse is set to true to get the most similair users\n",
    "        #now trying reverse set to False\n",
    "        #either way for some reason feature 2 outperfrom feature 3...\n",
    "        combined = sorted(combined, key=lambda x: x[0], reverse = True)\n",
    "\n",
    "        avg = 0\n",
    "        nof = 10.0\n",
    "        for k in range(int(nof)):\n",
    "            avg+= combined[k][1]\n",
    "\n",
    "        feature_3.append(float(avg/nof))\n",
    "    \n",
    "\n",
    "#populate feature_3_train and feature_3_test\n",
    "populate_7(train_users.user_to_ratings_full_transform, train_users.user_to_ratings_full, train_users.user_to_target_index_full, train_users.feature_3)\n",
    "populate_7(test_users.user_to_ratings_full_transform, test_users.user_to_ratings_full, test_users.user_to_target_index_full, test_users.feature_3)\n",
    "\n",
    "del train_users.user_to_ratings_full_transform\n",
    "del test_users.user_to_ratings_full_transform\n",
    "del train_users.user_to_ratings_full\n",
    "del test_users.user_to_ratings_full\n",
    "del train_users.user_to_target_index_full\n",
    "del test_users.user_to_target_index_full\n",
    "\n",
    "\n",
    "#adjusted cossine simlairity\n",
    "#https://stackoverflow.com/questions/40716459/choice-between-an-adjusted-cosine-similarity-vs-regular-cosine-similarity\n",
    "#https://github.com/csaluja/JupyterNotebooks-Medium/blob/master/CF%20Recommendation%20System-Examples.ipynb?source=post_page-----ecbffe1c20b1--------------------------------\n",
    "#https://towardsdatascience.com/collaborative-filtering-based-recommendation-systems-exemplified-ecbffe1c20b1\n",
    "\n",
    "\n",
    "#note: in the item-based collabortive filtering the means is implementaed item-wise\n",
    "#this means with user-based collaboritve filtering the mean is implementad user-wise\n",
    "\n",
    "\n",
    "#idea 1:\n",
    "#use diferrent data structures...\n",
    "#numpy arrays...\n",
    "#https://www.geeksforgeeks.org/python-lists-vs-numpy-arrays/#\n",
    "#https://stackoverflow.com/questions/29839350/numpy-append-vs-python-append\n",
    "#https://www.geeksforgeeks.org/python-convert-list-to-python-array/\n",
    "\n",
    "\n",
    "#idea 2:\n",
    "#make use of both feature_2 and feature_3\n",
    "\n",
    "#idea 3: would it be possible to convert many of the main dictionaries to lists or numpy arrays\n",
    "#note: numpy arrays cant have variable number of items for a dimension\n",
    "#but this can be over come by filling missing values\n",
    "#this mean many matrices would be sparse\n",
    "#there is also alot of appending to lists which is better for lists\n",
    "\n",
    "\n",
    "#idea 4: would it be helpful to design my own data structures???\n",
    "\n",
    "#idea 5: would it be helpful to have features like the average 10 closest in similairy and the 10 farthest in similarity???\n",
    "\n",
    "#idea 6: before trying this there could be better data strcuture to use that would speed up the process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26144338 0.20693758]\n",
      "[0.23599574 0.17306216]\n",
      "[0.24793323 0.16964531]\n",
      "[0.28303639 0.25911458]\n",
      "[0.26362457 0.18855531]\n",
      "[0.29633155 0.25954128]\n",
      "[0.24254895 0.14437217]\n",
      "[0.34149521 0.23429827]\n",
      "[0.26492073 0.17915645]\n",
      "[0.22740808 0.18277874]\n",
      "[0.24104753 0.20289195]\n",
      "[0.31190979 0.23754572]\n",
      "[0.23101705 0.17039545]\n",
      "[0.22029605 0.16711303]\n",
      "[0.31540829 0.21983582]\n",
      "[0.22340333 0.15789087]\n",
      "[0.2284842  0.16540736]\n",
      "[0.26537413 0.18416583]\n",
      "[0.23419217 0.17812299]\n",
      "[0.26700871 0.19593263]\n",
      "(0.332180737747964, 0.3050224360707141)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#alternative to simply rerunning alaysis: run the entire code starting where random choice is implemented...\n",
    "\n",
    "#earliest random choice is the test and train users\n",
    "#this becomes averaged out with more users\n",
    "#the next random choice is the random target movie for each user to be trained and tested against\n",
    "#this can also be averged out with more users...\n",
    "#lastly the there is randomness used in the model\n",
    "#random state can be used to keep runs consistent\n",
    "#but a number of random runs can be combined to see the real difference between including...\n",
    "#different hyper parameters\n",
    "\n",
    "\n",
    "#hyper paramaters: only the layers and the features are a hyper parameters at the moment\n",
    "#def test_hyper_parameters():\n",
    "\n",
    "# runs analysis a number of times and average the returned\n",
    "# def average_results():\n",
    "\n",
    "#returns the two average scores with and without rounding\n",
    "# def analysis():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_parameters(layers, train_input_features, test_input_features):\n",
    "    train_inputs = [list(pair) for pair in train_input_features]\n",
    "    test_inputs = [list(pair) for pair in test_input_features]\n",
    "\n",
    "    return average_results(20, layers, train_inputs, test_inputs)\n",
    "    \n",
    "\n",
    "\n",
    "def average_results(nof_runs, layers, train_inputs, text_inputs):\n",
    "    no_rounding = 0\n",
    "    rounding = 0\n",
    "    for _ in range(nof_runs):\n",
    "        pair = analysis(layers, train_inputs, text_inputs)\n",
    "        no_rounding+=pair[0]\n",
    "        rounding+=pair[1]\n",
    "    return float(no_rounding/nof_runs), float(rounding/nof_runs)\n",
    "\n",
    "\n",
    "def analysis(layers, train_inputs, test_inputs):\n",
    "    #scale input features\n",
    "    input_scalar = StandardScaler()\n",
    "    train_inputs_scaled = input_scalar.fit_transform(train_inputs)\n",
    "\n",
    "    #scale target values\n",
    "    target_scalar = StandardScaler()\n",
    "    true_rating_train_scaled = target_scalar.fit_transform(np.array(train_users.user_to_target_rating).reshape(-1, 1))\n",
    "    true_rating_train_scaled = np.reshape(true_rating_train_scaled, len(true_rating_train_scaled))\n",
    "\n",
    "    #build and train model\n",
    "    reg = MLPRegressor(hidden_layer_sizes = layers, solver = \"adam\",  max_iter = 1000)\n",
    "    reg.fit(train_inputs_scaled, true_rating_train_scaled)\n",
    "\n",
    "    #show importance of different inputs features...\n",
    "    results = permutation_importance(reg, train_inputs_scaled,true_rating_train_scaled)\n",
    "    print(results[\"importances_mean\"])\n",
    "\n",
    "    #scale inputs features\n",
    "    input_scalar = StandardScaler()\n",
    "    test_inputs_scaled = input_scalar.fit_transform(test_inputs)\n",
    "\n",
    "    #predict the scaled verison of ouptuts\n",
    "    scaled_predictions = reg.predict(test_inputs_scaled)\n",
    "\n",
    "    #change back into regular outputs to be tested with target scalar above...\n",
    "    #not sure if this is correct???\n",
    "    #would it be better to use a new scalar object???\n",
    "    #need to know the mean and the std dev of the orginal predictions\n",
    "    predictions = target_scalar.inverse_transform(np.array(scaled_predictions).reshape(-1, 1))\n",
    "\n",
    "    #test with and without roundings...\n",
    "    rounded_predictions = []\n",
    "    for item in predictions:\n",
    "        rounded_predictions.append(float(round(item[0]*2)/2.0))\n",
    "\n",
    "    return(r2_score(test_users.user_to_target_rating, predictions), \n",
    "        r2_score(test_users.user_to_target_rating, rounded_predictions))\n",
    "\n",
    "\n",
    "print(test_parameters((10,10,10), \n",
    "      zip(train_users.feature_1, train_users.feature_2),\n",
    "      zip(test_users.feature_1, test_users.feature_2)))\n",
    "\n",
    "\n",
    "\n",
    "# all (10,10,10):\n",
    "\n",
    "# features 1 and 3 \n",
    "# (0.18554102264617328, 0.16860136788605123)\n",
    "\n",
    "# features 1 and 2\n",
    "# (0.20158362399544255, 0.1773859572065005)\n",
    "\n",
    "# features 1 and 3 with feature 3 reversed\n",
    "# (0.21357221749346827, 0.20629067245119317)\n",
    "\n",
    "# features 1 and 2 with feature 3 reversed\n",
    "# (0.23359676025501463, 0.2268980477223428)\n",
    "\n",
    "# feature 1 and 2 (with feature 1 reversed)\n",
    "# (0.11148086956267429, 0.08668995334522105)\n",
    "\n",
    "# feature 1 and 2 (with feature 1 complete)\n",
    "# (0.4308803372158775, 0.43312216112837687)\n",
    "# t2: (0.20265435431958068, 0.1869232087341802) \n",
    "# t3: (0.19338736134917242, 0.15702773818660246)\n",
    "# need to try with more layers...\n",
    "# (20,10,10)\n",
    "# t4: (0.1963526265039616, 0.13345576142966786) \n",
    "# (20,15,10)\n",
    "# t5: (0.1961748594852359, 0.1437342396667033)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is for observations and process descriptions\n",
    "\n",
    "\n",
    "#How will the model work to predict ratings in the test data???\n",
    "#for each test user a movie is randomly selected\n",
    "\n",
    "#The prediction will be made with the word counts for the ratings by the user but using the\n",
    "#the words_in_order of the train data for faster runtime (may change later)\n",
    "\n",
    "#besides an average for a number of simailair movies the user has watched, the easy\n",
    "#parameter is average rating since it only considers ratings from train data\n",
    "\n",
    "#analysis without feature scaling...\n",
    "#feature scaling:\n",
    "#https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/#:~:text=Scaling%20the%20target%20value%20is,learn%20and%20understand%20the%20problem.&text=Scaling%20of%20the%20data%20comes,algorithms%20in%20the%20data%20set.\n",
    "#https://towardsdatascience.com/collaborative-filtering-based-recommendation-systems-exemplified-ecbffe1c20b1\n",
    "\n",
    "#without scaling...\n",
    "# reg = MLPRegressor(hidden_layer_sizes = (20,15,10), max_iter = 10000)\n",
    "# train_inputs = []\n",
    "# for feature_1, feature_2 in zip(feature_1_train, feature_3_train):\n",
    "#     train_inputs.append([feature_1, feature_2])\n",
    "# reg.fit(train_inputs, true_rating_train)\n",
    "# results = permutation_importance(reg, train_inputs,true_rating_train)\n",
    "# print(results[\"importances_mean\"])\n",
    "# test_inputs = []\n",
    "# for feature_1, feature_2 in zip(feature_1_test, feature_3_test):\n",
    "#     test_inputs.append([feature_1, feature_2])\n",
    "# predictions = reg.predict(test_inputs)\n",
    "# rounded_predictions = []\n",
    "# for item in predictions:\n",
    "#     rounded_predictions.append(float(round(item*2)/2.0))\n",
    "# print(r2_score(true_rating_test, predictions))\n",
    "# print(r2_score(true_rating_test, rounded_predictions))\n",
    "\n",
    "\n",
    "# commented out for testing\n",
    "# predicted = []\n",
    "# for user in user_to_movie_id_to_corpus_train.keys(): \n",
    "#     if(len(movie_id_to_ratings[user_to_target_movie_id[user]])==1):\n",
    "#         predicted.append(overall_average)\n",
    "#     else:\n",
    "#         predicted.append(float(((movie_id_to_average_rating[user_to_target_movie_id[user]]\n",
    "#                         *len(movie_id_to_ratings[user_to_target_movie_id[user]]))\n",
    "#                         -user_to_movie_id_to_rating[user][user_to_target_movie_id[user]])\n",
    "#                         /(len(movie_id_to_ratings[user_to_target_movie_id[user]])-1)))\n",
    "        \n",
    "# nof_overall_avg = 0\n",
    "# for item in predicted:\n",
    "#     if item == overall_average:\n",
    "#         nof_overall_avg += 1\n",
    "# print(nof_overall_avg)\n",
    "# print(r2_score(true, predicted))\n",
    "\n",
    "\n",
    "#now for the user comparison logic (need user to list of movie ratings)\n",
    "#fill in ratings that the user hasn't watched with the method above\n",
    "#then cluster the users by their ratings\n",
    "\n",
    "#note: agglomerative clustering might make more sense here since k-means has random init for centroids...\n",
    "#note: to guess a new users rating requires that none of that users ratings have been used to train the model\n",
    "#The data needs to be split into test and train before modeling the algorithm on the train data\n",
    "\n",
    "#Training process:\n",
    "#split data into test and train data\n",
    "#proceed with train data...\n",
    "#cluster movies by the tokens with range for k\n",
    "#cluster users by the ratings with range for k and (fill in ratings for movies a users hasn't watched with some guess)\n",
    "#guess: this can be obtained by clustering the movies that the user has watched...\n",
    "#for each movie the user hasn't watched find the cluster that it belongs to with the highest possible k value\n",
    "#that the user has at least one movie belonging to one of the clusters and then take the average of those movies\n",
    "#this is exactly like a later training step excpet it is applied to all the movies the user watched\n",
    "\n",
    "#for a single randomly chosen movie from each user in the trainging data...\n",
    "\n",
    "#find the cluster the movie belongs to \n",
    "#find the movies part of that same cluster that the user has scored at the highest possible k value\n",
    "#take the average score of these movies\n",
    "#find the cluster the user belongs to\n",
    "#find the average rating of the movie for users in that cluster at the highest possible k value\n",
    "#train an mlp model with both averages and perhaps some extra statistics as features...\n",
    "#using the given movie ratings as actuals\n",
    "\n",
    "\n",
    "#The process of predicting a rating:\n",
    "#1. find the cluster the movie belongs to \n",
    "#2. find the movies part of that same cluster that the user has scored at the highest possible k value\n",
    "#3. take the average score of these movies\n",
    "#4. find the cluster the user belongs to\n",
    "#5. find the average rating of the movie for users in that cluster at the highest possible k value\n",
    "#6. input into the trained mlp model both averages and perhaps some extra statistics\n",
    "#7. make predictions and test against the randomly chosen movies actual ratings\n",
    "\n",
    "\n",
    "#summary:\n",
    "#find cluster for movie -> find movies part of the same clusters that the users rated -> average\n",
    "#question: are the clusters unique to the movies the user has watched or to all movies???\n",
    "#what is the technical difference???\n",
    "#is this the same as finding the most simimlair movie the user rated and copying the rating???\n",
    "\n",
    "#find cluster for user -> find the ratings for the movie by people in the same cluster -> average\n",
    "\n",
    "#other avenues considered:\n",
    "#idea 1:\n",
    "#for the first process, instead of averaging the movies that only the user rated, find other users that are...\n",
    "#like the user in question and find the average for that movie cluster\n",
    "#Problem: it is better to get the users raw opionion rather than generalizing it to some like minded users\n",
    "#there is an extra costly step to this\n",
    "#idea 2: \n",
    "#for the second process, instead of finding the average rating for the movie in the same cluster of users...\n",
    "#also find the average rating of movies that are like the movie in question \n",
    "#Problem, it is better to get the movies rating itself as it would be the most accurate indicator\n",
    "#there is an extra costly step to this\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test with overall averges:\n",
    "#note: users have between 50 and 75 ratings each\n",
    "#note: there are 250 users who are taken into account \n",
    "#note: seed int is one for above cells (cells part of creating the csv file)\n",
    "\n",
    "#with seed int == 3, 4 taking overall averages: 0.09565753948597455\n",
    "#with seed_int == 1, 2 taking overall averages: 0.070404868516315\n",
    "#with seed_int == 2, 5 taking overall averages: 0.11310085954932936\n",
    "#with seed_int == 4, 6 taking overall averages: 0.07125374341347135\n",
    "#with seed_int == 5, 4 taking overall averages: 0.17736444913943628\n",
    "#compute time: 11 minutes\n",
    "\n",
    "\n",
    "#test with users related movies:\n",
    "#is there a magic proportion of movies to average???\n",
    "#note: this is taking around the same time as the above tests meaning \n",
    "#there could be more users to include in analysis with little increase in runtime\n",
    "#k fold cross validation could be effective\n",
    "#https://www.youtube.com/watch?v=TIgfjmp-4BA&ab_channel=Udacity\n",
    "\n",
    "#effect of choosing a random seed...\n",
    "#https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79\n",
    "\n",
    "#try tinkering with the number of similair movies to average\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
