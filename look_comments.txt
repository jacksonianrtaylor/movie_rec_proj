LOOK: What about k-means clustering and then a weighted average for movies in the same cluster as the target movie


#LOOK: Need to check if the model is overfitting (mlp regressor)

#LOOK: need to try gradient descent instead of sgd

#LOOK: is there enough data for training???

#LOOK: A potentially helpful thing to do would be to perform cluster analysis on the term frequencies of the movies.
#then certain movies that are clustered around the target can be used to predict the rating of the target movies
#rather than use every movie the user rated ignoring the major differences in clusters.
#this assumes movies in the same general cluster follow the same rules
#the closer you are to a movie in that cluster the more of that other movies rating you pick up

#LOOK: Need to explore an even more efficient usage of svd
#my application: https://yeunun-choo.medium.com/singular-value-decomposition-in-a-movie-recommender-system-e3565ed42066
#more involved: https://pianalytix.com/simple-movie-recommender-using-svd/


#LOOK: All train users have much more movie ratings than test users, so the users average rating is being
#assumed to be a more reliable estimator 
#For the svd part, remember that traing was developed with taking svd outputs for users with the same number of movies...
#as user that were going to be tested but this resultedin in worse results.


#LOOK: Need to apply hyperparameter tuning
#Need to systematically construct a list of hidden layer sizes of different sizes and lengths
#What if I were to construct it with interavle of 5?
#What is something other than grid search was used?

#LOOK: revert this back to 3 layers and max nof nodes  = 15

#LOOK: in the preliminary testing the number of runs is 100 to reduce the random varaition and make it so that the...
#best perfoming network is actually the best 


#LOOK: there is slight variation in results between running on ubuntu and windows but it is very accurate to a certaun decimal.

#LOOK: should try using the netflix prize data to compare to the winning algorithm
#LOOK: should round the ratings to the nearest whole numbers like is netflix prize
#how should they be rounded without loss???

#LOOK: why do we need to filter the number of movies on record for users when a cetrain lower number of rating can be...
#taken from users with more than enough ratings???

# Average r2_score with rounded prediction to nearest .5 (note: the actual ratings a user makes must be divisable by .5): 0.17836146508107842
# Minutes taken: 1.7588933110237122


#LOOK: Minutes taken: 2.2997989495595297 with grid search...


#LOOK: problem with scopt and baysian optimization and numpy
#https://stackoverflow.com/questions/76321820/how-to-fix-the-numpy-int-attribute-error-when-using-skopt-bayessearchcv-in-sci

#LOOK: for simplicity baysian search was not used because of a dependency problem

#LOOK: include this in readme: before this current code using optimization,...
#The older code tested 100 models per layer input to be sure to find the best performing parameter
#testing a model multiple times is slow when using grid and random search because you arn't omitting values that are
#not optimal unless you edit the list of hyperparameters (list of layer combination) which can be tedious
#instead just applying a constant group of layers testing for 100 iterations and then adjusting the weigth in hopes of improvemnt
#seemed to result int the best number of layers
#the outpu and best perfoming layer combination is different from the grid search and individual testing
#becasue eveyr single model is tested 100 times inthe previous code