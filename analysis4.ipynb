{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m norm\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import var\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statistics\n",
    "import math\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "#load data\n",
    "ratings = pd.read_csv('dataset/ratings.csv')\n",
    "moviesPartial = pd.read_csv('dataset/movies.csv')\n",
    "moviesFull = pd.read_csv('dataset/movie_dataset.csv')\n",
    "\n",
    "#drop duplicates\n",
    "moviesFull.drop_duplicates(subset = 'title', inplace=True)\n",
    "\n",
    "#drop columns that do nothing\n",
    "ratings = ratings.drop(['timestamp'], axis = 1)\n",
    "moviesPartial = moviesPartial.drop(['genres'],axis=1)\n",
    "\n",
    "#all the users are to be tested\n",
    "userRatings = []\n",
    "for i in range(1,611):\n",
    "    userRatings.append(ratings[ratings['userId'] ==i])\n",
    "\n",
    "#remove the year and keep the name\n",
    "moviesPartial['title'] = moviesPartial['title'].map(lambda string: string[:-7])\n",
    "\n",
    "#drop duplicates\n",
    "moviesPartial.drop_duplicates(subset = 'title', inplace=True)\n",
    "\n",
    "#helper functions:\n",
    "def get_title_from_movieId(tmp):\n",
    "    return moviesPartial[moviesPartial[\"movieId\"]== tmp][\"title\"].to_string(index=False)\n",
    "\n",
    "def checkTitle(tmp):\n",
    "    if(tmp not in list(moviesFull[\"title\"])):\n",
    "        #The word \"the\" is being apended to the ends of titles\n",
    "        tmp = tmp[-3:] +\" \"+ tmp[:-5]\n",
    "        return moviesFull[moviesFull[\"title\"] == tmp][\"title\"].to_string(index=False)\n",
    "    else:\n",
    "        return moviesFull[moviesFull[\"title\"] == tmp][\"title\"].to_string(index=False)\n",
    "\n",
    "\n",
    "\n",
    "#used to filter out movies that are not in both data sets\n",
    "newUserTitles = []\n",
    "newUserRatings = []\n",
    "averageUserRating = 0\n",
    "cnt =0\n",
    "for userRating in userRatings:\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    for rating, id in zip(list(userRating[\"rating\"]), list(userRating[\"movieId\"])):\n",
    "        title = get_title_from_movieId(id)\n",
    "        checked = checkTitle(title)\n",
    "        if(checked != 'Series([], )'):\n",
    "            temp1.append(checked)\n",
    "            temp2.append(rating)\n",
    "            averageUserRating += rating\n",
    "            cnt+=1\n",
    "\n",
    "    newUserTitles.append(temp1)\n",
    "    newUserRatings.append(temp2)\n",
    "\n",
    "averageUserRating/= cnt\n",
    "    \n",
    "\n",
    "\n",
    "#this might lead to a referencce error\n",
    "#populate infos; a list of data frames\n",
    "infos = []\n",
    "for user in newUserTitles:\n",
    "    i = 0\n",
    "    tempInfo = pd.DataFrame(columns = list(moviesFull.columns))\n",
    "    for name in user:\n",
    "        if(len(moviesFull[moviesFull[\"title\"] == name]) !=0):\n",
    "            tempInfo.loc[i] = moviesFull[moviesFull[\"title\"] == name].iloc[0]\n",
    "        i+=1\n",
    "    infos.append(tempInfo)\n",
    "    \n",
    "\n",
    "features = ['keywords','cast','genres','director']\n",
    "\n",
    "\n",
    "for info in infos:\n",
    "    for feature in features:\n",
    "        info[feature] = info[feature].fillna('')\n",
    "\n",
    "colNumbers = []\n",
    "for feature in features:   \n",
    "    colNumbers.append(infos[0].columns.get_loc(feature))\n",
    "\n",
    "fullDataList =[]\n",
    "\n",
    "\n",
    "for frame in infos:\n",
    "    fullDataList.append(frame.values.tolist())\n",
    "\n",
    "combinedFeatures = []\n",
    "\n",
    "for item in fullDataList:\n",
    "    tmp = []\n",
    "    for row in item:\n",
    "        tmp.append(row[colNumbers[0]]+\" \"+row[colNumbers[1]]+\" \"+row[colNumbers[2]]+\" \"+row[colNumbers[3]])\n",
    "    combinedFeatures.append(tmp)\n",
    "\n",
    "\n",
    "def transform1(arr):\n",
    "    ret = []\n",
    "    for item in arr:\n",
    "        if(item<=.5):\n",
    "            ret.append(1/item)\n",
    "        if(item>.5):\n",
    "            ret.append(-1*(1/(1-item)))\n",
    "    return ret\n",
    "\n",
    "def transform2(arr):\n",
    "    ret = []\n",
    "    for item in arr:\n",
    "        ret.append(1/item)\n",
    "    return ret\n",
    "\n",
    "def findAverageRating(arr1, arr2, title, ignore1, ignore2, ave):\n",
    "    ret =0\n",
    "    cnt =0\n",
    "    single = True\n",
    "    for index, item1, item2 in zip(enumerate(arr1), arr2):\n",
    "        for i in range(len(item1)):\n",
    "            if(title == item1[i] and (ignore1!=index or ignore2!=i)):\n",
    "                ret+= item2[i]\n",
    "                cnt+=1\n",
    "                single = False\n",
    "\n",
    "    if(single):\n",
    "        return ave\n",
    "    else:\n",
    "        return ret/cnt\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(combinedFeatures)):\n",
    "    count_matrix = CountVectorizer().fit_transform(combinedFeatures[i]).toarray().tolist()\n",
    "    randIndex = random.randint(0, len(count_matrix)-1)\n",
    "    randTestItem = count_matrix[randIndex]\n",
    "    del count_matrix[randIndex]\n",
    "\n",
    "    #newUserTitles[i][randIndex] will provide a random title name\n",
    "    #then loop through the entire newUserTitle to find matching titles to...\n",
    "    #add the corresponsing rating at the same index\n",
    "    #ignore the same index to omit the curent users rating\n",
    "    #it may be faster to use a dictionary\n",
    "\n",
    "\n",
    "    #if there is no ratings from other users give the default score of the combined average of\n",
    "    #all ratings ever can be calcuated above\n",
    "\n",
    "\n",
    "    cosine_sim = cosine_similarity(X = count_matrix ,Y = [randTestItem])\n",
    "\n",
    "    ratings = newUserRatings[i]\n",
    "    randomRating = ratings[randIndex]\n",
    "    del ratings[randIndex]\n",
    "\n",
    "    print(\"p1\",len(count_matrix))\n",
    "    print(\"p2\",len(cosine_sim))\n",
    "    print(cosine_sim)\n",
    "    similairities = np.reshape(cosine_sim,  (len(cosine_sim)))\n",
    "    print(similairities)\n",
    "\n",
    "    averageRating =  sum(ratings)/(len(ratings))\n",
    "\n",
    "    tmp = []\n",
    "    tmp.append(findAverageRating(newUserTitles,\n",
    "                                  newUserRatings,\n",
    "                                    newUserTitles[i][randIndex],\n",
    "                                  i, randIndex, averageUserRating))\n",
    "    tmp.append(averageRating)\n",
    "    tmp.append(sum(similairities)/(len(similairities)))\n",
    "    tmp.append(statistics.variance(ratings))\n",
    "    tmp.append(statistics.variance(similairities))\n",
    "    ratingsZ = stats.zscore(ratings)\n",
    "    ratingsZ = [0 if math.isnan(x) else x for x in ratingsZ]\n",
    "    ratingsZ = [-item if item<0 else item for item in ratingsZ]\n",
    "    simsZ  = stats.zscore(similairities)\n",
    "    simsZ = [-item if item<0 else item for item in simsZ]\n",
    "\n",
    "    totalRating = 0\n",
    "\n",
    "    #does adding constant multiplier help?\n",
    "    #nots: 20\n",
    "    for sim, rating,simZ, ratingZ in zip(similairities, ratings, simsZ, ratingsZ):\n",
    "        totalRating += sim*(rating-averageRating)*simZ*ratingZ\n",
    "    \n",
    "    tmp.append(totalRating)\n",
    "    #next try just total rating\n",
    "    X.append(tmp)\n",
    "    y.append(randomRating)\n",
    "\n",
    "\n",
    "\n",
    "#new varriables to feed into the linear reg model:\n",
    "#variance of ratings, variance of similairities\n",
    "#mean of ratings, mean of similarities, rating diff\n",
    "\n",
    "#new model:\n",
    "\n",
    "# regr = MLPRegressor(hidden_layer_sizes=(200, 100), max_iter = 10000).fit(X, y)\n",
    "# print(\"after nearal net regression:\", regr.score(X, y))\n",
    "# predicted = regr.predict(X)\n",
    "# for item, actual in zip(predicted, y):\n",
    "#     print(\"predicted:\", item)\n",
    "#     print(\"actual:\", actual)\n",
    "\n",
    "\n",
    "#old model\n",
    "# reg = LinearRegression().fit(X, y)\n",
    "# #note: uses training data to test\n",
    "# print(\"after linear regression:\", reg.score(X, y))\n",
    "# predicted = reg.predict(X)\n",
    "# for item, actual in zip(predicted, y):\n",
    "#     print(\"predicted:\", item)\n",
    "#     print(\"actual:\", actual)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after nearal net regression: -0.31749215720931034\n",
      "10000\n",
      "(1000, 1000, 1000)\n",
      "predicted: 3.9035727913697587\n",
      "actual: 3.0\n",
      "predicted: 4.670201243266667\n",
      "actual: 4.0\n",
      "predicted: 4.822735110400296\n",
      "actual: 4.0\n",
      "predicted: 3.3847751026912705\n",
      "actual: 5.0\n",
      "predicted: 3.682444423657722\n",
      "actual: 3.5\n",
      "predicted: 3.6006656016675462\n",
      "actual: 3.0\n",
      "predicted: 4.056034277896135\n",
      "actual: 4.0\n",
      "predicted: 4.574822945055988\n",
      "actual: 5.0\n",
      "predicted: 2.9970633225035086\n",
      "actual: 5.0\n",
      "predicted: 3.4732412995539166\n",
      "actual: 3.0\n",
      "predicted: 3.689169108588059\n",
      "actual: 4.0\n",
      "predicted: 3.9450241199160385\n",
      "actual: 4.0\n",
      "predicted: 3.278853593880186\n",
      "actual: 4.0\n",
      "predicted: 3.333002808892066\n",
      "actual: 3.0\n",
      "predicted: 3.3137764859631726\n",
      "actual: 3.0\n",
      "predicted: 2.9622937157158935\n",
      "actual: 3.0\n",
      "predicted: 3.4471108025506583\n",
      "actual: 3.0\n",
      "predicted: 3.9031463156278314\n",
      "actual: 4.0\n",
      "predicted: 4.127857851857565\n",
      "actual: 5.0\n",
      "predicted: 2.570898114415924\n",
      "actual: 2.0\n",
      "predicted: 1.9185487531534173\n",
      "actual: 1.0\n",
      "predicted: 3.893212746663771\n",
      "actual: 4.0\n",
      "predicted: 2.5769308100881023\n",
      "actual: 4.5\n",
      "predicted: 3.672040188013638\n",
      "actual: 3.0\n",
      "predicted: 3.376200994176086\n",
      "actual: 3.0\n",
      "predicted: 4.549452192900953\n",
      "actual: 4.0\n",
      "predicted: 4.732926987122085\n",
      "actual: 0.5\n",
      "predicted: 4.719497037620983\n",
      "actual: 5.0\n",
      "predicted: 3.1517375247276584\n",
      "actual: 2.5\n",
      "predicted: 3.6820298696035314\n",
      "actual: 4.0\n",
      "predicted: 3.0231147357642856\n",
      "actual: 4.0\n",
      "predicted: 3.597629491024378\n",
      "actual: 4.0\n",
      "predicted: 2.630957303551208\n",
      "actual: 5.0\n",
      "predicted: 2.9443325971700447\n",
      "actual: 3.5\n",
      "predicted: 3.2870501585184595\n",
      "actual: 4.0\n",
      "predicted: 4.5559744073295985\n",
      "actual: 4.5\n",
      "predicted: 4.346122757131092\n",
      "actual: 4.0\n",
      "predicted: 4.764235581047424\n",
      "actual: 4.0\n",
      "predicted: 3.808039249656942\n",
      "actual: 5.0\n",
      "predicted: 2.10154279211708\n",
      "actual: 5.0\n",
      "predicted: 2.465079874698042\n",
      "actual: 4.0\n",
      "predicted: 1.9782147860934085\n",
      "actual: 4.5\n",
      "predicted: 3.637658767425026\n",
      "actual: 4.0\n",
      "predicted: 4.08704857061623\n",
      "actual: 4.5\n",
      "predicted: 5.321030576558303\n",
      "actual: 4.5\n",
      "predicted: 3.8807188321777923\n",
      "actual: 5.0\n",
      "predicted: 3.620365979897729\n",
      "actual: 3.0\n",
      "predicted: 3.1396860674037077\n",
      "actual: 3.5\n",
      "predicted: 1.8220337253226442\n",
      "actual: 5.0\n",
      "predicted: 3.3718579390847436\n",
      "actual: 4.0\n",
      "predicted: 3.8418633720837683\n",
      "actual: 5.0\n",
      "predicted: 3.9031998875320792\n",
      "actual: 4.0\n",
      "predicted: 2.21063255036457\n",
      "actual: 4.0\n",
      "predicted: 2.6439240212869404\n",
      "actual: 4.0\n",
      "predicted: 3.5855718374455616\n",
      "actual: 4.0\n",
      "predicted: 3.9252018172391017\n",
      "actual: 4.0\n",
      "predicted: 4.1976312426113855\n",
      "actual: 4.0\n",
      "predicted: 4.257129844830803\n",
      "actual: 1.0\n",
      "predicted: 3.4934431417640095\n",
      "actual: 3.0\n",
      "predicted: 4.118946289424431\n",
      "actual: 5.0\n",
      "predicted: 4.018690211177735\n",
      "actual: 4.5\n",
      "predicted: 3.3895108577636144\n",
      "actual: 5.0\n",
      "predicted: 2.50020622854578\n",
      "actual: 1.5\n",
      "predicted: 3.686943222042326\n",
      "actual: 5.0\n",
      "predicted: 4.458041621264269\n",
      "actual: 3.0\n",
      "predicted: 1.9691172627379536\n",
      "actual: 3.0\n",
      "predicted: 1.1821557459549858\n",
      "actual: 4.0\n",
      "predicted: 5.061761577112132\n",
      "actual: 3.5\n",
      "predicted: 3.3926287453185937\n",
      "actual: 4.0\n",
      "predicted: 5.522746554591778\n",
      "actual: 5.0\n",
      "predicted: 3.500495854883188\n",
      "actual: 3.0\n",
      "predicted: 3.7915651747622374\n",
      "actual: 3.0\n",
      "predicted: 1.9654591227728628\n",
      "actual: 3.0\n",
      "predicted: 3.940385311529323\n",
      "actual: 5.0\n",
      "predicted: 3.721752272515674\n",
      "actual: 3.0\n",
      "predicted: 3.2339922792322904\n",
      "actual: 3.0\n",
      "predicted: 3.4592862900713026\n",
      "actual: 2.5\n",
      "predicted: 3.0233807412056155\n",
      "actual: 4.0\n",
      "predicted: 3.551526517518705\n",
      "actual: 5.0\n",
      "predicted: 4.279329714812847\n",
      "actual: 4.0\n",
      "predicted: 4.475478840864491\n",
      "actual: 4.0\n",
      "predicted: 4.139629479518363\n",
      "actual: 5.0\n",
      "predicted: 3.7905587425434275\n",
      "actual: 5.0\n",
      "predicted: 1.8535116886093619\n",
      "actual: 3.5\n",
      "predicted: 4.042149345283276\n",
      "actual: 5.0\n",
      "predicted: 4.276315656018306\n",
      "actual: 4.0\n",
      "predicted: 3.0390108475725572\n",
      "actual: 4.0\n",
      "predicted: 3.7085499524168872\n",
      "actual: 3.0\n",
      "predicted: 3.928026155439583\n",
      "actual: 4.0\n",
      "predicted: 3.9802986770148157\n",
      "actual: 4.0\n",
      "predicted: 3.4063692385379127\n",
      "actual: 4.0\n",
      "predicted: 3.5968297121951376\n",
      "actual: 4.0\n",
      "predicted: 3.5248887602693983\n",
      "actual: 5.0\n",
      "predicted: 3.8371622696038745\n",
      "actual: 3.0\n",
      "predicted: 3.13235254323442\n",
      "actual: 3.5\n",
      "predicted: 3.1359973342942715\n",
      "actual: 4.0\n",
      "predicted: 3.791848408596839\n",
      "actual: 4.0\n",
      "predicted: 2.083243419350004\n",
      "actual: 3.0\n",
      "predicted: 4.08805549625328\n",
      "actual: 4.5\n",
      "predicted: 3.6033389676176277\n",
      "actual: 3.5\n",
      "predicted: 4.673977353772652\n",
      "actual: 4.0\n",
      "predicted: 3.3118226492055816\n",
      "actual: 4.0\n",
      "predicted: 3.651786032581028\n",
      "actual: 4.0\n",
      "predicted: 3.5228320160522784\n",
      "actual: 4.0\n",
      "predicted: 3.6275193664953074\n",
      "actual: 2.5\n",
      "predicted: 3.680110489548565\n",
      "actual: 4.0\n",
      "predicted: 3.720768496943675\n",
      "actual: 3.5\n",
      "predicted: 3.1555989336040158\n",
      "actual: 3.5\n",
      "predicted: 3.8814235521160207\n",
      "actual: 3.0\n",
      "predicted: 3.9539423213960423\n",
      "actual: 4.0\n",
      "predicted: 3.7873662541580604\n",
      "actual: 3.0\n",
      "predicted: 2.876620649219023\n",
      "actual: 4.5\n",
      "predicted: 4.015285706316878\n",
      "actual: 5.0\n",
      "predicted: 3.6292854818885694\n",
      "actual: 5.0\n",
      "predicted: 4.292890681768836\n",
      "actual: 5.0\n",
      "predicted: 3.650925419679005\n",
      "actual: 4.0\n",
      "predicted: 3.8211473484570924\n",
      "actual: 4.0\n",
      "predicted: 3.4965103289758726\n",
      "actual: 0.5\n",
      "predicted: 2.766859911133011\n",
      "actual: 3.5\n",
      "predicted: 2.6897127398959215\n",
      "actual: 2.0\n",
      "predicted: 4.190263207595901\n",
      "actual: 4.0\n",
      "predicted: 1.9629897355883377\n",
      "actual: 4.0\n",
      "predicted: 4.650225324259818\n",
      "actual: 5.0\n",
      "predicted: 3.229177863548488\n",
      "actual: 4.0\n",
      "predicted: 3.3533079677864253\n",
      "actual: 3.5\n",
      "predicted: 6.054427536481337\n",
      "actual: 5.0\n",
      "predicted: 4.0211598734209115\n",
      "actual: 3.0\n",
      "predicted: 3.9202943122627376\n",
      "actual: 3.5\n",
      "predicted: 4.299530410591454\n",
      "actual: 4.5\n",
      "predicted: 3.809533831880129\n",
      "actual: 4.0\n",
      "predicted: 3.2775541400353996\n",
      "actual: 3.0\n",
      "predicted: 3.9890066946704765\n",
      "actual: 4.0\n",
      "predicted: 1.949081588505531\n",
      "actual: 2.0\n",
      "predicted: 3.116206171368489\n",
      "actual: 3.0\n",
      "predicted: 3.8087498895592553\n",
      "actual: 5.0\n",
      "predicted: 4.1213653561741594\n",
      "actual: 5.0\n",
      "predicted: 3.541357833049404\n",
      "actual: 5.0\n",
      "predicted: 3.6445969743914644\n",
      "actual: 4.5\n",
      "predicted: 3.649415279636691\n",
      "actual: 4.5\n",
      "predicted: 3.8397575128383052\n",
      "actual: 4.0\n",
      "predicted: 4.125929167670553\n",
      "actual: 3.0\n",
      "predicted: 3.0916243800560075\n",
      "actual: 4.5\n",
      "predicted: 4.182829073754472\n",
      "actual: 3.0\n",
      "predicted: 4.006924601135409\n",
      "actual: 4.0\n",
      "predicted: 2.0258050466794453\n",
      "actual: 4.0\n",
      "predicted: 3.364262842569724\n",
      "actual: 3.0\n",
      "predicted: 3.5501054255182845\n",
      "actual: 0.5\n",
      "predicted: 3.4266399200946482\n",
      "actual: 4.5\n",
      "predicted: 3.555054185493211\n",
      "actual: 3.0\n",
      "predicted: 4.042921235763701\n",
      "actual: 1.5\n",
      "predicted: 4.412614764013477\n",
      "actual: 4.5\n",
      "predicted: 3.6459191762657435\n",
      "actual: 3.0\n",
      "predicted: 3.284034554021724\n",
      "actual: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repos\\movie_rec_proj\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)\n",
    "\n",
    "\n",
    "#another feature can be average user score for the movie in question\n",
    "#how can this integrate the other methods to recommend simlair movies\n",
    "#rather than directly predict what the user rates\n",
    "#should there be words omited from the descriptions to reduce sudo simlairtiy\n",
    "#look into inverse document frequency\n",
    "\n",
    "#https://www.youtube.com/watch?v=O9aAwvk6SNI&ab_channel=HackersRealm\n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes=(1000,  1000, 1000), \n",
    "                    activation = \"relu\",\n",
    "                    solver =\"adam\",\n",
    "                    learning_rate_init =.00001,\n",
    "                    max_iter = 10000,\n",
    "                    n_iter_no_change = 100).fit(X_train, y_train)\n",
    "\n",
    "score  = regr.score(X_test, y_test)\n",
    "file = open(\"testing.txt\", \"a\")\n",
    "file.write(\"hidden_layer_sizes=\"+str(regr.hidden_layer_sizes)+\", max_iter = \"+str(regr.n_iter_)+\" \" + str(score)+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "print(\"after nearal net regression:\", score)\n",
    "print(regr.n_iter_)\n",
    "print(regr.hidden_layer_sizes)\n",
    "\n",
    "predicted = regr.predict(X_test)\n",
    "for item, actual in zip(predicted, y_test):\n",
    "    print(\"predicted:\", item)\n",
    "    print(\"actual:\", actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
